{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baaeb589",
   "metadata": {},
   "source": [
    "This notebook looks at the `scanpy` classic [dimensionality reduction tutorial](https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html) \n",
    "from the distortion estimation point of view. We'll apply the UMAP and cell type\n",
    "clustering routines and then create some interactive figures that show how cell\n",
    "types can have systematically different distortion properties. If you want to see what this looks like in `scanpy`'s [new plotting workflow](https://scanpy.readthedocs.io/en/stable/tutorials/plotting/core.html)\n",
    "just replace the `sc.datasets.pbmc3k_processed()` call below with `sc.datasets.pbmc68k_reduced()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a66574a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "adata = sc.datasets.pbmc3k_processed()\n",
    "save_dir = \"/Users/krissankaran/Desktop/collaborations/distortions-project/distortions-dev/paper/figures/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f14dd8",
   "metadata": {},
   "source": [
    "## Run UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617ff48e",
   "metadata": {},
   "source": [
    "The block below looks like a lot of code, but it's mostly because we need to hard code the labels for different self clusters. The first four lines are the most important they run a new map with 50 nearest neighbors after PCA denoising. We then cluster those UMAP embeddings with the Leiden algorithm. We can get some more interpretable cell type annotations by referring to well known marker genes. This is what the `marker_gene_dict` and  `cluster2annotation` variables contain. None of these steps are really necessary for distortion estimation, but they'll allow us to put names on the differences between cell types, that will see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53992f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import scanpy as sc\n",
    "random.seed(20250410)\n",
    "\n",
    "n_neighbors = 10\n",
    "sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=50)\n",
    "sc.tl.umap(adata, init_pos = \"spectral\") # set to \"random\" for random initialization\n",
    "sc.tl.leiden(\n",
    "    adata,\n",
    "    key_added=\"clusters\",\n",
    "    resolution=0.5,\n",
    "    n_iterations=2,\n",
    "    flavor=\"igraph\",\n",
    "    directed=False,\n",
    ")\n",
    "marker_genes_dict = {\n",
    "    \"B-cell\": [\"CD79A\", \"MS4A1\"],\n",
    "    \"Dendritic\": [\"FCER1A\", \"CST3\"],\n",
    "    \"Monocytes\": [\"FCGR3A\"],\n",
    "    \"NK\": [\"GNLY\", \"NKG7\"],\n",
    "    \"Other\": [\"IGLL1\"],\n",
    "    \"Plasma\": [\"IGJ\"],\n",
    "    \"T-cell\": [\"CD3D\"],\n",
    "}\n",
    "\n",
    "cluster2annotation = {\n",
    "    \"0\": \"Monocytes\",\n",
    "    \"1\": \"NK\",\n",
    "    \"2\": \"T-cell\",\n",
    "    \"3\": \"Dendritic\",\n",
    "    \"4\": \"Dendritic\",\n",
    "    \"5\": \"Plasma\",\n",
    "    \"6\": \"B-cell\",\n",
    "    \"7\": \"Dendritic\",\n",
    "    \"8\": \"Other\",\n",
    "}\n",
    "\n",
    "adata.obs[\"cell_type\"] = adata.obs[\"clusters\"].map(cluster2annotation).astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d183f729",
   "metadata": {},
   "source": [
    "## Estimate Distortion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4670345a",
   "metadata": {},
   "source": [
    "Now that we have the embedding, we can estimate the associated distortion. The array `H` below stores, the local distortion information associated with every single cell. The estimates come from the geometry function, which is exactly copied from the [`megaman` package](https://mmp2.github.io/megaman/) and which implement the algorithms described in this [paper](https://arxiv.org/abs/1305.7255). This function unfortunately has a few hyperparameters, and that's because to estimate distortion we need to estimate a graph Laplacian. This provides a kind of ground truth manifold distance information -- in fact, there is strong theory to support the use of this object in estimating manifolds when the sample size increases to infinity. Unfortunately, with any finite amount of data, the estimate can depend on the hyper parameters in the function. We generally recommend setting the number of neighbors to be the same as the number of neighbors in the original embedding function, in this case 50. From there, we can set the radius to the a small multiple of the average distance between neighbors. The scaling epsilon parameter is usually a small number from one to 10 and it's purpose is to stabilize the values `H`. You might want to tinker it with it in case you're noticing an extreme range of ellipse sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eed286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distortions.geometry import Geometry, local_distortions\n",
    "import numpy as np\n",
    "\n",
    "embedding = adata.obsm[\"X_umap\"].copy()\n",
    "radius = 3 * np.mean(adata.obsp[\"distances\"].data)\n",
    "geom = Geometry(\"brute\", laplacian_method=\"geometric\", laplacian_kwds={\"scaling_epps\": 5}, adjacency_kwds={\"n_neighbors\": n_neighbors}, affinity_kwds={\"radius\": radius})\n",
    "H, Hvv, Hs = local_distortions(embedding, adata.X, geom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b402e5",
   "metadata": {},
   "source": [
    "Next would do some light postprocessing on the local distortion estimates. This is only necessary in this notebook because we want to illustrate the isometrization routine. Since the raw output H has a few outliers will try truncating them. This will make sure that those outliers don't dominate the visualization. We also re-normalize the singular values `Hs` according to their mean. This ensures that we aren't always contracting or always dilating regions of the visualization when we interact with it. Again this step is only necessary for the `inter_isometry` function below that implements isometrization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83687980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# postprocessing\n",
    "#Hs[Hs > 8] = 8 # for random plot\n",
    "Hs[Hs > 2.5] = 2.5\n",
    "Hs /= Hs.mean()\n",
    "for i in range(len(H)):\n",
    "    H[i] = Hvv[i] @ np.diag(Hs[i]) @ Hvv[i].T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839c44f1",
   "metadata": {},
   "source": [
    "Next, we add that local distortion information into our original embedding output. There's nothing really fancy going on in `bind_metric`. It's really just a wrapper of some pandas concatenation calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb68800a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distortions.geometry import bind_metric\n",
    "\n",
    "embedding = bind_metric(embedding, Hvv, Hs)\n",
    "embedding[\"cell_type\"] = adata.obs[\"cell_type\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139d99a9",
   "metadata": {},
   "source": [
    "## Static Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff14f6cc",
   "metadata": {},
   "source": [
    "Before we do anything interactive, let's build some intuition about these outputs using some static visualizations. Our first is a plot is just a scatter pot of the UMAP embeddings. We see some clear structure that differentiates between different types of blood cells. The question is -- how reliable are these embeddings for making specific distance comparisons? From the raw output, we had no idea about house distances might be stretched or compressed locally, or whether distances between clusters accurately preserve the distances observed in the original high-dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb8f4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "sort_order = [\"Monocytes\", \"NK\", \"T-cell\", \"Dendritic\", \"Plasma\", \"B-cell\", \"Other\"]\n",
    "alt.Chart(embedding).mark_circle().encode(\n",
    "    x=alt.X(\"embedding_0\"),\n",
    "    y=alt.Y(\"embedding_1\"),\n",
    "    color=alt.Color(\"cell_type\", sort=sort_order).scale(scheme=\"category10\")\n",
    ").properties(width=400, height=400)\\\n",
    " .configure_axis(grid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c012f80e",
   "metadata": {},
   "source": [
    "Let's now look at a less standard (but still static) plot. We'll compare the singular values from the local metrics estimated above. Please give a sense of the dilation and compression induced by the embedding locally around a cell. Ideally these would all be close to the identity of line meaning that no one direction along the true manifold is stretched more than any another. Here, though we noticed that often the x-axis (first singular value, $\\lambda_1$) is quite a bit larger than the y-axis (second singular value, $\\lambda_2$). The directions with the larger $\\lambda_{1}$ relative to $\\lambda_{2}$ have been stretched. We also noticed that the T-cells and some NK cells have the more severe distortion, since their x-axis values can be much larger than their y-axis values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807b7b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distortions.visualization import eigenvalue_plot\n",
    "\n",
    "lambda_plot = eigenvalue_plot(\n",
    "    Hs, embedding[\"cell_type\"],\n",
    "    sort_order=[\"Monocytes\", \"NK\", \"T-cell\", \"Dendritic\", \"Plasma\", \"B-cell\", \"Other\"]\n",
    ").configure_axis(labelFontSize=12, titleFontSize=22)\\\n",
    " .configure_range(category=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd'])\n",
    "\n",
    "lambda_plot.save(f\"{save_dir}/pbmc_lambda_random.svg\")\n",
    "lambda_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9a70bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_mask = (Hs[:, 0] < 5) & (Hs[:, 1] < 2.5)\n",
    "Hs_zoom = Hs[compression_mask]\n",
    "cell_types_zoom = embedding[\"cell_type\"].iloc[compression_mask]\n",
    "\n",
    "lambda_plot_zoom = eigenvalue_plot(\n",
    "    Hs_zoom, cell_types_zoom,\n",
    "    sort_order=[\"Monocytes\", \"NK\", \"T-cell\", \"Dendritic\", \"Plasma\", \"B-cell\", \"Other\"]\n",
    ").configure_axis(labelFontSize=12, titleFontSize=22)\\\n",
    " .configure_range(category=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd'])\n",
    "\n",
    "lambda_plot_zoom.save(f\"{save_dir}/pbmc_lambda_zoom_random.svg\")\n",
    "lambda_plot_zoom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507e4e50",
   "metadata": {},
   "source": [
    "## Interactive Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15c4e8c",
   "metadata": {},
   "source": [
    "Now we're ready to make some interactive visualizations. Our first looks for fragmented neighborhoods. These neighborhoods are centered around cells that have a large fraction of neighbors that are placed very far away in the embedding space relative to their true distances in gene expression space. The intuition is that algorithms like UMAP, and $t$-SNE are known to \"tear\" the data.  In extreme cases, cells that might have been not that far apart in their gene expression patterns can be placed on opposite sides of the visualization.  This phenomenon is relatively well documented theoretically as well -- nonlinear dimensionality reduction sometimes resorts to introducing discontinuities in order to achieve their overall embedding objective.\n",
    "\n",
    "In the block below, the object `N` and is just a dictionary where the keys are the centers of the distorted neighborhoods and the values are the 50 nearest neighbors to that center cell. We interactively visualize these neighborhoods, using the `dplot` code. The layering syntax should feel familiar to ggplot2 or altair users (granted with much less functionality). The mapping object takes columns of the input `DataFrame` to the graphical properties in the marks below.  The `inter_edge_link` command, add interactivity so that when we place our mouse close to one of the fragmented neighborhoods, we see edges emanating to all their neighbors. The fragmented neighborhoods themselves are highlighted with a thick border. The threshold argument controls how close the mouse needs to be before the links are drawn, and strokeWidth gives the associated line width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82d4e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distortions.geometry import neighborhoods\n",
    "from distortions.visualization import dplot\n",
    "\n",
    "N = neighborhoods(adata, threshold=.2, outlier_factor=3)\n",
    "plots = {}\n",
    "plots[\"pbmc_links\"] = dplot(embedding, width=440, height=340)\\\n",
    "    .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\\n",
    "    .geom_ellipse(radiusMax=15, radiusMin=1)\\\n",
    "    .inter_edge_link(N=N, threshold=.1, strokeWidth=0.4)\\\n",
    "    .scale_color(legendTextSize=15)\\\n",
    "    .labs(x=\"UMAP 1\", y=\"UMAP 2\")\n",
    "plots[\"pbmc_links\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110f4394",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plots[\"pbmc_links\"].save(f\"{save_dir}/pbmc_links.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dfe602",
   "metadata": {},
   "source": [
    "Unfortunately, the way these notebooks are hosted, you won't be able to directly interact with the output from the call, even though if you were following along in your own notebook, the output should be interactive. We've copied a small recording of our interacting with this visualization in case you just want to have an idea of what this package gives without running it yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b751c4",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/krisrs1128/distortions-data/main/figures/pbmc_fragments.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619d1aa4",
   "metadata": {},
   "source": [
    "Our next interactive plot compares the embedding versus original expression distances. Instead of flagging entire neighborhoods that have been fragmented, it can be used to find individual links that are poorly preserved in the embedding compared to the original data. We accomplish this by extracting the distance between neighbors and the original and embedding spaces with the `neighborhood_distances` function and then passing that to `inter_boxplot` layer. You can now drag a brush over the boxplot widget, and it will highlight the neighboring pairs that lie under the brush. For example, when we draw our brush over the top points above the leftmost box, we're highlighting, neighbors that are very close to one another in expression space but which have been placed far apart in the embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ccc58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distortions.geometry import neighborhood_distances\n",
    "\n",
    "dists = neighborhood_distances(adata)\n",
    "plots[\"pbmc_boxplot\"] = dplot(embedding, width=540, height=340)\\\n",
    "    .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\\n",
    "    .geom_ellipse(radiusMax=15, radiusMin=1)\\\n",
    "    .inter_boxplot(dists=dists, strokeWidth=0.4, legendOffset=100)\\\n",
    "    .labs(x=\"UMAP 1\", y=\"UMAP 2\")\n",
    "plots[\"pbmc_boxplot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b91acc",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/krisrs1128/distortions-data/main/figures/pbmc_boxplot.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f4bbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plots[\"pbmc_boxplot\"].save(f\"{save_dir}/pbmc_boxplot.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7d2f6f",
   "metadata": {},
   "source": [
    "Next let's apply our isometrization function. This allows us to reverse the distortion locally around query regions. Formally it applies the inverse of the distortion metrics `H` that were estimated above. The intuition is that this serves as a kind of compromise. Even though we can't ensure that our overall visualization is an isometry, we can at least try to achieve isometries locally around an area of interest. We have set a few hyperparameters here -- they are explained in a bit more detail in the blocks below. For example, we can see that many of the T cells are quite eccentric (this is consistent with the singular values scatterplot above). When we hover over them, they are compressed to be more circular. The directions of dilation have been compressed slightly so that the artificial spread introduced by the inventing algorithm is removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd757c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {k: H[k] for k in range(len(H))}\n",
    "plots[\"pbmc_isometry\"] = dplot(embedding, width=440, height=340)\\\n",
    "    .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\\n",
    "    .geom_ellipse(radiusMin=.7, radiusMax=8)\\\n",
    "    .inter_isometry(metrics=metrics, metric_bw=0.5, transformation_bw=0.2, strokeWidth=0.2)\\\n",
    "    .scale_color(legendTextSize=8)\\\n",
    "    .labs(x=\"UMAP 1\", y=\"UMAP 2\")\n",
    "plots[\"pbmc_isometry\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cfd7a4",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/krisrs1128/distortions-data/main/figures/pbmc_isometry.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b432e30",
   "metadata": {},
   "source": [
    "The metric and transformation bandwidth (`bw`) parameters set in the above visualization are necessary to formalize the isomerization step. The metric bandwidth parameter determines how many of the neighboring ellipses should be used when learning the inverse transformation. Smaller values mean that more neighbors can contribute to the inverse. This can make the output, more stable, but has the downside that it averages over metrics that might not actually be that similar to ones near the mouse. The transformation bandwidth parameter controls how much of a plot gets changed whenever we move our mouse. It can be a bit unwieldy to transform all samples in the plot just to see the isometric embedding within the region of interest. The two plots below highlight the similar ellipses according to both parameters as we move on us over the plot -- similar points appear in black."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba9ad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots[\"pbmc_transform\"] = dplot(embedding, width=440, height=340)\\\n",
    "    .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"kernel_transform\")\\\n",
    "    .geom_ellipse(radiusMin=.7, radiusMax=8)\\\n",
    "    .inter_isometry(metrics=metrics, metric_bw=1, transformation_bw=0.2, strokeWidth=0.2)\\\n",
    "    .scale_color(legendTextSize=8)\\\n",
    "    .labs(x=\"UMAP 1\", y=\"UMAP 2\")\n",
    "\n",
    "plots[\"pbmc_metric\"] = dplot(embedding, width=440, height=340)\\\n",
    "    .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"kernel_metric\")\\\n",
    "    .geom_ellipse(radiusMin=.7, radiusMax=8)\\\n",
    "    .inter_isometry(metrics=metrics, metric_bw=1, transformation_bw=0.2, strokeWidth=0.2)\\\n",
    "    .scale_color(legendTextSize=8)\\\n",
    "    .labs(x=\"UMAP 1\", y=\"UMAP 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dd1019",
   "metadata": {},
   "source": [
    "The block below appears only so that we can save the state of our interactive plots into an SVG file. This is how we got the plots for our paper. You can read more about saving SVGs from the output of the distortion package by reading the \"Saving Interactions as SVG \" tutorial on this site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e5afe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[p.save(f\"{save_dir}/{k}.svg\") for k, p in plots.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1260fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "[display(p) for p in plots.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8b7525",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dist2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
