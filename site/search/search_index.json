{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Distortions","text":"<p>The <code>distortions</code> package gives functions to compute and visualize the distortions that are introduced by nonlinear dimensionality reduction algorithms. It is designed to wrap arbitrary embedding methods and builds on the distortion estimation routines from the <code>megaman</code> package.  The resulting visualizations visualizations can let you interactively query properties that are not well preserved by the embedding. For example, the image below shows us selecting distances that are larger in the embedding space compared to the original data space (to run this yourself, see the <code>PBMC Atlas</code> article).</p> <p></p>"},{"location":"index.html#installation","title":"Installation","text":"<p>You can install the package using:</p> <pre><code>python -m pip install distortions\n</code></pre>"},{"location":"index.html#help","title":"Help","text":"<p>You can reach us by creating an Issue in the package repository or sending an email to ksankaran@wisc.edu. We appreciate your trying out the package and will try our best to reply promptly.</p>"},{"location":"reference/api.html","title":"Function Reference","text":""},{"location":"reference/api.html#api-reference","title":"API Reference","text":""},{"location":"reference/api.html#distortionsgeometry","title":"<code>distortions.geometry</code>","text":""},{"location":"reference/api.html#distortions.geometry.Geometry","title":"<code>Geometry</code>","text":"<p>               Bases: <code>object</code></p> <p>The Geometry class stores the data, distance, affinity and laplacian matrices used by the various embedding methods and is the primary object passed to embedding functions.</p> <p>The Geometry class contains functions to compute the aforementioned matrices and allows for re-computation whenever necessary.</p> <p>Parameters:</p> Name Type Description Default <code>adjacency_method</code> <code>string {'auto', 'brute', 'pyflann', 'cyflann'}</code> <p>method for computing pairwise radius neighbors graph.</p> <code>'auto'</code> <code>adjacency_kwds</code> <code>dict</code> <p>dictionary containing keyword arguments for adjacency matrix. see distance.py docmuentation for arguments for each method. If new kwargs are passed to compute_adjacency_matrix then this dictionary will be updated.</p> <code>None</code> <code>affinity_method</code> <code>string {'auto', 'gaussian'}</code> <p>method of computing affinity matrix</p> <code>'auto'</code> <code>affinity_kwds</code> <code>dict</code> <p>dictionary containing keyword arguments for affinity matrix. see affinity.py documentation for arguments for each method. If new kwargs are passed to compute_affinity_matrix then this dictionary will be updated.</p> <code>None</code> <code>laplacian_method</code> <code>(string,)</code> <p>type of laplacian to be computed. Possibilities are {'symmetricnormalized', 'geometric', 'renormalized', 'unnormalized', 'randomwalk'} see laplacian.py for more information.</p> <code>'auto'</code> <code>laplacian_kwds</code> <code>dice</code> <p>dictionary containing keyword arguments for Laplacian matrix. see laplacian.py docmuentation for arguments for each method. If new kwargs are passed to compute_laplacian_matrix then this dictionary will be updated.</p> <code>None</code> <code>**kwargs</code> <p>additional arguments will be parsed and used to override values in the above dictionaries. For example: - <code>affinity_radius</code> will override <code>affinity_kwds['radius']</code> - <code>adjacency_n_neighbors</code> will override <code>adjacency_kwds['n_neighbors']</code> etc.</p> <code>{}</code> Source code in <code>distortions/geometry/geometry.py</code> <pre><code>class Geometry(object):\n    \"\"\"\n    The Geometry class stores the data, distance, affinity and laplacian\n    matrices used by the various embedding methods and is the primary\n    object passed to embedding functions.\n\n    The Geometry class contains functions to compute the aforementioned\n    matrices and allows for re-computation whenever necessary.\n\n    Parameters\n    ----------\n    adjacency_method : string {'auto', 'brute', 'pyflann', 'cyflann'}\n        method for computing pairwise radius neighbors graph.\n    adjacency_kwds : dict\n        dictionary containing keyword arguments for adjacency matrix.\n        see distance.py docmuentation for arguments for each method.\n        If new kwargs are passed to compute_adjacency_matrix then this\n        dictionary will be updated.\n    affinity_method : string {'auto', 'gaussian'}\n        method of computing affinity matrix\n    affinity_kwds : dict\n        dictionary containing keyword arguments for affinity matrix.\n        see affinity.py documentation for arguments for each method.\n        If new kwargs are passed to compute_affinity_matrix then this\n        dictionary will be updated.\n    laplacian_method : string,\n        type of laplacian to be computed. Possibilities are\n        {'symmetricnormalized', 'geometric', 'renormalized',\n        'unnormalized', 'randomwalk'} see laplacian.py for more information.\n    laplacian_kwds : dice\n        dictionary containing keyword arguments for Laplacian matrix.\n        see laplacian.py docmuentation for arguments for each method.\n        If new kwargs are passed to compute_laplacian_matrix then this\n        dictionary will be updated.\n    **kwargs :\n        additional arguments will be parsed and used to override values in\n        the above dictionaries. For example:\n        - `affinity_radius` will override `affinity_kwds['radius']`\n        - `adjacency_n_neighbors` will override `adjacency_kwds['n_neighbors']`\n        etc.\n    \"\"\"\n    def __init__(self, adjacency_method='auto', adjacency_kwds=None,\n                 affinity_method='auto', affinity_kwds=None,\n                 laplacian_method='auto',laplacian_kwds=None, **kwargs):\n        self.adjacency_method = adjacency_method\n        self.adjacency_kwds = dict(**(adjacency_kwds or {}))\n        self.affinity_method = affinity_method\n        self.affinity_kwds = dict(**(affinity_kwds or {}))\n        self.laplacian_method = laplacian_method\n        self.laplacian_kwds = dict(**(laplacian_kwds or {}))\n\n        # map extra keywords: e.g. affinity_radius -&gt; affinity_kwds['radius']\n        dicts = dict(adjaceny=self.adjacency_kwds,\n                     affinity=self.affinity_kwds,\n                     laplacian=self.laplacian_kwds)\n        for key, val in kwargs.items():\n            keysplit = key.split('_')\n            if keysplit[0] not in dicts:\n                raise ValueError('key `{0}` not valid'.format(key))\n            dicts[keysplit[0]]['_'.join(keysplit[1:])] = val\n\n        self.X = None\n        self.adjacency_matrix = None\n        self.affinity_matrix = None\n        self.laplacian_matrix = None\n        self.laplacian_symmetric = None\n        self.laplacian_weights = None\n\n    def set_radius(self, radius, override=True, X=None, n_components=2):\n        \"\"\"Set the radius for the adjacency and affinity computation\n\n        By default, this will override keyword arguments provided on\n        initialization.\n\n        Parameters\n        ----------\n        radius : float\n            radius to set for adjacency and affinity.\n        override : bool (default: True)\n            if False, then only set radius if not already defined in\n            `adjacency_args` and `affinity_args`.\n        X : ndarray or sparse (optional)\n            if provided, estimate a suitable radius from this data.\n        n_components : int (default=2)\n            the number of components to use when estimating the radius\n        \"\"\"\n        if radius &lt; 0:\n            raise ValueError(\"radius must be non-negative\")\n\n        if override or ('radius' not in self.adjacency_kwds and\n                        'n_neighbors' not in self.adjacency_kwds):\n            self.adjacency_kwds['radius'] = radius\n\n        if override or ('radius' not in self.affinity_kwds):\n            self.affinity_kwds['radius'] = radius\n\n    def set_matrix(self, X, input_type):\n        \"\"\"\n        Set the data matrix given the input type.\n\n        Parameters\n        ----------\n        X : array-like\n            Input matrix to set.\n        input_type : str\n            Type of matrix to set. Options: {'data', 'adjacency', 'affinity'}\n        \"\"\"\n        if input_type == 'data':\n            self.set_data_matrix(X)\n        elif input_type == 'adjacency':\n            self.set_adjacency_matrix(X)\n        elif input_type == 'affinity':\n            self.set_affinity_matrix(X)\n        else:\n            raise ValueError(\"Unrecognized input_type: {0}\".format(input_type))\n\n\n    def compute_adjacency_matrix(self, copy=False, **kwargs):\n        \"\"\"\n        This function will compute the adjacency matrix.\n        In order to acquire the existing adjacency matrix use\n        self.adjacency_matrix as comptute_adjacency_matrix() will re-compute\n        the adjacency matrix.\n\n        Parameters\n        ----------\n        copy : boolean, whether to return a copied version of the adjacency matrix\n        **kwargs : see distance.py docmuentation for arguments for each method.\n\n        Returns\n        -------\n        self.adjacency_matrix : sparse matrix (N_obs, N_obs)\n            Non explicit 0.0 values should be considered not connected.\n        \"\"\"\n        if self.X is None:\n            raise ValueError(distance_error_msg)\n\n        kwds = self.adjacency_kwds.copy()\n        kwds.update(kwargs)\n        self.adjacency_matrix = compute_adjacency_matrix(self.X,\n                                                         self.adjacency_method,\n                                                         **kwds)\n        if copy:\n            return self.adjacency_matrix.copy()\n        else:\n            return self.adjacency_matrix\n\n    def compute_affinity_matrix(self, copy=False, **kwargs):\n        \"\"\"\n        This function will compute the affinity matrix. In order to\n        acquire the existing affinity matrix use self.affinity_matrix as\n        comptute_affinity_matrix() will re-compute the affinity matrix.\n\n        Parameters\n        ----------\n        copy : boolean\n            whether to return a copied version of the affinity matrix\n        **kwargs :\n            see affinity.py docmuentation for arguments for each method.\n\n        Returns\n        -------\n        self.affinity_matrix : sparse matrix (N_obs, N_obs)\n            contains the pairwise affinity values using the Guassian kernel\n            and bandwidth equal to the affinity_radius\n        \"\"\"\n        if self.adjacency_matrix is None:\n            self.compute_adjacency_matrix()\n\n        kwds = self.affinity_kwds.copy()\n        kwds.update(kwargs)\n        self.affinity_matrix = compute_affinity_matrix(self.adjacency_matrix,\n                                                       self.affinity_method,\n                                                       **kwds)\n        if copy:\n            return self.affinity_matrix.copy()\n        else:\n            return self.affinity_matrix\n\n    def compute_laplacian_matrix(self, copy=True, return_lapsym=False, **kwargs):\n        \"\"\"\n        Note: this function will compute the laplacian matrix. In order to acquire\n            the existing laplacian matrix use self.laplacian_matrix as\n            compute_laplacian_matrix() will re-compute the laplacian matrix.\n\n        Parameters\n        ----------\n        copy : boolean, whether to return copied version of the self.laplacian_matrix\n        return_lapsym : boolean, if True returns additionally the symmetrized version of\n            the requested laplacian and the re-normalization weights.\n        **kwargs : see laplacian.py docmuentation for arguments for each method.\n\n        Returns\n        -------\n        self.laplacian_matrix : sparse matrix (N_obs, N_obs).\n            The requested laplacian.\n        self.laplacian_symmetric : sparse matrix (N_obs, N_obs)\n            The symmetric laplacian.\n        self.laplacian_weights : ndarray (N_obs,)\n            The renormalization weights used to make\n            laplacian_matrix from laplacian_symmetric\n        \"\"\"\n        if self.affinity_matrix is None:\n            self.compute_affinity_matrix()\n\n        kwds = self.laplacian_kwds.copy()\n        kwds.update(kwargs)\n        kwds['full_output'] = return_lapsym\n        result = compute_laplacian_matrix(self.affinity_matrix,\n                                          self.laplacian_method,\n                                          **kwds)\n        if return_lapsym:\n            (self.laplacian_matrix,\n             self.laplacian_symmetric,\n             self.laplacian_weights) = result\n        else:\n            self.laplacian_matrix = result\n\n        if copy:\n            return self.laplacian_matrix.copy()\n        else:\n            return self.laplacian_matrix\n\n    def set_data_matrix(self, X):\n        \"\"\"\n        Set the data matrix.\n\n        Parameters\n        ----------\n        X : array-like, shape (n_samples, n_features)\n            The original data set to input.\n        \"\"\"\n        #X = check_array(X, accept_sparse=sparse_formats)\n        self.X = X\n\n    def set_adjacency_matrix(self, adjacency_mat):\n        \"\"\"\n        Set the adjacency matrix.\n\n        Parameters\n        ----------\n        adjacency_mat : sparse matrix, shape (n_samples, n_samples)\n            The adjacency matrix to input.\n        \"\"\"\n        #adjacency_mat = check_array(adjacency_mat, accept_sparse=sparse_formats)\n        if adjacency_mat.shape[0] != adjacency_mat.shape[1]:\n            raise ValueError(\"adjacency matrix is not square\")\n        self.adjacency_matrix = adjacency_mat\n\n    def set_affinity_matrix(self, affinity_mat):\n        \"\"\"\n        Set the affinity matrix.\n\n        Parameters\n        ----------\n        affinity_mat : sparse matrix (N_obs, N_obs).\n            The adjacency matrix to input.\n        \"\"\"\n        #affinity_mat = check_array(affinity_mat, accept_sparse=sparse_formats)\n        if affinity_mat.shape[0] != affinity_mat.shape[1]:\n            raise ValueError(\"affinity matrix is not square\")\n        self.affinity_matrix = affinity_mat\n\n    def set_laplacian_matrix(self, laplacian_mat):\n        \"\"\"\n        Set the Laplacian matrix.\n\n        Parameters\n        ----------\n        laplacian_mat : sparse matrix (N_obs, N_obs).\n            The Laplacian matrix to input.\n        \"\"\"\n        #laplacian_mat = check_array(laplacian_mat, accept_sparse = sparse_formats)\n        if laplacian_mat.shape[0] != laplacian_mat.shape[1]:\n            raise ValueError(\"Laplacian matrix is not square\")\n        self.laplacian_matrix = laplacian_mat\n\n    def delete_data_matrix(self):\n        \"\"\"Delete the data matrix from the Geometry object.\"\"\"\n        self.X = None\n\n    def delete_adjacency_matrix(self):\n        \"\"\"Delete the adjacency matrix from the Geometry object.\"\"\"\n        self.adjacency_matrix = None\n\n    def delete_affinity_matrix(self):\n        \"\"\"Delete the affinity matrix from the Geometry object.\"\"\"\n        self.affinity_matrix = None\n\n    def delete_laplacian_matrix(self):\n        \"\"\"Delete the Laplacian matrix from the Geometry object.\"\"\"\n        self.laplacian_matrix = None\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.Geometry.compute_adjacency_matrix","title":"<code>compute_adjacency_matrix(copy=False, **kwargs)</code>","text":"<p>This function will compute the adjacency matrix. In order to acquire the existing adjacency matrix use self.adjacency_matrix as comptute_adjacency_matrix() will re-compute the adjacency matrix.</p> <p>Parameters:</p> Name Type Description Default <code>copy</code> <code>boolean, whether to return a copied version of the adjacency matrix</code> <code>False</code> <code>**kwargs</code> <code>see distance.py docmuentation for arguments for each method.</code> <code>{}</code> <p>Returns:</p> Type Description <code>self.adjacency_matrix : sparse matrix (N_obs, N_obs)</code> <p>Non explicit 0.0 values should be considered not connected.</p> Source code in <code>distortions/geometry/geometry.py</code> <pre><code>def compute_adjacency_matrix(self, copy=False, **kwargs):\n    \"\"\"\n    This function will compute the adjacency matrix.\n    In order to acquire the existing adjacency matrix use\n    self.adjacency_matrix as comptute_adjacency_matrix() will re-compute\n    the adjacency matrix.\n\n    Parameters\n    ----------\n    copy : boolean, whether to return a copied version of the adjacency matrix\n    **kwargs : see distance.py docmuentation for arguments for each method.\n\n    Returns\n    -------\n    self.adjacency_matrix : sparse matrix (N_obs, N_obs)\n        Non explicit 0.0 values should be considered not connected.\n    \"\"\"\n    if self.X is None:\n        raise ValueError(distance_error_msg)\n\n    kwds = self.adjacency_kwds.copy()\n    kwds.update(kwargs)\n    self.adjacency_matrix = compute_adjacency_matrix(self.X,\n                                                     self.adjacency_method,\n                                                     **kwds)\n    if copy:\n        return self.adjacency_matrix.copy()\n    else:\n        return self.adjacency_matrix\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.Geometry.compute_affinity_matrix","title":"<code>compute_affinity_matrix(copy=False, **kwargs)</code>","text":"<p>This function will compute the affinity matrix. In order to acquire the existing affinity matrix use self.affinity_matrix as comptute_affinity_matrix() will re-compute the affinity matrix.</p> <p>Parameters:</p> Name Type Description Default <code>copy</code> <code>boolean</code> <p>whether to return a copied version of the affinity matrix</p> <code>False</code> <code>**kwargs</code> <p>see affinity.py docmuentation for arguments for each method.</p> <code>{}</code> <p>Returns:</p> Type Description <code>self.affinity_matrix : sparse matrix (N_obs, N_obs)</code> <p>contains the pairwise affinity values using the Guassian kernel and bandwidth equal to the affinity_radius</p> Source code in <code>distortions/geometry/geometry.py</code> <pre><code>def compute_affinity_matrix(self, copy=False, **kwargs):\n    \"\"\"\n    This function will compute the affinity matrix. In order to\n    acquire the existing affinity matrix use self.affinity_matrix as\n    comptute_affinity_matrix() will re-compute the affinity matrix.\n\n    Parameters\n    ----------\n    copy : boolean\n        whether to return a copied version of the affinity matrix\n    **kwargs :\n        see affinity.py docmuentation for arguments for each method.\n\n    Returns\n    -------\n    self.affinity_matrix : sparse matrix (N_obs, N_obs)\n        contains the pairwise affinity values using the Guassian kernel\n        and bandwidth equal to the affinity_radius\n    \"\"\"\n    if self.adjacency_matrix is None:\n        self.compute_adjacency_matrix()\n\n    kwds = self.affinity_kwds.copy()\n    kwds.update(kwargs)\n    self.affinity_matrix = compute_affinity_matrix(self.adjacency_matrix,\n                                                   self.affinity_method,\n                                                   **kwds)\n    if copy:\n        return self.affinity_matrix.copy()\n    else:\n        return self.affinity_matrix\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.Geometry.compute_laplacian_matrix","title":"<code>compute_laplacian_matrix(copy=True, return_lapsym=False, **kwargs)</code>","text":"<p>Note: this function will compute the laplacian matrix. In order to acquire     the existing laplacian matrix use self.laplacian_matrix as     compute_laplacian_matrix() will re-compute the laplacian matrix.</p> <p>Parameters:</p> Name Type Description Default <code>copy</code> <code>boolean, whether to return copied version of the self.laplacian_matrix</code> <code>True</code> <code>return_lapsym</code> <code>boolean, if True returns additionally the symmetrized version of</code> <p>the requested laplacian and the re-normalization weights.</p> <code>False</code> <code>**kwargs</code> <code>see laplacian.py docmuentation for arguments for each method.</code> <code>{}</code> <p>Returns:</p> Type Description <code>self.laplacian_matrix : sparse matrix (N_obs, N_obs).</code> <p>The requested laplacian.</p> <code>self.laplacian_symmetric : sparse matrix (N_obs, N_obs)</code> <p>The symmetric laplacian.</p> <code>self.laplacian_weights : ndarray (N_obs,)</code> <p>The renormalization weights used to make laplacian_matrix from laplacian_symmetric</p> Source code in <code>distortions/geometry/geometry.py</code> <pre><code>def compute_laplacian_matrix(self, copy=True, return_lapsym=False, **kwargs):\n    \"\"\"\n    Note: this function will compute the laplacian matrix. In order to acquire\n        the existing laplacian matrix use self.laplacian_matrix as\n        compute_laplacian_matrix() will re-compute the laplacian matrix.\n\n    Parameters\n    ----------\n    copy : boolean, whether to return copied version of the self.laplacian_matrix\n    return_lapsym : boolean, if True returns additionally the symmetrized version of\n        the requested laplacian and the re-normalization weights.\n    **kwargs : see laplacian.py docmuentation for arguments for each method.\n\n    Returns\n    -------\n    self.laplacian_matrix : sparse matrix (N_obs, N_obs).\n        The requested laplacian.\n    self.laplacian_symmetric : sparse matrix (N_obs, N_obs)\n        The symmetric laplacian.\n    self.laplacian_weights : ndarray (N_obs,)\n        The renormalization weights used to make\n        laplacian_matrix from laplacian_symmetric\n    \"\"\"\n    if self.affinity_matrix is None:\n        self.compute_affinity_matrix()\n\n    kwds = self.laplacian_kwds.copy()\n    kwds.update(kwargs)\n    kwds['full_output'] = return_lapsym\n    result = compute_laplacian_matrix(self.affinity_matrix,\n                                      self.laplacian_method,\n                                      **kwds)\n    if return_lapsym:\n        (self.laplacian_matrix,\n         self.laplacian_symmetric,\n         self.laplacian_weights) = result\n    else:\n        self.laplacian_matrix = result\n\n    if copy:\n        return self.laplacian_matrix.copy()\n    else:\n        return self.laplacian_matrix\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.Geometry.delete_adjacency_matrix","title":"<code>delete_adjacency_matrix()</code>","text":"<p>Delete the adjacency matrix from the Geometry object.</p> Source code in <code>distortions/geometry/geometry.py</code> <pre><code>def delete_adjacency_matrix(self):\n    \"\"\"Delete the adjacency matrix from the Geometry object.\"\"\"\n    self.adjacency_matrix = None\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.Geometry.delete_affinity_matrix","title":"<code>delete_affinity_matrix()</code>","text":"<p>Delete the affinity matrix from the Geometry object.</p> Source code in <code>distortions/geometry/geometry.py</code> <pre><code>def delete_affinity_matrix(self):\n    \"\"\"Delete the affinity matrix from the Geometry object.\"\"\"\n    self.affinity_matrix = None\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.Geometry.delete_data_matrix","title":"<code>delete_data_matrix()</code>","text":"<p>Delete the data matrix from the Geometry object.</p> Source code in <code>distortions/geometry/geometry.py</code> <pre><code>def delete_data_matrix(self):\n    \"\"\"Delete the data matrix from the Geometry object.\"\"\"\n    self.X = None\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.Geometry.delete_laplacian_matrix","title":"<code>delete_laplacian_matrix()</code>","text":"<p>Delete the Laplacian matrix from the Geometry object.</p> Source code in <code>distortions/geometry/geometry.py</code> <pre><code>def delete_laplacian_matrix(self):\n    \"\"\"Delete the Laplacian matrix from the Geometry object.\"\"\"\n    self.laplacian_matrix = None\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.Geometry.set_adjacency_matrix","title":"<code>set_adjacency_matrix(adjacency_mat)</code>","text":"<p>Set the adjacency matrix.</p> <p>Parameters:</p> Name Type Description Default <code>adjacency_mat</code> <code>sparse matrix, shape (n_samples, n_samples)</code> <p>The adjacency matrix to input.</p> required Source code in <code>distortions/geometry/geometry.py</code> <pre><code>def set_adjacency_matrix(self, adjacency_mat):\n    \"\"\"\n    Set the adjacency matrix.\n\n    Parameters\n    ----------\n    adjacency_mat : sparse matrix, shape (n_samples, n_samples)\n        The adjacency matrix to input.\n    \"\"\"\n    #adjacency_mat = check_array(adjacency_mat, accept_sparse=sparse_formats)\n    if adjacency_mat.shape[0] != adjacency_mat.shape[1]:\n        raise ValueError(\"adjacency matrix is not square\")\n    self.adjacency_matrix = adjacency_mat\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.Geometry.set_affinity_matrix","title":"<code>set_affinity_matrix(affinity_mat)</code>","text":"<p>Set the affinity matrix.</p> <p>Parameters:</p> Name Type Description Default <code>affinity_mat</code> <code>sparse matrix (N_obs, N_obs).</code> <p>The adjacency matrix to input.</p> required Source code in <code>distortions/geometry/geometry.py</code> <pre><code>def set_affinity_matrix(self, affinity_mat):\n    \"\"\"\n    Set the affinity matrix.\n\n    Parameters\n    ----------\n    affinity_mat : sparse matrix (N_obs, N_obs).\n        The adjacency matrix to input.\n    \"\"\"\n    #affinity_mat = check_array(affinity_mat, accept_sparse=sparse_formats)\n    if affinity_mat.shape[0] != affinity_mat.shape[1]:\n        raise ValueError(\"affinity matrix is not square\")\n    self.affinity_matrix = affinity_mat\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.Geometry.set_data_matrix","title":"<code>set_data_matrix(X)</code>","text":"<p>Set the data matrix.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>(array - like, shape(n_samples, n_features))</code> <p>The original data set to input.</p> required Source code in <code>distortions/geometry/geometry.py</code> <pre><code>def set_data_matrix(self, X):\n    \"\"\"\n    Set the data matrix.\n\n    Parameters\n    ----------\n    X : array-like, shape (n_samples, n_features)\n        The original data set to input.\n    \"\"\"\n    #X = check_array(X, accept_sparse=sparse_formats)\n    self.X = X\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.Geometry.set_laplacian_matrix","title":"<code>set_laplacian_matrix(laplacian_mat)</code>","text":"<p>Set the Laplacian matrix.</p> <p>Parameters:</p> Name Type Description Default <code>laplacian_mat</code> <code>sparse matrix (N_obs, N_obs).</code> <p>The Laplacian matrix to input.</p> required Source code in <code>distortions/geometry/geometry.py</code> <pre><code>def set_laplacian_matrix(self, laplacian_mat):\n    \"\"\"\n    Set the Laplacian matrix.\n\n    Parameters\n    ----------\n    laplacian_mat : sparse matrix (N_obs, N_obs).\n        The Laplacian matrix to input.\n    \"\"\"\n    #laplacian_mat = check_array(laplacian_mat, accept_sparse = sparse_formats)\n    if laplacian_mat.shape[0] != laplacian_mat.shape[1]:\n        raise ValueError(\"Laplacian matrix is not square\")\n    self.laplacian_matrix = laplacian_mat\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.Geometry.set_matrix","title":"<code>set_matrix(X, input_type)</code>","text":"<p>Set the data matrix given the input type.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array - like</code> <p>Input matrix to set.</p> required <code>input_type</code> <code>str</code> <p>Type of matrix to set. Options: {'data', 'adjacency', 'affinity'}</p> required Source code in <code>distortions/geometry/geometry.py</code> <pre><code>def set_matrix(self, X, input_type):\n    \"\"\"\n    Set the data matrix given the input type.\n\n    Parameters\n    ----------\n    X : array-like\n        Input matrix to set.\n    input_type : str\n        Type of matrix to set. Options: {'data', 'adjacency', 'affinity'}\n    \"\"\"\n    if input_type == 'data':\n        self.set_data_matrix(X)\n    elif input_type == 'adjacency':\n        self.set_adjacency_matrix(X)\n    elif input_type == 'affinity':\n        self.set_affinity_matrix(X)\n    else:\n        raise ValueError(\"Unrecognized input_type: {0}\".format(input_type))\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.Geometry.set_radius","title":"<code>set_radius(radius, override=True, X=None, n_components=2)</code>","text":"<p>Set the radius for the adjacency and affinity computation</p> <p>By default, this will override keyword arguments provided on initialization.</p> <p>Parameters:</p> Name Type Description Default <code>radius</code> <code>float</code> <p>radius to set for adjacency and affinity.</p> required <code>override</code> <code>bool (default: True)</code> <p>if False, then only set radius if not already defined in <code>adjacency_args</code> and <code>affinity_args</code>.</p> <code>True</code> <code>X</code> <code>ndarray or sparse(optional)</code> <p>if provided, estimate a suitable radius from this data.</p> <code>None</code> <code>n_components</code> <code>int(default=2)</code> <p>the number of components to use when estimating the radius</p> <code>2</code> Source code in <code>distortions/geometry/geometry.py</code> <pre><code>def set_radius(self, radius, override=True, X=None, n_components=2):\n    \"\"\"Set the radius for the adjacency and affinity computation\n\n    By default, this will override keyword arguments provided on\n    initialization.\n\n    Parameters\n    ----------\n    radius : float\n        radius to set for adjacency and affinity.\n    override : bool (default: True)\n        if False, then only set radius if not already defined in\n        `adjacency_args` and `affinity_args`.\n    X : ndarray or sparse (optional)\n        if provided, estimate a suitable radius from this data.\n    n_components : int (default=2)\n        the number of components to use when estimating the radius\n    \"\"\"\n    if radius &lt; 0:\n        raise ValueError(\"radius must be non-negative\")\n\n    if override or ('radius' not in self.adjacency_kwds and\n                    'n_neighbors' not in self.adjacency_kwds):\n        self.adjacency_kwds['radius'] = radius\n\n    if override or ('radius' not in self.affinity_kwds):\n        self.affinity_kwds['radius'] = radius\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.bind_metric","title":"<code>bind_metric(embedding, Hvv, Hs)</code>","text":"<p>Combine embedding coordinates with local Riemannian metric information.</p> <p>Parameters:</p> Name Type Description Default <code>embedding</code> <code>(ndarray, shape(n_samples, n_embedding_dims))</code> <p>The low-dimensional embedding of the data. This should be the same array as the <code>embedding</code> argument passed to <code>local_distortions</code>.</p> required <code>Hvv</code> <code>(ndarray, shape(n_samples, n_embedding_dims, n_embedding_dims))</code> <p>The singular vectors of the dual Riemannian metric tensor for each sample, as returned by <code>local_distortions</code>.</p> required <code>Hs</code> <code>(ndarray, shape(n_samples, n_embedding_dims))</code> <p>The singular values of the dual Riemannian metric tensor for each sample, as returned by <code>local_distortions</code>.</p> required <p>Returns:</p> Name Type Description <code>combined</code> <code>DataFrame</code> <p>A DataFrame containing the embedding coordinates, the singular vectors and singular values of the local dual Riemannian metric for each sample, and an additional column \"angle\" computed from the first two singular vector components.</p> Notes <p>This function is intended to facilitate analysis and visualization by merging the embedding and local metric information into a single tabular structure.</p> Source code in <code>distortions/geometry/rmetric.py</code> <pre><code>def bind_metric(embedding, Hvv, Hs):\n    \"\"\"\n    Combine embedding coordinates with local Riemannian metric information.\n\n    Parameters\n    ----------\n    embedding : np.ndarray, shape (n_samples, n_embedding_dims)\n        The low-dimensional embedding of the data. This should be the same array\n        as the `embedding` argument passed to `local_distortions`.\n    Hvv : np.ndarray, shape (n_samples, n_embedding_dims, n_embedding_dims)\n        The singular vectors of the dual Riemannian metric tensor for each sample,\n        as returned by `local_distortions`.\n    Hs : np.ndarray, shape (n_samples, n_embedding_dims)\n        The singular values of the dual Riemannian metric tensor for each sample,\n        as returned by `local_distortions`.\n\n    Returns\n    -------\n    combined : pd.DataFrame\n        A DataFrame containing the embedding coordinates, the singular vectors and\n        singular values of the local dual Riemannian metric for each sample, and\n        an additional column \"angle\" computed from the first two singular vector\n        components.\n\n    Notes\n    -----\n    This function is intended to facilitate analysis and visualization by merging\n    the embedding and local metric information into a single tabular structure.\n    \"\"\"\n    K = embedding.shape[1]\n    Hvv_df = pd.concat([arrays_to_df(Hvv), arrays_to_df(Hs)], axis=1)\n    embedding_df = pd.DataFrame(embedding, columns=[f\"embedding_{i}\" for i in range(K)])\n    embedding_df = embedding_df.reset_index(drop=True)\n    Hvv_df = Hvv_df.reset_index(drop=True)\n\n    # merge the embedding and metric data\n    combined = pd.concat([embedding_df, Hvv_df], axis=1)\n    metric_columns = sum([[f\"x{i}\", f\"y{i}\"] for i in range(K)], []) + [f\"s{i}\" for i in range(K)]\n    combined.columns = list(embedding_df.columns) + metric_columns\n    combined[\"angle\"] = np.arctan(combined.y1 / combined.x1) * (180 / np.pi)\n    return combined\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.boxplot_data","title":"<code>boxplot_data(x, y, nbin=10, outlier_iqr=3, **kwargs)</code>","text":"<p>Compute boxplot statistics and identify outliers within distance bins.</p> <p>This function divides the x-values (typically true distances) into bins and computes boxplot statistics for the y-values (typically embedding distances) within each bin. It identifies outliers using the IQR method.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array - like</code> <p>Input values used for binning (typically true/original distances).</p> required <code>y</code> <code>array - like</code> <p>Target values for which to compute statistics (typically embedding distances).</p> required <code>nbin</code> <code>int</code> <p>Number of bins to divide the x-value range into.</p> <code>10</code> <code>outlier_iqr</code> <code>float</code> <p>IQR multiplier for outlier detection. Values beyond Q1 - outlier_iqrIQR or Q3 + outlier_iqrIQR within each bin are considered outliers.</p> <code>3</code> <code>**kwargs</code> <code>keyword arguments</code> <p>Additional keyword arguments (currently unused).</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>summaries</code> <code>DataFrame</code> <p>DataFrame with boxplot statistics for each bin containing columns: - 'bin_id': bin identifier - 'q1', 'q2', 'q3': quartile values - 'min', 'max': minimum and maximum values - 'iqr': interquartile range - 'lower', 'upper': outlier detection bounds - 'bin': string representation of bin range</p> <code>outliers</code> <code>DataFrame</code> <p>DataFrame with outlier information containing columns: - 'index': original index of outlier point - 'bin_id': which bin the outlier belongs to - 'bin': string representation of bin range - 'value': the outlier y-value</p> Source code in <code>distortions/geometry/neighborhoods.py</code> <pre><code>def boxplot_data(x, y, nbin=10, outlier_iqr=3, **kwargs):\n    \"\"\"\n    Compute boxplot statistics and identify outliers within distance bins.\n\n    This function divides the x-values (typically true distances) into bins and\n    computes boxplot statistics for the y-values (typically embedding distances)\n    within each bin. It identifies outliers using the IQR method.\n\n    Parameters\n    ----------\n    x : array-like\n        Input values used for binning (typically true/original distances).\n    y : array-like\n        Target values for which to compute statistics (typically embedding distances).\n    nbin : int, default=10\n        Number of bins to divide the x-value range into.\n    outlier_iqr : float, default=3\n        IQR multiplier for outlier detection. Values beyond Q1 - outlier_iqr*IQR\n        or Q3 + outlier_iqr*IQR within each bin are considered outliers.\n    **kwargs : keyword arguments\n        Additional keyword arguments (currently unused).\n\n    Returns\n    -------\n    summaries : pd.DataFrame\n        DataFrame with boxplot statistics for each bin containing columns:\n        - 'bin_id': bin identifier\n        - 'q1', 'q2', 'q3': quartile values\n        - 'min', 'max': minimum and maximum values\n        - 'iqr': interquartile range\n        - 'lower', 'upper': outlier detection bounds\n        - 'bin': string representation of bin range\n    outliers : pd.DataFrame  \n        DataFrame with outlier information containing columns:\n        - 'index': original index of outlier point\n        - 'bin_id': which bin the outlier belongs to\n        - 'bin': string representation of bin range\n        - 'value': the outlier y-value\n    \"\"\"\n    # divide the data into nbin groups, and compute quantiles in each\n    bin_ids, bin_edges = pd.cut(x, bins=nbin, labels=False, retbins=True)\n    bin_edges = np.round(bin_edges, 1)\n\n    summaries = (\n        pd.DataFrame({'bin_id': bin_ids, 'y': y})\n        .groupby('bin_id', as_index=False)['y']\n        .agg(q1=lambda v: np.percentile(v, 25),\n             q2=lambda v: np.percentile(v, 50),\n             q3=lambda v: np.percentile(v, 75),\n             min='min', max='max')\n    )\n    summaries['iqr'] = summaries.q3 - summaries.q1\n    summaries['lower'] = np.maximum(summaries.q2 - outlier_iqr * summaries.iqr, summaries['min'])\n    summaries['upper'] = np.minimum(summaries.q2 + outlier_iqr * summaries.iqr, summaries['max'])\n    summaries['bin'] = summaries['bin_id'].map(lambda b: f\"{bin_edges[b]}-{bin_edges[b + 1]}\")\n\n    # compute outliers according to the IQR above\n    outliers = [\n        {\"index\": i, \"bin_id\": int(b), \"bin\": f\"{bin_edges[b]}-{bin_edges[b + 1]}\", \"value\": val}\n        for i, (b, val) in enumerate(zip(bin_ids, y))\n        if not np.isnan(b) and (\n            val &lt; summaries.loc[b, 'q1'] - outlier_iqr * summaries.loc[b, 'iqr'] or\n            val &gt; summaries.loc[b, 'q3'] + outlier_iqr * summaries.loc[b, 'iqr']\n        )\n    ]\n    return summaries, pd.DataFrame(outliers)\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.local_distortions","title":"<code>local_distortions(embedding, data, geom)</code>","text":"<p>Compute local Riemannian metric distortions for each sample.</p> <p>Parameters:</p> Name Type Description Default <code>embedding</code> <code>(ndarray, shape(n_samples, n_embedding_dims))</code> <p>Low-dimensional embedding of the data. Each row corresponds to a sample, and each column corresponds to an embedding dimension.</p> required <code>data</code> <code>(ndarray, shape(n_samples, n_features))</code> <p>Original high-dimensional data. Each row is a sample, each column a feature.</p> required <code>geom</code> <code>Geometry</code> <p>An instance of the Geometry class (from geometry.py) that provides methods for setting the data matrix and computing the Laplacian matrix.</p> required <p>Returns:</p> Name Type Description <code>H</code> <code>ndarray</code> <p>Dual Riemannian metric tensor for each sample.</p> <code>Hvv</code> <code>ndarray</code> <p>Singular vectors of the dual metric tensor for each sample.</p> <code>Hs</code> <code>ndarray</code> <p>Singular values of the dual metric tensor for each sample.</p> Notes <p>This function sets the data matrix in the provided Geometry object, computes the Laplacian matrix, and then estimates the local Riemannian metric distortions in the embedding space using the original data.</p> Source code in <code>distortions/geometry/rmetric.py</code> <pre><code>def local_distortions(embedding, data, geom):\n    \"\"\"\n    Compute local Riemannian metric distortions for each sample.\n\n    Parameters\n    ----------\n    embedding : np.ndarray, shape (n_samples, n_embedding_dims)\n        Low-dimensional embedding of the data. Each row corresponds to a sample,\n        and each column corresponds to an embedding dimension.\n    data : np.ndarray, shape (n_samples, n_features)\n        Original high-dimensional data. Each row is a sample, each column a feature.\n    geom : Geometry\n        An instance of the Geometry class (from geometry.py) that provides\n        methods for setting the data matrix and computing the Laplacian matrix.\n\n    Returns\n    -------\n    H : np.ndarray\n        Dual Riemannian metric tensor for each sample.\n    Hvv : np.ndarray\n        Singular vectors of the dual metric tensor for each sample.\n    Hs : np.ndarray\n        Singular values of the dual metric tensor for each sample.\n\n    Notes\n    -----\n    This function sets the data matrix in the provided Geometry object,\n    computes the Laplacian matrix, and then estimates the local Riemannian\n    metric distortions in the embedding space using the original data.\n    \"\"\"\n    geom.set_data_matrix(data)\n    L = geom.compute_laplacian_matrix()\n    _, _, Hvv, Hs, _, H = riemann_metric(embedding, L, n_dim=2)\n    return H, Hvv, Hs\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.neighborhood_distances","title":"<code>neighborhood_distances(adata, embed_key='X_umap')</code>","text":"<p>Compute pairwise distances between samples and their neighbors in both original and embedding spaces.</p> <p>This function calculates pairwise distances between each sample and its neighbors in the original high-dimensional space and compares them with distances in the reduced embedding space. This is useful for analyzing how well the embedding preserves local neighborhood structure.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>Annotated data matrix. Must contain a precomputed embedding (e.g., UMAP or t-SNE) in <code>obsm[embed_key]</code> and a neighbor graph in <code>obsp[\"distances\"]</code>.</p> required <code>embed_key</code> <code>str</code> <p>Key in <code>adata.obsm</code> where the embedding coordinates are stored.</p> <code>\"X_umap\"</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with columns:     - 'center': index of the sample (cell)     - 'neighbor': index of the neighbor sample     - 'true': distance in the original space (from <code>adata.obsp[\"distances\"]</code>)     - 'embedding': distance in the embedding space (from <code>adata.obsm[embed_key]</code>)</p> Notes <p>The number of neighbors is determined by the structure of the neighbor graph in <code>adata.obsp[\"distances\"]</code>. The function assumes that the embedding and neighbor graph have already been computed.</p> Source code in <code>distortions/geometry/neighborhoods.py</code> <pre><code>def neighborhood_distances(adata, embed_key=\"X_umap\"):\n    \"\"\"\n    Compute pairwise distances between samples and their neighbors in both original and embedding spaces.\n\n    This function calculates pairwise distances between each sample and its\n    neighbors in the original high-dimensional space and compares them with\n    distances in the reduced embedding space. This is useful for analyzing\n    how well the embedding preserves local neighborhood structure.\n\n    Parameters\n    ----------\n    adata : anndata.AnnData\n        Annotated data matrix. Must contain a precomputed embedding (e.g., UMAP or t-SNE) in `obsm[embed_key]`\n        and a neighbor graph in `obsp[\"distances\"]`.\n    embed_key : str, default=\"X_umap\"\n        Key in `adata.obsm` where the embedding coordinates are stored.\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame with columns:\n            - 'center': index of the sample (cell)\n            - 'neighbor': index of the neighbor sample\n            - 'true': distance in the original space (from `adata.obsp[\"distances\"]`)\n            - 'embedding': distance in the embedding space (from `adata.obsm[embed_key]`)\n\n    Notes\n    -----\n    The number of neighbors is determined by the structure of the neighbor graph in `adata.obsp[\"distances\"]`.\n    The function assumes that the embedding and neighbor graph have already been computed.\n    \"\"\"\n    knn_graph = adata.obsp[\"distances\"]\n    dist_list = []\n\n    for ix in range(len(adata)):\n        neighbors = knn_graph[ix].nonzero()[1]\n        true = knn_graph[ix, neighbors].toarray().flatten()\n        embedding = cdist(\n            [adata.obsm[embed_key][ix, :]], \n            adata.obsm[embed_key][neighbors, :]\n        ).flatten()\n        dist_list.append(pd.DataFrame({\n            \"center\": [ix] * len(neighbors), \n            \"neighbor\": neighbors,\n            \"true\": true,\n            \"embedding\": embedding\n        }))\n\n    return pd.concat(dist_list)\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.local_distortions","title":"<code>local_distortions(embedding, data, geom)</code>","text":"<p>Compute local Riemannian metric distortions for each sample.</p> <p>Parameters:</p> Name Type Description Default <code>embedding</code> <code>(ndarray, shape(n_samples, n_embedding_dims))</code> <p>Low-dimensional embedding of the data. Each row corresponds to a sample, and each column corresponds to an embedding dimension.</p> required <code>data</code> <code>(ndarray, shape(n_samples, n_features))</code> <p>Original high-dimensional data. Each row is a sample, each column a feature.</p> required <code>geom</code> <code>Geometry</code> <p>An instance of the Geometry class (from geometry.py) that provides methods for setting the data matrix and computing the Laplacian matrix.</p> required <p>Returns:</p> Name Type Description <code>H</code> <code>ndarray</code> <p>Dual Riemannian metric tensor for each sample.</p> <code>Hvv</code> <code>ndarray</code> <p>Singular vectors of the dual metric tensor for each sample.</p> <code>Hs</code> <code>ndarray</code> <p>Singular values of the dual metric tensor for each sample.</p> Notes <p>This function sets the data matrix in the provided Geometry object, computes the Laplacian matrix, and then estimates the local Riemannian metric distortions in the embedding space using the original data.</p> Source code in <code>distortions/geometry/rmetric.py</code> <pre><code>def local_distortions(embedding, data, geom):\n    \"\"\"\n    Compute local Riemannian metric distortions for each sample.\n\n    Parameters\n    ----------\n    embedding : np.ndarray, shape (n_samples, n_embedding_dims)\n        Low-dimensional embedding of the data. Each row corresponds to a sample,\n        and each column corresponds to an embedding dimension.\n    data : np.ndarray, shape (n_samples, n_features)\n        Original high-dimensional data. Each row is a sample, each column a feature.\n    geom : Geometry\n        An instance of the Geometry class (from geometry.py) that provides\n        methods for setting the data matrix and computing the Laplacian matrix.\n\n    Returns\n    -------\n    H : np.ndarray\n        Dual Riemannian metric tensor for each sample.\n    Hvv : np.ndarray\n        Singular vectors of the dual metric tensor for each sample.\n    Hs : np.ndarray\n        Singular values of the dual metric tensor for each sample.\n\n    Notes\n    -----\n    This function sets the data matrix in the provided Geometry object,\n    computes the Laplacian matrix, and then estimates the local Riemannian\n    metric distortions in the embedding space using the original data.\n    \"\"\"\n    geom.set_data_matrix(data)\n    L = geom.compute_laplacian_matrix()\n    _, _, Hvv, Hs, _, H = riemann_metric(embedding, L, n_dim=2)\n    return H, Hvv, Hs\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.neighborhoods","title":"<code>neighborhoods</code>","text":""},{"location":"reference/api.html#distortions.geometry.neighborhoods.boxplot_data","title":"<code>boxplot_data(x, y, nbin=10, outlier_iqr=3, **kwargs)</code>","text":"<p>Compute boxplot statistics and identify outliers within distance bins.</p> <p>This function divides the x-values (typically true distances) into bins and computes boxplot statistics for the y-values (typically embedding distances) within each bin. It identifies outliers using the IQR method.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array - like</code> <p>Input values used for binning (typically true/original distances).</p> required <code>y</code> <code>array - like</code> <p>Target values for which to compute statistics (typically embedding distances).</p> required <code>nbin</code> <code>int</code> <p>Number of bins to divide the x-value range into.</p> <code>10</code> <code>outlier_iqr</code> <code>float</code> <p>IQR multiplier for outlier detection. Values beyond Q1 - outlier_iqrIQR or Q3 + outlier_iqrIQR within each bin are considered outliers.</p> <code>3</code> <code>**kwargs</code> <code>keyword arguments</code> <p>Additional keyword arguments (currently unused).</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>summaries</code> <code>DataFrame</code> <p>DataFrame with boxplot statistics for each bin containing columns: - 'bin_id': bin identifier - 'q1', 'q2', 'q3': quartile values - 'min', 'max': minimum and maximum values - 'iqr': interquartile range - 'lower', 'upper': outlier detection bounds - 'bin': string representation of bin range</p> <code>outliers</code> <code>DataFrame</code> <p>DataFrame with outlier information containing columns: - 'index': original index of outlier point - 'bin_id': which bin the outlier belongs to - 'bin': string representation of bin range - 'value': the outlier y-value</p> Source code in <code>distortions/geometry/neighborhoods.py</code> <pre><code>def boxplot_data(x, y, nbin=10, outlier_iqr=3, **kwargs):\n    \"\"\"\n    Compute boxplot statistics and identify outliers within distance bins.\n\n    This function divides the x-values (typically true distances) into bins and\n    computes boxplot statistics for the y-values (typically embedding distances)\n    within each bin. It identifies outliers using the IQR method.\n\n    Parameters\n    ----------\n    x : array-like\n        Input values used for binning (typically true/original distances).\n    y : array-like\n        Target values for which to compute statistics (typically embedding distances).\n    nbin : int, default=10\n        Number of bins to divide the x-value range into.\n    outlier_iqr : float, default=3\n        IQR multiplier for outlier detection. Values beyond Q1 - outlier_iqr*IQR\n        or Q3 + outlier_iqr*IQR within each bin are considered outliers.\n    **kwargs : keyword arguments\n        Additional keyword arguments (currently unused).\n\n    Returns\n    -------\n    summaries : pd.DataFrame\n        DataFrame with boxplot statistics for each bin containing columns:\n        - 'bin_id': bin identifier\n        - 'q1', 'q2', 'q3': quartile values\n        - 'min', 'max': minimum and maximum values\n        - 'iqr': interquartile range\n        - 'lower', 'upper': outlier detection bounds\n        - 'bin': string representation of bin range\n    outliers : pd.DataFrame  \n        DataFrame with outlier information containing columns:\n        - 'index': original index of outlier point\n        - 'bin_id': which bin the outlier belongs to\n        - 'bin': string representation of bin range\n        - 'value': the outlier y-value\n    \"\"\"\n    # divide the data into nbin groups, and compute quantiles in each\n    bin_ids, bin_edges = pd.cut(x, bins=nbin, labels=False, retbins=True)\n    bin_edges = np.round(bin_edges, 1)\n\n    summaries = (\n        pd.DataFrame({'bin_id': bin_ids, 'y': y})\n        .groupby('bin_id', as_index=False)['y']\n        .agg(q1=lambda v: np.percentile(v, 25),\n             q2=lambda v: np.percentile(v, 50),\n             q3=lambda v: np.percentile(v, 75),\n             min='min', max='max')\n    )\n    summaries['iqr'] = summaries.q3 - summaries.q1\n    summaries['lower'] = np.maximum(summaries.q2 - outlier_iqr * summaries.iqr, summaries['min'])\n    summaries['upper'] = np.minimum(summaries.q2 + outlier_iqr * summaries.iqr, summaries['max'])\n    summaries['bin'] = summaries['bin_id'].map(lambda b: f\"{bin_edges[b]}-{bin_edges[b + 1]}\")\n\n    # compute outliers according to the IQR above\n    outliers = [\n        {\"index\": i, \"bin_id\": int(b), \"bin\": f\"{bin_edges[b]}-{bin_edges[b + 1]}\", \"value\": val}\n        for i, (b, val) in enumerate(zip(bin_ids, y))\n        if not np.isnan(b) and (\n            val &lt; summaries.loc[b, 'q1'] - outlier_iqr * summaries.loc[b, 'iqr'] or\n            val &gt; summaries.loc[b, 'q3'] + outlier_iqr * summaries.loc[b, 'iqr']\n        )\n    ]\n    return summaries, pd.DataFrame(outliers)\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.neighborhoods.broken_knn","title":"<code>broken_knn(embedding, k=2, z_thresh=1.0)</code>","text":"<p>Determine broken points in embedding space using k-NN distances and Z-score thresholding.</p> <p>This function identifies potentially problematic points in an embedding by computing their average k-nearest neighbor distances, calculating Z-scores, and flagging points that exceed the threshold as broken or isolated.</p> <p>Parameters:</p> Name Type Description Default <code>embedding</code> <code>(array - like, shape(n_samples, n_features))</code> <p>The embedding coordinates for all samples.</p> required <code>k</code> <code>int</code> <p>Number of nearest neighbors to consider for distance calculation.</p> <code>2</code> <code>z_thresh</code> <code>float</code> <p>Z-score threshold for identifying broken points. Points with Z-scores greater than or equal to this value are considered broken.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>list of int</code> <p>List of indices of broken points, sorted by descending Z-score. If no points exceed the threshold, returns the single point with the highest Z-score.</p> Source code in <code>distortions/geometry/neighborhoods.py</code> <pre><code>def broken_knn(embedding, k=2, z_thresh=1.0):\n    \"\"\"\n    Determine broken points in embedding space using k-NN distances and Z-score thresholding.\n\n    This function identifies potentially problematic points in an embedding by\n    computing their average k-nearest neighbor distances, calculating Z-scores,\n    and flagging points that exceed the threshold as broken or isolated.\n\n    Parameters\n    ----------\n    embedding : array-like, shape (n_samples, n_features)\n        The embedding coordinates for all samples.\n    k : int, default=2\n        Number of nearest neighbors to consider for distance calculation.\n    z_thresh : float, default=1.0\n        Z-score threshold for identifying broken points. Points with Z-scores\n        greater than or equal to this value are considered broken.\n\n    Returns\n    -------\n    list of int\n        List of indices of broken points, sorted by descending Z-score.\n        If no points exceed the threshold, returns the single point with\n        the highest Z-score.\n    \"\"\"\n    sub = embedding\n    nbr_sub = NearestNeighbors(n_neighbors=k).fit(sub)\n    d_sub, _ = nbr_sub.kneighbors(sub)\n    d1 = d_sub.mean(axis=1) \n\n    # 2) Z-score &amp; threshold\n    mu, sigma = d1.mean(), d1.std()\n    z = (d1 - mu) / sigma\n    locs = np.where(z &gt;= z_thresh)[0]\n    if len(locs)==0:\n        locs = [int(np.argmax(z))]\n\n    # 3) rank by descending Z-score\n    locs = sorted(locs, key=lambda i: z[i], reverse=True)\n    return locs\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.neighborhoods.identify_broken_box","title":"<code>identify_broken_box(dists, outlier_factor=3, nbin=10)</code>","text":"<p>Identify broken links using boxplot-based outlier detection within distance bins.</p> <p>This helper function bins the true distances and identifies outliers in the embedding distances within each bin using boxplot criteria.</p> <p>Parameters:</p> Name Type Description Default <code>dists</code> <code>DataFrame</code> <p>DataFrame with 'true' and 'embedding' distance columns.</p> required <code>outlier_factor</code> <code>float</code> <p>IQR multiplier for outlier detection threshold.</p> <code>3</code> <code>nbin</code> <code>int</code> <p>Number of bins to divide the true distance range into.</p> <code>10</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Copy of input distances DataFrame with additional 'brokenness' boolean column indicating which links are identified as broken outliers.</p> Source code in <code>distortions/geometry/neighborhoods.py</code> <pre><code>def identify_broken_box(dists, outlier_factor=3, nbin=10):\n    \"\"\"\n    Identify broken links using boxplot-based outlier detection within distance bins.\n\n    This helper function bins the true distances and identifies outliers in the\n    embedding distances within each bin using boxplot criteria.\n\n    Parameters\n    ----------\n    dists : pd.DataFrame\n        DataFrame with 'true' and 'embedding' distance columns.\n    outlier_factor : float, default=3\n        IQR multiplier for outlier detection threshold.\n    nbin : int, default=10\n        Number of bins to divide the true distance range into.\n\n    Returns\n    -------\n    pd.DataFrame\n        Copy of input distances DataFrame with additional 'brokenness' boolean column\n        indicating which links are identified as broken outliers.\n    \"\"\"\n    _, outliers = boxplot_data(dists[\"true\"], dists[\"embedding\"], nbin, outlier_factor)\n    brokenness = dists.copy()\n    brokenness = brokenness.reset_index()\n    brokenness[\"brokenness\"] = False\n    brokenness.loc[outliers[\"index\"].values, \"brokenness\"] = True\n    return brokenness\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.neighborhoods.identify_broken_window","title":"<code>identify_broken_window(dists, outlier_factor=3, percentiles=[75, 25], frame=[50, 50])</code>","text":"<p>Identify broken links using sliding window smoothing and residual analysis.</p> <p>This helper function applies a sliding window median filter to the distance relationship and identifies links where the embedding distance significantly exceeds the smoothed expectation.</p> <p>Parameters:</p> Name Type Description Default <code>dists</code> <code>DataFrame</code> <p>DataFrame with 'true' and 'embedding' distance columns.</p> required <code>outlier_factor</code> <code>float</code> <p>Multiplier for IQR-based outlier threshold in residual analysis.</p> <code>3</code> <code>percentiles</code> <code>list of float</code> <p>Percentiles used for IQR calculation.</p> <code>[75, 25]</code> <code>frame</code> <code>list of int</code> <p>Window frame size [before, after] for sliding median calculation.</p> <code>[50, 50]</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with original columns plus: - 'embedding_smooth': smoothed embedding distances - 'residual': difference between actual and smoothed embedding distances - 'brokenness': boolean indicating broken links</p> Source code in <code>distortions/geometry/neighborhoods.py</code> <pre><code>def identify_broken_window(dists, outlier_factor=3, percentiles=[75, 25], frame=[50, 50]):\n    \"\"\"\n    Identify broken links using sliding window smoothing and residual analysis.\n\n    This helper function applies a sliding window median filter to the distance\n    relationship and identifies links where the embedding distance significantly\n    exceeds the smoothed expectation.\n\n    Parameters\n    ----------\n    dists : pd.DataFrame\n        DataFrame with 'true' and 'embedding' distance columns.\n    outlier_factor : float, default=3\n        Multiplier for IQR-based outlier threshold in residual analysis.\n    percentiles : list of float, default=[75, 25]\n        Percentiles used for IQR calculation.\n    frame : list of int, default=[50, 50]\n        Window frame size [before, after] for sliding median calculation.\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame with original columns plus:\n        - 'embedding_smooth': smoothed embedding distances\n        - 'residual': difference between actual and smoothed embedding distances  \n        - 'brokenness': boolean indicating broken links\n    \"\"\"\n    line = alt.Chart(dists).transform_window(\n        embedding_smooth='median(embedding)',\n        sort=[alt.SortField('true')],\n        frame=frame\n    ).mark_line().encode(\n        x='true:Q',\n        y='embedding_smooth:Q'\n    )\n\n    result = extract_data(line).drop_duplicates()\n    result[\"residual\"] = result[\"embedding\"] - result[\"embedding_smooth\"]\n    result[\"brokenness\"] = result[\"residual\"] &gt; result[\"embedding_smooth\"] + \\\n        outlier_factor * iqr(result[\"residual\"], percentiles)\n    return result\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.neighborhoods.iqr","title":"<code>iqr(x, percentiles)</code>","text":"<p>Calculate the interquartile range between given percentiles.</p> <p>This function computes the difference between two percentiles of the input array, typically used to measure the spread of data.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array - like</code> <p>Input array for which to calculate the interquartile range.</p> required <code>percentiles</code> <code>array-like of length 2</code> <p>Two percentile values (e.g., [25, 75] for standard IQR). The function returns the difference between the higher and lower percentiles.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The interquartile range (difference between the specified percentiles).</p> Source code in <code>distortions/geometry/neighborhoods.py</code> <pre><code>def iqr(x, percentiles):\n    \"\"\"\n    Calculate the interquartile range between given percentiles.\n\n    This function computes the difference between two percentiles of the\n    input array, typically used to measure the spread of data.\n\n    Parameters\n    ----------\n    x : array-like\n        Input array for which to calculate the interquartile range.\n    percentiles : array-like of length 2\n        Two percentile values (e.g., [25, 75] for standard IQR).\n        The function returns the difference between the higher and lower percentiles.\n\n    Returns\n    -------\n    float\n        The interquartile range (difference between the specified percentiles).\n    \"\"\"\n    return np.subtract(*np.percentile(x, percentiles))\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.neighborhoods.neighbor_generator","title":"<code>neighbor_generator(embedding, broken_locations=[], number_neighbor=10)</code>","text":"<p>Generate neighbor lists for broken points in the embedding space.</p> <p>This function finds nearest neighbors for specified broken points (or automatically detected ones) in the embedding space. It's useful for understanding the local neighborhood structure around problematic points.</p> <p>Parameters:</p> Name Type Description Default <code>embedding</code> <code>(array - like, shape(n_samples, n_features))</code> <p>The embedding coordinates for all samples.</p> required <code>broken_locations</code> <code>list of int</code> <p>Indices of broken points for which to generate neighbors. If empty, automatically detects broken points using broken_knn().</p> <code>[]</code> <code>number_neighbor</code> <code>int</code> <p>Number of nearest neighbors to find for each broken point.</p> <code>10</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary mapping broken point indices (int) to lists of their  nearest neighbor indices, excluding the point itself.</p> Source code in <code>distortions/geometry/neighborhoods.py</code> <pre><code>def neighbor_generator(embedding, broken_locations = [], number_neighbor=10):\n    \"\"\"\n    Generate neighbor lists for broken points in the embedding space.\n\n    This function finds nearest neighbors for specified broken points (or\n    automatically detected ones) in the embedding space. It's useful for\n    understanding the local neighborhood structure around problematic points.\n\n    Parameters\n    ----------\n    embedding : array-like, shape (n_samples, n_features)\n        The embedding coordinates for all samples.\n    broken_locations : list of int, default=[]\n        Indices of broken points for which to generate neighbors. If empty,\n        automatically detects broken points using broken_knn().\n    number_neighbor : int, default=10\n        Number of nearest neighbors to find for each broken point.\n\n    Returns\n    -------\n    dict\n        Dictionary mapping broken point indices (int) to lists of their \n        nearest neighbor indices, excluding the point itself.\n    \"\"\"\n    if len(broken_locations) == 0:\n        broken_locations = broken_knn(embedding)\n    nbr_full = NearestNeighbors(n_neighbors=number_neighbor+1).fit(embedding)\n    isolated = {}\n    for idx in broken_locations:\n        _, neigh = nbr_full.kneighbors([embedding[idx]])\n        isolated[int(idx)] = neigh[0][1:].tolist()  # drop self\n    return isolated\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.neighborhoods.neighborhood_distances","title":"<code>neighborhood_distances(adata, embed_key='X_umap')</code>","text":"<p>Compute pairwise distances between samples and their neighbors in both original and embedding spaces.</p> <p>This function calculates pairwise distances between each sample and its neighbors in the original high-dimensional space and compares them with distances in the reduced embedding space. This is useful for analyzing how well the embedding preserves local neighborhood structure.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>Annotated data matrix. Must contain a precomputed embedding (e.g., UMAP or t-SNE) in <code>obsm[embed_key]</code> and a neighbor graph in <code>obsp[\"distances\"]</code>.</p> required <code>embed_key</code> <code>str</code> <p>Key in <code>adata.obsm</code> where the embedding coordinates are stored.</p> <code>\"X_umap\"</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with columns:     - 'center': index of the sample (cell)     - 'neighbor': index of the neighbor sample     - 'true': distance in the original space (from <code>adata.obsp[\"distances\"]</code>)     - 'embedding': distance in the embedding space (from <code>adata.obsm[embed_key]</code>)</p> Notes <p>The number of neighbors is determined by the structure of the neighbor graph in <code>adata.obsp[\"distances\"]</code>. The function assumes that the embedding and neighbor graph have already been computed.</p> Source code in <code>distortions/geometry/neighborhoods.py</code> <pre><code>def neighborhood_distances(adata, embed_key=\"X_umap\"):\n    \"\"\"\n    Compute pairwise distances between samples and their neighbors in both original and embedding spaces.\n\n    This function calculates pairwise distances between each sample and its\n    neighbors in the original high-dimensional space and compares them with\n    distances in the reduced embedding space. This is useful for analyzing\n    how well the embedding preserves local neighborhood structure.\n\n    Parameters\n    ----------\n    adata : anndata.AnnData\n        Annotated data matrix. Must contain a precomputed embedding (e.g., UMAP or t-SNE) in `obsm[embed_key]`\n        and a neighbor graph in `obsp[\"distances\"]`.\n    embed_key : str, default=\"X_umap\"\n        Key in `adata.obsm` where the embedding coordinates are stored.\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame with columns:\n            - 'center': index of the sample (cell)\n            - 'neighbor': index of the neighbor sample\n            - 'true': distance in the original space (from `adata.obsp[\"distances\"]`)\n            - 'embedding': distance in the embedding space (from `adata.obsm[embed_key]`)\n\n    Notes\n    -----\n    The number of neighbors is determined by the structure of the neighbor graph in `adata.obsp[\"distances\"]`.\n    The function assumes that the embedding and neighbor graph have already been computed.\n    \"\"\"\n    knn_graph = adata.obsp[\"distances\"]\n    dist_list = []\n\n    for ix in range(len(adata)):\n        neighbors = knn_graph[ix].nonzero()[1]\n        true = knn_graph[ix, neighbors].toarray().flatten()\n        embedding = cdist(\n            [adata.obsm[embed_key][ix, :]], \n            adata.obsm[embed_key][neighbors, :]\n        ).flatten()\n        dist_list.append(pd.DataFrame({\n            \"center\": [ix] * len(neighbors), \n            \"neighbor\": neighbors,\n            \"true\": true,\n            \"embedding\": embedding\n        }))\n\n    return pd.concat(dist_list)\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.neighborhoods.neighborhoods","title":"<code>neighborhoods(adata, outlier_factor=3, threshold=0.2, method='box', percentiles=[75, 25], frame=[50, 50], nbin=10, **kwargs)</code>","text":"<p>Identify broken neighborhoods in embeddings using different methods.</p> <p>This function serves as the main interface for detecting broken neighborhoods in dimensionality reduction embeddings. It supports multiple methods for identifying outliers and broken links between original and embedding spaces.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>Annotated data matrix with precomputed embedding and neighbor graph.</p> required <code>outlier_factor</code> <code>float</code> <p>Factor used to determine outlier threshold. Higher values are more permissive (fewer outliers detected).</p> <code>3</code> <code>threshold</code> <code>float</code> <p>Proportion threshold for flagging samples as having broken neighborhoods. Centers with more than this proportion of broken neighbors are flagged.</p> <code>0.2  </code> <code>method</code> <code>str</code> <p>Method for identifying broken neighborhoods. Options: - \"box\": Uses boxplot-based outlier detection - \"window\": Uses sliding window smoothing with residual analysis</p> <code>\"box\"</code> <code>percentiles</code> <code>list of float</code> <p>Percentiles used for IQR calculation in windowing method.</p> <code>[75, 25]</code> <code>frame</code> <code>list of int</code> <p>Window frame size [before, after] for sliding window smoothing.</p> <code>[50, 50]</code> <code>nbin</code> <code>int</code> <p>Number of bins for boxplot method.</p> <code>10</code> <code>**kwargs</code> <code>keyword arguments</code> <p>Additional arguments passed to neighborhood_distances().</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary mapping center indices to lists of their neighbor indices for samples with broken neighborhoods.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If an unsupported method is specified.</p> Source code in <code>distortions/geometry/neighborhoods.py</code> <pre><code>def neighborhoods(adata, outlier_factor=3, threshold=0.2, method=\"box\",\n                  percentiles=[75, 25], frame=[50, 50], nbin=10, **kwargs):\n    \"\"\"\n    Identify broken neighborhoods in embeddings using different methods.\n\n    This function serves as the main interface for detecting broken neighborhoods\n    in dimensionality reduction embeddings. It supports multiple methods for\n    identifying outliers and broken links between original and embedding spaces.\n\n    Parameters\n    ----------\n    adata : anndata.AnnData\n        Annotated data matrix with precomputed embedding and neighbor graph.\n    outlier_factor : float, default=3\n        Factor used to determine outlier threshold. Higher values are more\n        permissive (fewer outliers detected).\n    threshold : float, default=0.2  \n        Proportion threshold for flagging samples as having broken neighborhoods.\n        Centers with more than this proportion of broken neighbors are flagged.\n    method : str, default=\"box\"\n        Method for identifying broken neighborhoods. Options:\n        - \"box\": Uses boxplot-based outlier detection\n        - \"window\": Uses sliding window smoothing with residual analysis\n    percentiles : list of float, default=[75, 25]\n        Percentiles used for IQR calculation in windowing method.\n    frame : list of int, default=[50, 50]\n        Window frame size [before, after] for sliding window smoothing.\n    nbin : int, default=10\n        Number of bins for boxplot method.\n    **kwargs : keyword arguments\n        Additional arguments passed to neighborhood_distances().\n\n    Returns\n    -------\n    dict\n        Dictionary mapping center indices to lists of their neighbor indices\n        for samples with broken neighborhoods.\n\n    Raises\n    ------\n    NotImplementedError\n        If an unsupported method is specified.\n    \"\"\"\n    if method == \"box\":\n        return neighborhoods_box(adata, outlier_factor, threshold, nbin, **kwargs)\n    if method == \"window\":\n        return neighborhoods_window(adata, outlier_factor, threshold, percentiles, frame, **kwargs)\n    else:\n        return NotImplementedError(f\"Method {method} not implemented for broken neighborhood construction.\")\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.neighborhoods.neighborhoods_box","title":"<code>neighborhoods_box(adata, outlier_factor=3, threshold=0.2, nbin=10, **kwargs)</code>","text":"<p>Identify broken neighborhoods using boxplot-based outlier detection.</p> <p>This method bins the true distances and computes boxplot statistics within each bin. Links are considered broken if their embedding distance is an outlier relative to other links with similar true distances.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>Annotated data matrix with precomputed embedding and neighbor graph.</p> required <code>outlier_factor</code> <code>float</code> <p>IQR multiplier for boxplot outlier detection. Values beyond Q1 - outlier_factorIQR or Q3 + outlier_factorIQR are outliers.</p> <code>3</code> <code>threshold</code> <code>float</code> <p>Proportion threshold for flagging samples as having broken neighborhoods.</p> <code>0.2</code> <code>nbin</code> <code>int</code> <p>Number of bins to divide the true distance range into.</p> <code>10</code> <code>**kwargs</code> <code>keyword arguments</code> <p>Additional arguments passed to neighborhood_distances().</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary mapping center indices to lists of their neighbor indices for samples with broken neighborhoods.</p> Source code in <code>distortions/geometry/neighborhoods.py</code> <pre><code>def neighborhoods_box(adata, outlier_factor=3, threshold=0.2, nbin=10, **kwargs):\n    \"\"\"\n    Identify broken neighborhoods using boxplot-based outlier detection.\n\n    This method bins the true distances and computes boxplot statistics within\n    each bin. Links are considered broken if their embedding distance is an\n    outlier relative to other links with similar true distances.\n\n    Parameters\n    ----------\n    adata : anndata.AnnData\n        Annotated data matrix with precomputed embedding and neighbor graph.\n    outlier_factor : float, default=3\n        IQR multiplier for boxplot outlier detection. Values beyond\n        Q1 - outlier_factor*IQR or Q3 + outlier_factor*IQR are outliers.\n    threshold : float, default=0.2\n        Proportion threshold for flagging samples as having broken neighborhoods.\n    nbin : int, default=10\n        Number of bins to divide the true distance range into.\n    **kwargs : keyword arguments\n        Additional arguments passed to neighborhood_distances().\n\n    Returns\n    -------\n    dict\n        Dictionary mapping center indices to lists of their neighbor indices\n        for samples with broken neighborhoods.\n    \"\"\"\n    dists = neighborhood_distances(adata, **kwargs)\n    brokenness = identify_broken_box(dists, outlier_factor, nbin)\n    return threshold_links(dists, brokenness, threshold)\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.neighborhoods.neighborhoods_window","title":"<code>neighborhoods_window(adata, outlier_factor=3, threshold=0.2, percentiles=[75, 25], frame=[50, 50], **kwargs)</code>","text":"<p>Identify broken neighborhoods using window-based smoothing and residual analysis.</p> <p>This method applies a sliding window median filter to the distance relationships and identifies outliers based on residuals from the smoothed curve. Points with large positive residuals indicate broken neighborhoods where embedding distances are much larger than expected.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>Annotated data matrix with precomputed embedding and neighbor graph.</p> required <code>outlier_factor</code> <code>float</code> <p>Multiplier for IQR-based outlier threshold. Residuals greater than median + outlier_factor * IQR are considered broken.</p> <code>3</code> <code>threshold</code> <code>float</code> <p>Proportion threshold for flagging samples as having broken neighborhoods.</p> <code>0.2</code> <code>percentiles</code> <code>list of float</code> <p>Percentiles used for IQR calculation in residual analysis.</p> <code>[75, 25]</code> <code>frame</code> <code>list of int</code> <p>Window frame size [before, after] for sliding median calculation.</p> <code>[50, 50]</code> <code>**kwargs</code> <code>keyword arguments</code> <p>Additional arguments passed to neighborhood_distances().</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary mapping center indices to lists of their neighbor indices for samples with broken neighborhoods.</p> Source code in <code>distortions/geometry/neighborhoods.py</code> <pre><code>def neighborhoods_window(adata, outlier_factor=3, threshold=0.2, percentiles=[75, 25], frame=[50, 50], **kwargs):\n    \"\"\"\n    Identify broken neighborhoods using window-based smoothing and residual analysis.\n\n    This method applies a sliding window median filter to the distance relationships\n    and identifies outliers based on residuals from the smoothed curve. Points with\n    large positive residuals indicate broken neighborhoods where embedding distances\n    are much larger than expected.\n\n    Parameters\n    ----------\n    adata : anndata.AnnData\n        Annotated data matrix with precomputed embedding and neighbor graph.\n    outlier_factor : float, default=3\n        Multiplier for IQR-based outlier threshold. Residuals greater than\n        median + outlier_factor * IQR are considered broken.\n    threshold : float, default=0.2\n        Proportion threshold for flagging samples as having broken neighborhoods.\n    percentiles : list of float, default=[75, 25]\n        Percentiles used for IQR calculation in residual analysis.\n    frame : list of int, default=[50, 50]\n        Window frame size [before, after] for sliding median calculation.\n    **kwargs : keyword arguments\n        Additional arguments passed to neighborhood_distances().\n\n    Returns\n    -------\n    dict\n        Dictionary mapping center indices to lists of their neighbor indices\n        for samples with broken neighborhoods.\n    \"\"\"\n    dists = neighborhood_distances(adata, **kwargs)\n    brokenness = identify_broken_window(dists, outlier_factor, percentiles, frame)\n    return threshold_links(dists, brokenness, threshold)\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.neighborhoods.threshold_links","title":"<code>threshold_links(dists, brokenness, threshold=0.2)</code>","text":"<p>Flag samples with high proportions of broken neighborhood links.</p> <p>This function identifies samples where the proportion of broken neighborhood links exceeds a specified threshold, indicating problematic embedding regions.</p> <p>Parameters:</p> Name Type Description Default <code>dists</code> <code>DataFrame</code> <p>DataFrame containing distance information with 'center' and 'neighbor' columns.</p> required <code>brokenness</code> <code>DataFrame</code> <p>DataFrame with 'center' and 'brokenness' columns indicating broken links.</p> required <code>threshold</code> <code>float</code> <p>Proportion threshold for flagging samples. Centers with more than this proportion of broken neighbors are included in the output.</p> <code>0.2</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary mapping center indices (int) to lists of their neighbor indices for samples exceeding the brokenness threshold.</p> Source code in <code>distortions/geometry/neighborhoods.py</code> <pre><code>def threshold_links(dists, brokenness, threshold=0.2):\n    \"\"\"\n    Flag samples with high proportions of broken neighborhood links.\n\n    This function identifies samples where the proportion of broken neighborhood\n    links exceeds a specified threshold, indicating problematic embedding regions.\n\n    Parameters\n    ----------\n    dists : pd.DataFrame\n        DataFrame containing distance information with 'center' and 'neighbor' columns.\n    brokenness : pd.DataFrame\n        DataFrame with 'center' and 'brokenness' columns indicating broken links.\n    threshold : float, default=0.2\n        Proportion threshold for flagging samples. Centers with more than this\n        proportion of broken neighbors are included in the output.\n\n    Returns\n    -------\n    dict\n        Dictionary mapping center indices (int) to lists of their neighbor indices\n        for samples exceeding the brokenness threshold.\n    \"\"\"\n    brokenness = brokenness.reset_index()\n    centers = brokenness.center.unique()\n    summary_dict = {}\n\n    for i in range(len(centers)):\n        subset = brokenness[brokenness[\"center\"] == centers[i]]\n        if np.mean(subset[\"brokenness\"]) &gt; threshold:\n            brokenness.loc[i, \"brokenness\"] = True\n            summary_dict[centers[i]] = [int(z) for z in dists[dists.center == centers[i]].neighbor.values]\n    return summary_dict\n</code></pre>"},{"location":"reference/api.html#distortionsvisualization","title":"<code>distortions.visualization</code>","text":""},{"location":"reference/api.html#distortions.visualization.dplot","title":"<code>dplot</code>","text":"<p>               Bases: <code>AnyWidget</code></p> <p>Interactive Distortion Plot Widget</p> <p>This class provides an interactive widget for visualizing distortion metrics computed on datasets, with a ggplot2-like syntax for adding graphical marks and overlaying distortion criteria. It is designed for use in Jupyter environments and leverages the anywidget and traitlets libraries for interactivity. You can pause mouseover interactivity by holding down the control key.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input dataset to visualize. Must be convertible to a list of records.</p> required <code>*args</code> <code>tuple</code> <p>Additional positional arguments passed to the parent AnyWidget.</p> <code>()</code> <code>**kwargs</code> <code>dict</code> <p>Additional keyword arguments passed to the parent AnyWidget and used as visualization options.</p> <code>{}</code> <p>Methods:</p> Name Description <code>mapping</code> <p>Specify the mapping from data columns to visual properties.</p> <code>geom_ellipse</code> <p>Add an ellipse layer to the plot.</p> <code>geom_hair</code> <p>Add a hair (small oriented lines) layer to the plot.</p> <code>labs</code> <p>Add labels to the plot.</p> <code>geom_edge_link</code> <p>Add edge link geometry to the plot.</p> <code>inter_edge_link</code> <p>Add interactive edge link geometry to the plot.</p> <code>inter_isometry</code> <p>Add interactive isometry overlays to the plot.</p> <code>scale_color</code> <p>Add a color scale to the plot.</p> <code>scale_size</code> <p>Add a size scale to the plot.</p> <code>inter_boxplot</code> <p>Add an interactive boxplot layer for distortion metrics, using provided distance summaries and outlier information.</p> <code>save</code> <p>Save the current view to SVG.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; df = pd.DataFrame({...})\n&gt;&gt;&gt; dplot(df).mapping(x='embedding_1', y='embedding_2').geom_ellipse()\n</code></pre> Source code in <code>distortions/visualization/interactive.py</code> <pre><code>class dplot(anywidget.AnyWidget):\n    \"\"\"\n    Interactive Distortion Plot Widget\n\n    This class provides an interactive widget for visualizing distortion metrics\n    computed on datasets, with a ggplot2-like syntax for adding graphical marks\n    and overlaying distortion criteria. It is designed for use in Jupyter\n    environments and leverages the anywidget and traitlets libraries for\n    interactivity. You can pause mouseover interactivity by holding down the\n    control key.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        The input dataset to visualize. Must be convertible to a list of records.\n    *args : tuple\n        Additional positional arguments passed to the parent AnyWidget.\n    **kwargs : dict\n        Additional keyword arguments passed to the parent AnyWidget and used as\n        visualization options.\n\n    Methods\n    -------\n    mapping(**kwargs)\n        Specify the mapping from data columns to visual properties.\n    geom_ellipse(**kwargs)\n        Add an ellipse layer to the plot.\n    geom_hair(**kwargs)\n        Add a hair (small oriented lines) layer to the plot.\n    labs(**kwargs)\n        Add labels to the plot.\n    geom_edge_link(**kwargs)\n        Add edge link geometry to the plot.\n    inter_edge_link(**kwargs)\n        Add interactive edge link geometry to the plot.\n    inter_isometry(**kwargs)\n        Add interactive isometry overlays to the plot.\n    scale_color(**kwargs)\n        Add a color scale to the plot.\n    scale_size(**kwargs)\n        Add a size scale to the plot.\n    inter_boxplot(dists, **kwargs)\n        Add an interactive boxplot layer for distortion metrics, using provided\n        distance summaries and outlier information.\n    save(filename)\n        Save the current view to SVG.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import pandas as pd\n    &gt;&gt;&gt; df = pd.DataFrame({...})\n    &gt;&gt;&gt; dplot(df).mapping(x='embedding_1', y='embedding_2').geom_ellipse()\n    \"\"\"\n    widget_dir = Path(__file__).parent\n    _esm = widget_dir / \"render.js\"\n    _mapping = traitlets.Dict().tag(sync=True)\n    dataset = traitlets.List().tag(sync=True)\n    layers = traitlets.List().tag(sync=True)\n    neighbors = traitlets.List().tag(sync=True)\n    distance_summaries = traitlets.List().tag(sync=True)\n    outliers = traitlets.List().tag(sync=True)\n    options = traitlets.Dict().tag(sync=True)\n    elem_svg = traitlets.Unicode().tag(sync=True)\n\n    def __init__(self, df, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.dataset = df.to_dict(\"records\")\n        self.options = kwargs\n\n    def mapping(self, **kwargs):\n        \"\"\"\n        Specify the Mapping \n        \"\"\"\n        kwargs = {\"angle\": \"angle\", \"a\": \"s1\", \"b\": \"s0\", **kwargs}\n        self._mapping = kwargs\n        return self\n\n    def geom_ellipse(self, **kwargs):\n        self.layers = self.layers + [{\"type\": \"geom_ellipse\", \"options\": kwargs}]\n        return self\n\n    def geom_hair(self, **kwargs):\n        self.layers = self.layers + [{'type': 'geom_hair', 'options': kwargs}]\n        return self\n\n    def labs(self, **kwargs):\n        self.layers = self.layers + [{\"type\": \"labs\", \"options\": kwargs}]\n        return self\n\n    def geom_edge_link(self, **kwargs):\n        self.layers = self.layers + [{\"type\": \"geom_edge_link\", \"options\": kwargs}]\n        return self\n\n    def inter_edge_link(self, **kwargs):\n        self.layers = self.layers + [{\"type\": \"inter_edge_link\", \"options\": kwargs}]\n        return self\n\n    def inter_isometry(self, **kwargs):\n        self.layers = self.layers + [{\"type\": \"inter_isometry\", \"options\": kwargs}]\n        return self\n\n    def scale_color(self, **kwargs):\n        self.layers = self.layers + [{\"type\": \"scale_color\", \"options\": kwargs}]\n        return self\n\n    def scale_size(self, **kwargs):\n        self.layers = self.layers + [{\"type\": \"scale_size\", \"options\": kwargs}]\n        return self\n\n    def inter_boxplot(self, dists, **kwargs):\n        summaries, outliers = boxplot_data(dists[\"true\"], dists[\"embedding\"], **kwargs)\n        outliers[\"center\"] = dists.center.values[outliers[\"index\"].values]\n        outliers[\"neighbor\"] = dists.neighbor.values[outliers[\"index\"].values]\n\n        # pass the related data to the visualization\n        self.layers = self.layers + [{\"type\": \"inter_boxplot\", \"options\": kwargs}]\n        self.distance_summaries = summaries.to_dict(\"records\")\n        self.outliers = outliers.to_dict(\"records\")\n        return self\n\n    def save(self, filename=\"plot.svg\"):\n        self.send({\"type\": \"save\"})\n        with open(filename, \"w\") as f:\n            f.write(self.elem_svg)\n        f.close()\n</code></pre>"},{"location":"reference/api.html#distortions.visualization.dplot.mapping","title":"<code>mapping(**kwargs)</code>","text":"<p>Specify the Mapping</p> Source code in <code>distortions/visualization/interactive.py</code> <pre><code>def mapping(self, **kwargs):\n    \"\"\"\n    Specify the Mapping \n    \"\"\"\n    kwargs = {\"angle\": \"angle\", \"a\": \"s1\", \"b\": \"s0\", **kwargs}\n    self._mapping = kwargs\n    return self\n</code></pre>"},{"location":"reference/api.html#distortions.visualization.scanpy_umap","title":"<code>scanpy_umap(adata, max_cells=200, n_neighbors=10, n_pcs=40)</code>","text":"<p>Runs UMAP visualization on an AnnData object with basic preprocessing.</p> <p>This wrapper function filters genes by minimum count, applies log transformation, selects highly variable genes, computes neighbors in PCA space, and runs UMAP.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>AnnData experiment object containing the data to filter, transform, and apply UMAP to.</p> required <code>max_cells</code> <code>int, optional (default: 200)</code> <p>Maximum number of cells to use for visualization.</p> <code>200</code> <code>n_neighbors</code> <code>int, optional (default: 10)</code> <p>Number of neighbors to use for constructing the neighborhood graph.</p> <code>10</code> <code>n_pcs</code> <code>int, optional (default: 40)</code> <p>Number of principal components to use for neighborhood graph construction.</p> <code>40</code> <p>Returns:</p> Name Type Description <code>adata</code> <code>AnnData</code> <p>The AnnData object after preprocessing and UMAP computation.</p> Notes <p>The function modifies the input AnnData object in place.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scanpy as sc\n&gt;&gt;&gt; from distortion.visualization import scanpy_umap\n&gt;&gt;&gt; adata = sc.datasets.pbmc3k()\n&gt;&gt;&gt; adata_umap = scanpy_umap(adata, max_cells=100, n_neighbors=15, n_pcs=30)\n&gt;&gt;&gt; sc.pl.umap(adata_umap)\n</code></pre> Source code in <code>distortions/visualization/umap.py</code> <pre><code>def scanpy_umap(adata, max_cells=200, n_neighbors=10, n_pcs=40):\n    \"\"\"\n    Runs UMAP visualization on an AnnData object with basic preprocessing.\n\n    This wrapper function filters genes by minimum count, applies log\n    transformation, selects highly variable genes, computes neighbors in PCA\n    space, and runs UMAP.\n\n    Parameters\n    ----------\n    adata : anndata.AnnData\n        AnnData experiment object containing the data to filter, transform, and\n        apply UMAP to.\n    max_cells : int, optional (default: 200)\n        Maximum number of cells to use for visualization.\n    n_neighbors : int, optional (default: 10)\n        Number of neighbors to use for constructing the neighborhood graph.\n    n_pcs : int, optional (default: 40)\n        Number of principal components to use for neighborhood graph construction.\n\n    Returns\n    -------\n    adata : anndata.AnnData\n        The AnnData object after preprocessing and UMAP computation.\n\n    Notes\n    -----\n    The function modifies the input AnnData object in place.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import scanpy as sc\n    &gt;&gt;&gt; from distortion.visualization import scanpy_umap\n    &gt;&gt;&gt; adata = sc.datasets.pbmc3k()\n    &gt;&gt;&gt; adata_umap = scanpy_umap(adata, max_cells=100, n_neighbors=15, n_pcs=30)\n    &gt;&gt;&gt; sc.pl.umap(adata_umap)\n    \"\"\"\n    adata = adata[:max_cells, :]\n\n    # Preprocess the dataset\n    sc.pp.filter_genes(adata, min_counts=1)\n    sc.pp.log1p(adata)\n    sc.pp.highly_variable_genes(adata, min_mean=0.5, min_disp=0.5)\n    adata = adata[:, adata.var.highly_variable]\n\n    # Run UMAP\n    sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=n_pcs)\n    sc.tl.umap(adata)\n    return adata\n</code></pre>"},{"location":"tutorials/c_elegans.html","title":"Comparing Density Preserving Algorithms on the C. Elegans Data","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom distortions.geometry import neighborhoods, Geometry, local_distortions, bind_metric\nfrom distortions.visualization import dplot\nimport numpy as np\nimport scanpy as sc\nimport altair as alt\n</pre> import numpy as np import pandas as pd import matplotlib.pyplot as plt from distortions.geometry import neighborhoods, Geometry, local_distortions, bind_metric from distortions.visualization import dplot import numpy as np import scanpy as sc import altair as alt In\u00a0[2]: Copied! <pre># Read data directly from GitHub\ndata_url = \"https://raw.githubusercontent.com/krisrs1128/distortions-data/main/data/c-elegans_qc_final.txt\"\nmetadata_url = \"https://raw.githubusercontent.com/krisrs1128/distortions-data/main/data/c-elegans_qc_final_metadata.txt\"\n\ndata = np.loadtxt(data_url, delimiter=\"\\t\")\nmetadata = pd.read_csv(metadata_url, sep=\",\")\n\nprint(\"Data shape:\", data.shape)\nprint(\"Metadata shape:\", metadata.shape)\n</pre> # Read data directly from GitHub data_url = \"https://raw.githubusercontent.com/krisrs1128/distortions-data/main/data/c-elegans_qc_final.txt\" metadata_url = \"https://raw.githubusercontent.com/krisrs1128/distortions-data/main/data/c-elegans_qc_final_metadata.txt\"  data = np.loadtxt(data_url, delimiter=\"\\t\") metadata = pd.read_csv(metadata_url, sep=\",\")  print(\"Data shape:\", data.shape) print(\"Metadata shape:\", metadata.shape) <pre>Data shape: (86024, 100)\nMetadata shape: (86024, 15)\n</pre> In\u00a0[3]: Copied! <pre># chech min max value of data\nprint(\"Data min value:\", np.min(data))\nprint(\"Data max value:\", np.max(data))\n</pre> # chech min max value of data print(\"Data min value:\", np.min(data)) print(\"Data max value:\", np.max(data)) <pre>Data min value: -20.558958\nData max value: 26.90514\n</pre> In\u00a0[4]: Copied! <pre>metadata\n</pre> metadata Out[4]: Unnamed: 0 cell n.umi time.point batch Size_Factor cell.type cell.subtype plot.cell.type raw.embryo.time embryo.time embryo.time.bin raw.embryo.time.bin lineage passed_initial_QC_or_later_whitelisted 0 AAACCTGAGACAATAC-300.1.1 AAACCTGAGACAATAC-300.1.1 1630 300_minutes Waterston_300_minutes 1.023195 Body_wall_muscle BWM_head_row_1 BWM_head_row_1 360 380.0 330-390 330-390 MSxpappp True 1 AAACCTGAGGGCTCTC-300.1.1 AAACCTGAGGGCTCTC-300.1.1 2319 300_minutes Waterston_300_minutes 1.458210 NaN NaN NaN 260 220.0 210-270 210-270 MSxapaap True 2 AAACCTGAGTGCGTGA-300.1.1 AAACCTGAGTGCGTGA-300.1.1 3719 300_minutes Waterston_300_minutes 2.338283 NaN NaN NaN 270 230.0 210-270 270-330 NaN True 3 AAACCTGAGTTGAGTA-300.1.1 AAACCTGAGTTGAGTA-300.1.1 4251 300_minutes Waterston_300_minutes 2.659051 Body_wall_muscle BWM_anterior BWM_anterior 260 280.0 270-330 210-270 Dxap True 4 AAACCTGCAAGACGTG-300.1.1 AAACCTGCAAGACGTG-300.1.1 1003 300_minutes Waterston_300_minutes 0.629610 Ciliated_amphid_neuron AFD AFD 350 350.0 330-390 330-390 ABalpppapav/ABpraaaapav True ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 86019 TCTGAGACATGTCGAT-b02 TCTGAGACATGTCGAT-b02 585 mixed Murray_b02 0.364709 Rectal_gland Rectal_gland Rectal_gland 390 700.0 &gt; 650 390-450 NaN True 86020 TCTGAGACATGTCTCC-b02 TCTGAGACATGTCTCC-b02 510 mixed Murray_b02 0.323907 NaN NaN NaN 510 470.0 450-510 510-580 NaN True 86021 TGGCCAGCACGAAGCA-b02 TGGCCAGCACGAAGCA-b02 843 mixed Murray_b02 0.529174 NaN NaN NaN 400 470.0 450-510 390-450 NaN True 86022 TGGCGCACAGGCAGTA-b02 TGGCGCACAGGCAGTA-b02 636 mixed Murray_b02 0.397979 NaN NaN NaN 330 350.0 330-390 330-390 NaN True 86023 TGGGCGTTCAGGCCCA-b02 TGGGCGTTCAGGCCCA-b02 1132 mixed Murray_b02 0.706820 NaN NaN NaN 260 265.0 210-270 210-270 NaN True <p>86024 rows \u00d7 15 columns</p> In\u00a0[5]: Copied! <pre>colors = pd.Categorical(metadata['cell.type']).codes\nlabel_pick = [24, 14, 2, 34]\nfrom collections import defaultdict\n\ndef sampling(source, num_sample, label_pick):    \n    class_indices = defaultdict(list)\n    for idx, label in enumerate(source):\n        class_indices[label].append(idx)\n\n    # Randomly sample points from each class\n    rng = np.random.default_rng(seed=42)  # Set a seed for reproducibility\n    sampled_indices = []\n    for label, indices in class_indices.items():\n        if label in label_pick:\n            n_class_samples = min(len(indices), num_sample)  # Equal sampling\n            sampled_indices.extend(rng.choice(indices, n_class_samples, replace=False))\n    return sampled_indices\n\nsampled_indices = sampling(colors, 1000, label_pick)\n</pre> colors = pd.Categorical(metadata['cell.type']).codes label_pick = [24, 14, 2, 34] from collections import defaultdict  def sampling(source, num_sample, label_pick):         class_indices = defaultdict(list)     for idx, label in enumerate(source):         class_indices[label].append(idx)      # Randomly sample points from each class     rng = np.random.default_rng(seed=42)  # Set a seed for reproducibility     sampled_indices = []     for label, indices in class_indices.items():         if label in label_pick:             n_class_samples = min(len(indices), num_sample)  # Equal sampling             sampled_indices.extend(rng.choice(indices, n_class_samples, replace=False))     return sampled_indices  sampled_indices = sampling(colors, 1000, label_pick) In\u00a0[\u00a0]: Copied! <pre>from scipy.spatial import KDTree\n\ntree = KDTree(data)\ndists, _ = tree.query(data, k=3)\n</pre> from scipy.spatial import KDTree  tree = KDTree(data) dists, _ = tree.query(data, k=3) In\u00a0[\u00a0]: Copied! <pre>n_neighbors = 10\nradius = 3 * np.mean(dists)\ngeom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": 5})\n</pre> n_neighbors = 10 radius = 3 * np.mean(dists) geom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": 5}) In\u00a0[\u00a0]: Copied! <pre># set random seed for reproducibility\nnp.random.seed(42)\nimport umap\nembedding_dumap = umap.UMAP(n_neighbors=10, n_components=2, n_epochs=500, densmap = True).fit_transform(data)\nembedding_umap = umap.UMAP(n_neighbors=10, n_components=2, n_epochs=500, densmap = False).fit_transform(data)\n</pre> # set random seed for reproducibility np.random.seed(42) import umap embedding_dumap = umap.UMAP(n_neighbors=10, n_components=2, n_epochs=500, densmap = True).fit_transform(data) embedding_umap = umap.UMAP(n_neighbors=10, n_components=2, n_epochs=500, densmap = False).fit_transform(data) In\u00a0[\u00a0]: Copied! <pre>plt.figure(figsize=(8, 6))\nfig_umpa =plt.scatter(embedding_umap[:, 0], embedding_umap[:, 1], \n            c=pd.Categorical(metadata['cell.type']).codes, cmap='viridis', s=1)\nplt.colorbar(fig_umpa, label='Cell Type')\nplt.title(\"UMAP Embedding of C.elegans Dataset\")\nplt.xlabel(\"Dimension 1\")\nplt.ylabel(\"Dimension 2\")\nplt.show()\n</pre> plt.figure(figsize=(8, 6)) fig_umpa =plt.scatter(embedding_umap[:, 0], embedding_umap[:, 1],              c=pd.Categorical(metadata['cell.type']).codes, cmap='viridis', s=1) plt.colorbar(fig_umpa, label='Cell Type') plt.title(\"UMAP Embedding of C.elegans Dataset\") plt.xlabel(\"Dimension 1\") plt.ylabel(\"Dimension 2\") plt.show() In\u00a0[\u00a0]: Copied! <pre>plt.figure(figsize=(8, 6))\nfig_umpa =plt.scatter(embedding_dumap[:, 0], embedding_dumap[:, 1], \n            c=pd.Categorical(metadata['cell.type']).codes, cmap='viridis', s=1)\nplt.colorbar(fig_umpa, label='Cell Type')\nplt.title(\"DenseUMAP Embedding of C.elegans Dataset\")\nplt.xlabel(\"Dimension 1\")\nplt.ylabel(\"Dimension 2\")\nplt.show()\n</pre> plt.figure(figsize=(8, 6)) fig_umpa =plt.scatter(embedding_dumap[:, 0], embedding_dumap[:, 1],              c=pd.Categorical(metadata['cell.type']).codes, cmap='viridis', s=1) plt.colorbar(fig_umpa, label='Cell Type') plt.title(\"DenseUMAP Embedding of C.elegans Dataset\") plt.xlabel(\"Dimension 1\") plt.ylabel(\"Dimension 2\") plt.show() In\u00a0[\u00a0]: Copied! <pre># transfer a numpy data to anndata\nimport anndata as ad\nadata = ad.AnnData(X=data[sampled_indices])\nadata.X.shape\nadata.obsm[\"X_UMAP\"] = embedding_umap[sampled_indices]\nadata.obsm[\"X_DenseUMAP\"] = embedding_dumap[sampled_indices]\nadata.obs[\"cell_type\"] = metadata['cell.type'].values[sampled_indices]\nsc.pp.neighbors(adata, n_neighbors=50, n_pcs=40, method='gauss')\n</pre> # transfer a numpy data to anndata import anndata as ad adata = ad.AnnData(X=data[sampled_indices]) adata.X.shape adata.obsm[\"X_UMAP\"] = embedding_umap[sampled_indices] adata.obsm[\"X_DenseUMAP\"] = embedding_dumap[sampled_indices] adata.obs[\"cell_type\"] = metadata['cell.type'].values[sampled_indices] sc.pp.neighbors(adata, n_neighbors=50, n_pcs=40, method='gauss') In\u00a0[\u00a0]: Copied! <pre>umap_embed_test = adata.obsm[\"X_UMAP\"].copy()\ngeom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": radius})\nH, Hvv, Hs = local_distortions(umap_embed_test, adata.X, geom)\numap_embed_test = bind_metric(umap_embed_test, Hvv, Hs)\numap_embed_test[\"cell_type\"] = adata.obs[\"cell_type\"].values\n</pre> umap_embed_test = adata.obsm[\"X_UMAP\"].copy() geom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": radius}) H, Hvv, Hs = local_distortions(umap_embed_test, adata.X, geom) umap_embed_test = bind_metric(umap_embed_test, Hvv, Hs) umap_embed_test[\"cell_type\"] = adata.obs[\"cell_type\"].values In\u00a0[\u00a0]: Copied! <pre>N = neighborhoods(adata, threshold=.2, outlier_factor=2, method=\"box\", embed_key=\"X_UMAP\")\ndplot(umap_embed_test, width=600, height=500)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\\n    .geom_ellipse(radiusMax=8, radiusMin=2)\\\n    .scale_color(legendTextSize=8)\\\n    .labs(x=\"UMAP 1\", y=\"UMAP 2\")\\\n    .inter_edge_link(N=N, threshold=1, backgroundOpacity=0.4, strokeWidth=0.1, strokeOpacity=1, highlightStrokeWidth=0.1)\n</pre> N = neighborhoods(adata, threshold=.2, outlier_factor=2, method=\"box\", embed_key=\"X_UMAP\") dplot(umap_embed_test, width=600, height=500)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\     .geom_ellipse(radiusMax=8, radiusMin=2)\\     .scale_color(legendTextSize=8)\\     .labs(x=\"UMAP 1\", y=\"UMAP 2\")\\     .inter_edge_link(N=N, threshold=1, backgroundOpacity=0.4, strokeWidth=0.1, strokeOpacity=1, highlightStrokeWidth=0.1) In\u00a0[\u00a0]: Copied! <pre>from distortions.geometry import Geometry, bind_metric, local_distortions\ndumap_embed_test = adata.obsm[\"X_DenseUMAP\"].copy()\ngeom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": radius})\nH, Hvv, Hs = local_distortions(dumap_embed_test, adata.X, geom)\ndumap_embed_test = bind_metric(dumap_embed_test, Hvv, Hs)\ndumap_embed_test[\"cell_type\"] = adata.obs[\"cell_type\"].values\n</pre> from distortions.geometry import Geometry, bind_metric, local_distortions dumap_embed_test = adata.obsm[\"X_DenseUMAP\"].copy() geom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": radius}) H, Hvv, Hs = local_distortions(dumap_embed_test, adata.X, geom) dumap_embed_test = bind_metric(dumap_embed_test, Hvv, Hs) dumap_embed_test[\"cell_type\"] = adata.obs[\"cell_type\"].values In\u00a0[\u00a0]: Copied! <pre>N = neighborhoods(adata, threshold=.02, outlier_factor=2, method=\"box\", embed_key=\"X_UMAP\")\ndplot(dumap_embed_test, width=600, height=500)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\\n    .geom_ellipse()\\\n    .scale_color(legendTextSize=8)\\\n    .labs(x=\"DenseUMAP 1\", y=\"DenseUMAP 2\")\\\n    .inter_edge_link(N=N, threshold=1, backgroundOpacity=0.4, strokeWidth=0.1, strokeOpacity=1, highlightStrokeWidth=0.1)\n</pre> N = neighborhoods(adata, threshold=.02, outlier_factor=2, method=\"box\", embed_key=\"X_UMAP\") dplot(dumap_embed_test, width=600, height=500)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\     .geom_ellipse()\\     .scale_color(legendTextSize=8)\\     .labs(x=\"DenseUMAP 1\", y=\"DenseUMAP 2\")\\     .inter_edge_link(N=N, threshold=1, backgroundOpacity=0.4, strokeWidth=0.1, strokeOpacity=1, highlightStrokeWidth=0.1) In\u00a0[\u00a0]: Copied! <pre>from distortions.geometry.neighborhoods import broken_knn, neighbor_generator\n\nbrokens = broken_knn(adata.obsm['X_UMAP'], k=5, z_thresh=2.0) # after I found the broken points\nbroken_neighbors = neighbor_generator(embedding_umap, [sampled_indices[i] for i in brokens], number_neighbor=10) # generate neighbor dict\nbroken_neighbors\n</pre> from distortions.geometry.neighborhoods import broken_knn, neighbor_generator  brokens = broken_knn(adata.obsm['X_UMAP'], k=5, z_thresh=2.0) # after I found the broken points broken_neighbors = neighbor_generator(embedding_umap, [sampled_indices[i] for i in brokens], number_neighbor=10) # generate neighbor dict broken_neighbors In\u00a0[\u00a0]: Copied! <pre>#broken_neighbors[52388]\nbroken_neighbors[57113]\n</pre> #broken_neighbors[52388] broken_neighbors[57113] In\u00a0[\u00a0]: Copied! <pre>#point = 52388\npoint = 57113\nadata_add = ad.AnnData(X=data[sampled_indices+ broken_neighbors[point]])\nadata_add.obsm[\"X_DUMAP\"] = embedding_umap[sampled_indices + broken_neighbors[point]]\n</pre> #point = 52388 point = 57113 adata_add = ad.AnnData(X=data[sampled_indices+ broken_neighbors[point]]) adata_add.obsm[\"X_DUMAP\"] = embedding_umap[sampled_indices + broken_neighbors[point]] In\u00a0[\u00a0]: Copied! <pre>from distortions.visualization import dplot\ngeom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": radius})\nH, Hvv, Hs = local_distortions(adata.obsm['X_DenseUMAP'], adata.X, geom)\nembedding_test_1 = bind_metric(embedding_umap[sampled_indices], Hvv, Hs)\nembedding_test_1[\"cell_type\"] = pd.Categorical(metadata['cell.type'])[sampled_indices]\nmetrics = {k: H[k] for k in range(len(H))}\ndplot(embedding_test_1, width=900, height=500)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", angle=\"angle\", a=\"s0\", b=\"s1\", color=\"cell_type\")\\\n    .geom_ellipse()\\\n    .inter_isometry(metrics=metrics, metric_bw=3, transformation_bw=1)\\\n    .scale_color()\\\n    .labs(x=\"x-axis\", y=\"y-axis\")\n</pre> from distortions.visualization import dplot geom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": radius}) H, Hvv, Hs = local_distortions(adata.obsm['X_DenseUMAP'], adata.X, geom) embedding_test_1 = bind_metric(embedding_umap[sampled_indices], Hvv, Hs) embedding_test_1[\"cell_type\"] = pd.Categorical(metadata['cell.type'])[sampled_indices] metrics = {k: H[k] for k in range(len(H))} dplot(embedding_test_1, width=900, height=500)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", angle=\"angle\", a=\"s0\", b=\"s1\", color=\"cell_type\")\\     .geom_ellipse()\\     .inter_isometry(metrics=metrics, metric_bw=3, transformation_bw=1)\\     .scale_color()\\     .labs(x=\"x-axis\", y=\"y-axis\") In\u00a0[\u00a0]: Copied! <pre>geom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": 5})\nH, Hvv, Hs = local_distortions(adata_add.obsm[\"X_DUMAP\"], adata_add.X, geom)\nembedding_test_2 = bind_metric(embedding_dumap[sampled_indices + broken_neighbors[point]], Hvv, Hs)\nembedding_test_2[\"cell_type\"] = pd.Categorical(metadata['cell.type'])[sampled_indices + broken_neighbors[point]]\nmetrics = {k: H[k] for k in range(len(H))}\ndplot(embedding_test_2, width=900, height=500)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", angle=\"angle\", a=\"s0\", b=\"s1\", color=\"cell_type\")\\\n    .geom_ellipse()\\\n    .inter_isometry(metrics=metrics, metric_bw=3, transformation_bw=1)\\\n    .scale_color()\\\n    .labs(x=\"x-axis\", y=\"y-axis\")\n</pre> geom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": 5}) H, Hvv, Hs = local_distortions(adata_add.obsm[\"X_DUMAP\"], adata_add.X, geom) embedding_test_2 = bind_metric(embedding_dumap[sampled_indices + broken_neighbors[point]], Hvv, Hs) embedding_test_2[\"cell_type\"] = pd.Categorical(metadata['cell.type'])[sampled_indices + broken_neighbors[point]] metrics = {k: H[k] for k in range(len(H))} dplot(embedding_test_2, width=900, height=500)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", angle=\"angle\", a=\"s0\", b=\"s1\", color=\"cell_type\")\\     .geom_ellipse()\\     .inter_isometry(metrics=metrics, metric_bw=3, transformation_bw=1)\\     .scale_color()\\     .labs(x=\"x-axis\", y=\"y-axis\") In\u00a0[\u00a0]: Copied! <pre>dplot(embedding_test_1, width=700, height=500)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", angle=\"angle\", a=\"s0\", b=\"s1\", color=\"cell_type\")\\\n    .geom_hair(radiusMin=1, radiusMax=20)\\\n    .scale_color(legendTextSize=7)\\\n    .labs(x=\"UMAP-x\", y=\"UMAP-y\")\n</pre> dplot(embedding_test_1, width=700, height=500)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", angle=\"angle\", a=\"s0\", b=\"s1\", color=\"cell_type\")\\     .geom_hair(radiusMin=1, radiusMax=20)\\     .scale_color(legendTextSize=7)\\     .labs(x=\"UMAP-x\", y=\"UMAP-y\") In\u00a0[\u00a0]: Copied! <pre>dplot(embedding_test_2, width=700, height=500)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", angle=\"angle\", a=\"s0\", b=\"s1\", color=\"cell_type\")\\\n    .geom_hair()\\\n    .scale_color(legendTextSize=7)\\\n    .labs(x=\"DensMAP-x\", y=\"DensMAP-y\")\n</pre> dplot(embedding_test_2, width=700, height=500)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", angle=\"angle\", a=\"s0\", b=\"s1\", color=\"cell_type\")\\     .geom_hair()\\     .scale_color(legendTextSize=7)\\     .labs(x=\"DensMAP-x\", y=\"DensMAP-y\") In\u00a0[\u00a0]: Copied! <pre>rng = np.random.default_rng(seed=42)\n\ncell_types = metadata['cell.type'].dropna().unique()\nselected_types = rng.choice(cell_types, size=10, replace=False)\n\nn_per_type = 5000\nrandom_indices = []\nfor ct in selected_types:\n    idx = metadata.index[metadata['cell.type'] == ct].to_numpy()\n    k = min(len(idx), n_per_type)\n    random_indices.extend(rng.choice(idx, size=k, replace=False).tolist())\n\n\nadata_random = ad.AnnData(X=data[random_indices])\nadata_random.obsm[\"X_UMAP\"] = embedding_umap[random_indices]\nadata_random.obsm[\"X_DenseUMAP\"] = embedding_dumap[random_indices]\nadata_random.obs[\"cell_type\"] = metadata['cell.type'].values[random_indices]\nsc.pp.neighbors(adata_random, n_neighbors=50, n_pcs=40, method='gauss')\n</pre> rng = np.random.default_rng(seed=42)  cell_types = metadata['cell.type'].dropna().unique() selected_types = rng.choice(cell_types, size=10, replace=False)  n_per_type = 5000 random_indices = [] for ct in selected_types:     idx = metadata.index[metadata['cell.type'] == ct].to_numpy()     k = min(len(idx), n_per_type)     random_indices.extend(rng.choice(idx, size=k, replace=False).tolist())   adata_random = ad.AnnData(X=data[random_indices]) adata_random.obsm[\"X_UMAP\"] = embedding_umap[random_indices] adata_random.obsm[\"X_DenseUMAP\"] = embedding_dumap[random_indices] adata_random.obs[\"cell_type\"] = metadata['cell.type'].values[random_indices] sc.pp.neighbors(adata_random, n_neighbors=50, n_pcs=40, method='gauss') In\u00a0[\u00a0]: Copied! <pre>selected_types\n</pre> selected_types In\u00a0[\u00a0]: Copied! <pre>umap_embed_test = adata_random.obsm[\"X_UMAP\"].copy()\ngeom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": 2})\nH, Hvv, Hs = local_distortions(umap_embed_test, adata_random.X, geom)\numap_embed_test = bind_metric(umap_embed_test, Hvv, Hs)\numap_embed_test[\"cell_type\"] = adata_random.obs[\"cell_type\"].values\nsummary = {\"umap_kappa\": Hs[:, 0] / Hs[:, 1], \"umap_vol\": Hs[:, 0] * Hs[:, 1]}\n\nplots = {}\nN = {\n    \"UMAP\": neighborhoods(adata_random, threshold=.4, outlier_factor=3, embed_key=\"X_UMAP\"),\n    \"DensMAP\": neighborhoods(adata_random, threshold=.4, outlier_factor=3, embed_key=\"X_DenseUMAP\")\n}\n\nplots[\"UMAP_p\"] = dplot(umap_embed_test, width=600, height=500)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\\n    .geom_ellipse(radiusMin=1, radiusMax=20)\\\n    .scale_color(legendTextSize=8)\\\n    .labs(x=\"UMAP 1\", y=\"UMAP 2\")\\\n    .inter_edge_link(N=N[\"UMAP\"], threshold=1, backgroundOpacity=0.3, strokeWidth=0.1, strokeOpacity=1, highlightStrokeWidth=1)\n</pre> umap_embed_test = adata_random.obsm[\"X_UMAP\"].copy() geom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": 2}) H, Hvv, Hs = local_distortions(umap_embed_test, adata_random.X, geom) umap_embed_test = bind_metric(umap_embed_test, Hvv, Hs) umap_embed_test[\"cell_type\"] = adata_random.obs[\"cell_type\"].values summary = {\"umap_kappa\": Hs[:, 0] / Hs[:, 1], \"umap_vol\": Hs[:, 0] * Hs[:, 1]}  plots = {} N = {     \"UMAP\": neighborhoods(adata_random, threshold=.4, outlier_factor=3, embed_key=\"X_UMAP\"),     \"DensMAP\": neighborhoods(adata_random, threshold=.4, outlier_factor=3, embed_key=\"X_DenseUMAP\") }  plots[\"UMAP_p\"] = dplot(umap_embed_test, width=600, height=500)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\     .geom_ellipse(radiusMin=1, radiusMax=20)\\     .scale_color(legendTextSize=8)\\     .labs(x=\"UMAP 1\", y=\"UMAP 2\")\\     .inter_edge_link(N=N[\"UMAP\"], threshold=1, backgroundOpacity=0.3, strokeWidth=0.1, strokeOpacity=1, highlightStrokeWidth=1) In\u00a0[\u00a0]: Copied! <pre>dumap_embed_test = adata_random.obsm[\"X_DenseUMAP\"].copy()\ngeom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": 2})\nH, Hvv, Hs = local_distortions(dumap_embed_test, adata_random.X, geom)\ndumap_embed_test = bind_metric(dumap_embed_test, Hvv, Hs)\ndumap_embed_test[\"cell_type\"] = adata_random.obs[\"cell_type\"].values\nplots[\"DensMAP_p\"] = dplot(dumap_embed_test, width=600, height=500)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\\n    .geom_ellipse(radiusMin=1, radiusMax=20)\\\n    .scale_color(legendTextSize=8)\\\n    .labs(x=\"DensMAP 1\", y=\"DensMAP 2\")\\\n    .inter_edge_link(N=N[\"DensMAP\"], threshold=1, backgroundOpacity=0.3, strokeWidth=0.1, strokeOpacity=1, highlightStrokeWidth=1)\n</pre> dumap_embed_test = adata_random.obsm[\"X_DenseUMAP\"].copy() geom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": 2}) H, Hvv, Hs = local_distortions(dumap_embed_test, adata_random.X, geom) dumap_embed_test = bind_metric(dumap_embed_test, Hvv, Hs) dumap_embed_test[\"cell_type\"] = adata_random.obs[\"cell_type\"].values plots[\"DensMAP_p\"] = dplot(dumap_embed_test, width=600, height=500)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\     .geom_ellipse(radiusMin=1, radiusMax=20)\\     .scale_color(legendTextSize=8)\\     .labs(x=\"DensMAP 1\", y=\"DensMAP 2\")\\     .inter_edge_link(N=N[\"DensMAP\"], threshold=1, backgroundOpacity=0.3, strokeWidth=0.1, strokeOpacity=1, highlightStrokeWidth=1) In\u00a0[\u00a0]: Copied! <pre>metrics = {k: H[k] for k in range(len(H))}\nplots[\"normal_hair\"] = dplot(umap_embed_test, width=600, height=500)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", angle=\"angle\", a=\"s0\", b=\"s1\", color=\"cell_type\")\\\n    .geom_hair(radiusMin=1)\\\n    .scale_color(legendTextSize=7)\\\n    .labs(x=\"UMAP 1\", y=\"UMAP 2\")\\\n    .inter_edge_link(N=N[\"UMAP\"], threshold=1, backgroundOpacity=0.3, strokeWidth=0.1, strokeOpacity=1, highlightStrokeWidth=1, otherClasses=[\"hair\"])\n</pre> metrics = {k: H[k] for k in range(len(H))} plots[\"normal_hair\"] = dplot(umap_embed_test, width=600, height=500)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", angle=\"angle\", a=\"s0\", b=\"s1\", color=\"cell_type\")\\     .geom_hair(radiusMin=1)\\     .scale_color(legendTextSize=7)\\     .labs(x=\"UMAP 1\", y=\"UMAP 2\")\\     .inter_edge_link(N=N[\"UMAP\"], threshold=1, backgroundOpacity=0.3, strokeWidth=0.1, strokeOpacity=1, highlightStrokeWidth=1, otherClasses=[\"hair\"]) In\u00a0[\u00a0]: Copied! <pre>plots[\"dense_hair\"] = dplot(dumap_embed_test, width=600, height=500)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", angle=\"angle\", a=\"s0\", b=\"s1\", color=\"cell_type\")\\\n    .geom_hair(radiusMin=1)\\\n    .scale_color(legendTextSize=8)\\\n    .labs(x=\"DensMAP 1\", y=\"DensMAP 2\")\\\n    .inter_edge_link(N=N[\"DensMAP\"], threshold=1, backgroundOpacity=0.3, strokeWidth=0.1, strokeOpacity=1, highlightStrokeWidth=1, otherClasses=[\"hair\"])\n</pre> plots[\"dense_hair\"] = dplot(dumap_embed_test, width=600, height=500)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", angle=\"angle\", a=\"s0\", b=\"s1\", color=\"cell_type\")\\     .geom_hair(radiusMin=1)\\     .scale_color(legendTextSize=8)\\     .labs(x=\"DensMAP 1\", y=\"DensMAP 2\")\\     .inter_edge_link(N=N[\"DensMAP\"], threshold=1, backgroundOpacity=0.3, strokeWidth=0.1, strokeOpacity=1, highlightStrokeWidth=1, otherClasses=[\"hair\"]) In\u00a0[\u00a0]: Copied! <pre>summary[\"densmap_kappa\"] = Hs[:, 0] / Hs[:, 1]\nsummary[\"densmap_vol\"] = Hs[:, 0] * Hs[:, 1]\ndf_kappa = pd.concat([\n    pd.DataFrame({'ratio': np.log(summary[\"umap_kappa\"]), 'method': 'umap', 'cell_type': adata_random.obs['cell_type']}),\n    pd.DataFrame({'ratio': np.log(summary[\"densmap_kappa\"]), 'method': 'densmap'})\n])\n\nkappa_p = alt.Chart(df_kappa).mark_bar(opacity=0.8).encode(\n    x=alt.X('ratio', bin=alt.Bin(maxbins=50)),\n    y=alt.Y('count()', stack=None),\n    color=alt.Color('method:N', legend=alt.Legend(title=\"Method\"))\n).properties(width=400, height=300)\n#kappa_p.save(\"../../paper/figures/kappa_p.svg\")\n</pre> summary[\"densmap_kappa\"] = Hs[:, 0] / Hs[:, 1] summary[\"densmap_vol\"] = Hs[:, 0] * Hs[:, 1] df_kappa = pd.concat([     pd.DataFrame({'ratio': np.log(summary[\"umap_kappa\"]), 'method': 'umap', 'cell_type': adata_random.obs['cell_type']}),     pd.DataFrame({'ratio': np.log(summary[\"densmap_kappa\"]), 'method': 'densmap'}) ])  kappa_p = alt.Chart(df_kappa).mark_bar(opacity=0.8).encode(     x=alt.X('ratio', bin=alt.Bin(maxbins=50)),     y=alt.Y('count()', stack=None),     color=alt.Color('method:N', legend=alt.Legend(title=\"Method\")) ).properties(width=400, height=300) #kappa_p.save(\"../../paper/figures/kappa_p.svg\") In\u00a0[\u00a0]: Copied! <pre>#[p.save(f\"../../paper/figures/{k}.svg\") for k, p in plots.items()]\n</pre> #[p.save(f\"../../paper/figures/{k}.svg\") for k, p in plots.items()] In\u00a0[\u00a0]: Copied! <pre>[display(p) for p in plots.values()]\n</pre> [display(p) for p in plots.values()] In\u00a0[\u00a0]: Copied! <pre>from tqdm.notebook import tqdm\n\nthresholds = np.arange(0.05, 1.0, 0.05)\nnum_keys = {\"UMAP\": [], \"DensMAP\": []}\n\nfor t in tqdm(thresholds, desc=\"Calculating neighborhood sizes...\"):\n    N_umap = neighborhoods(adata_random, threshold=t, outlier_factor=3, embed_key=\"X_UMAP\")\n    N_densmap = neighborhoods(adata_random, threshold=t, outlier_factor=3, embed_key=\"X_DenseUMAP\")\n    num_keys[\"UMAP\"].append(len(N_umap))\n    num_keys[\"DensMAP\"].append(len(N_densmap))\n</pre> from tqdm.notebook import tqdm  thresholds = np.arange(0.05, 1.0, 0.05) num_keys = {\"UMAP\": [], \"DensMAP\": []}  for t in tqdm(thresholds, desc=\"Calculating neighborhood sizes...\"):     N_umap = neighborhoods(adata_random, threshold=t, outlier_factor=3, embed_key=\"X_UMAP\")     N_densmap = neighborhoods(adata_random, threshold=t, outlier_factor=3, embed_key=\"X_DenseUMAP\")     num_keys[\"UMAP\"].append(len(N_umap))     num_keys[\"DensMAP\"].append(len(N_densmap)) In\u00a0[\u00a0]: Copied! <pre>distortion_size = alt.Chart(\n    pd.DataFrame({\n        \"threshold\": np.tile(np.round(thresholds, 2), 2),\n        \"Method\": np.concatenate([[\"UMAP\"] * len(thresholds), [\"DensMAP\"] * len(thresholds)]),\n        \"Count\": np.concatenate([num_keys[\"UMAP\"], num_keys[\"DensMAP\"]])\n        })\n    ).mark_bar().encode(\n        x=alt.X(\"threshold:N\", title=\"Threshold Fraction\"),\n        y=alt.Y(\"Count:Q\", title=\"Number of Distorted Neighborhoods\"),\n        color=alt.Color(\"Method:N\", title=\"Method\")\n    )\n\n#distortion_size.save(\"../../paper/figures/distortion_size.svg\")\n</pre> distortion_size = alt.Chart(     pd.DataFrame({         \"threshold\": np.tile(np.round(thresholds, 2), 2),         \"Method\": np.concatenate([[\"UMAP\"] * len(thresholds), [\"DensMAP\"] * len(thresholds)]),         \"Count\": np.concatenate([num_keys[\"UMAP\"], num_keys[\"DensMAP\"]])         })     ).mark_bar().encode(         x=alt.X(\"threshold:N\", title=\"Threshold Fraction\"),         y=alt.Y(\"Count:Q\", title=\"Number of Distorted Neighborhoods\"),         color=alt.Color(\"Method:N\", title=\"Method\")     )  #distortion_size.save(\"../../paper/figures/distortion_size.svg\") In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorials/c_elegans.html#umap-and-denseumap","title":"UMAP and DenseUmap\u00b6","text":""},{"location":"tutorials/custom_neighbors.html","title":"Interacting with scDEED Flagged Neighborhoods","text":"In\u00a0[1]: Copied! <pre>import scanpy as sc\n\ncounts = sc.datasets.pbmc3k().X.todense().T\n%load_ext rpy2.ipython\n</pre> import scanpy as sc  counts = sc.datasets.pbmc3k().X.todense().T %load_ext rpy2.ipython In\u00a0[2]: Copied! <pre>%%R -i counts\n\nlibrary(tidyverse)\nlibrary(Seurat)\nlibrary(scDEED)\n\nperplexity &lt;- 40\ndata &lt;- CreateSeuratObject(counts) |&gt;\n    FindVariableFeatures() |&gt;\n    NormalizeData() |&gt;\n    ScaleData() |&gt;\n    RunPCA() |&gt;\n    RunTSNE(perplexity=perplexity)\n</pre> %%R -i counts  library(tidyverse) library(Seurat) library(scDEED)  perplexity &lt;- 40 data &lt;- CreateSeuratObject(counts) |&gt;     FindVariableFeatures() |&gt;     NormalizeData() |&gt;     ScaleData() |&gt;     RunPCA() |&gt;     RunTSNE(perplexity=perplexity) <pre>\u2500\u2500 Attaching core tidyverse packages \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 tidyverse 2.0.0 \u2500\u2500\n\u2714 dplyr     1.1.4     \u2714 readr     2.1.5\n\u2714 forcats   1.0.0     \u2714 stringr   1.5.1\n\u2714 ggplot2   3.5.2     \u2714 tibble    3.3.0\n\u2714 lubridate 1.9.4     \u2714 tidyr     1.3.1\n\u2714 purrr     1.1.0     \n\u2500\u2500 Conflicts \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 tidyverse_conflicts() \u2500\u2500\n\u2716 dplyr::filter() masks stats::filter()\n\u2716 dplyr::lag()    masks stats::lag()\n\u2139 Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n    WARNING: The R package \"reticulate\" only fixed recently\n    an issue that caused a segfault when used with rpy2:\n    https://github.com/rstudio/reticulate/pull/1188\n    Make sure that you use a version of that package that includes\n    the fix.\n    </pre> <pre>Loading required package: SeuratObject\nLoading required package: sp\n\u2018SeuratObject\u2019 was built under R 4.5.0 but the current version is\n4.5.1; it is recomended that you reinstall \u2018SeuratObject\u2019 as the ABI\nfor R may have changed\n\nAttaching package: \u2018SeuratObject\u2019\n\nThe following objects are masked from \u2018package:base\u2019:\n\n    intersect, t\n\n\nAttaching package: \u2018scDEED\u2019\n\nThe following object is masked from \u2018package:stats\u2019:\n\n    optimize\n\nWarning: Data is of class matrix. Coercing to dgCMatrix.\nFinding variable features for layer counts\nCalculating gene variances\n0%   10   20   30   40   50   60   70   80   90   100%\n[----|----|----|----|----|----|----|----|----|----|\n**************************************************|\nCalculating feature variances of standardized and clipped values\n0%   10   20   30   40   50   60   70   80   90   100%\n[----|----|----|----|----|----|----|----|----|----|\n**************************************************|\nNormalizing layer: counts\nPerforming log-normalization\n0%   10   20   30   40   50   60   70   80   90   100%\n[----|----|----|----|----|----|----|----|----|----|\n**************************************************|\nCentering and scaling data matrix\n\r  |                                                                            \r  |                                                                      |   0%\r  |                                                                            \r  |===================================                                   |  50%\r  |                                                                            \r  |======================================================================| 100%\nPC_ 1 \nPositive:  Feature28818, Feature30430, Feature10609, Feature10611, Feature30934, Feature16745, Feature21054, Feature18999, Feature1956, Feature2225 \n\t   Feature32216, Feature29429, Feature31964, Feature1958, Feature1846, Feature31959, Feature23264, Feature18773, Feature18149, Feature17465 \n\t   Feature13509, Feature13383, Feature30115, Feature25893, Feature1903, Feature23057, Feature22827, Feature19264, Feature25268, Feature2483 \nNegative:  Feature19155, Feature10608, Feature24758, Feature1636, Feature26263, Feature12205, Feature19180, Feature2301, Feature26825, Feature13131 \n\t   Feature15831, Feature8890, Feature28833, Feature2760, Feature4088, Feature7587, Feature13779, Feature8887, Feature15412, Feature13126 \n\t   Feature13862, Feature19991, Feature532, Feature4134, Feature7224, Feature18406, Feature9383, Feature31076, Feature20238, Feature11419 \nPC_ 2 \nPositive:  Feature30657, Feature18945, Feature23289, Feature10681, Feature10678, Feature10682, Feature23927, Feature27508, Feature10680, Feature9799 \n\t   Feature10701, Feature10696, Feature10685, Feature10679, Feature10700, Feature10694, Feature2243, Feature21419, Feature10608, Feature17729 \n\t   Feature23476, Feature26139, Feature25915, Feature31683, Feature18431, Feature7803, Feature7465, Feature30509, Feature2121, Feature25909 \nNegative:  Feature31076, Feature17450, Feature28833, Feature8890, Feature22590, Feature7345, Feature19180, Feature4047, Feature22589, Feature7170 \n\t   Feature26840, Feature2238, Feature26825, Feature2301, Feature2317, Feature16816, Feature16916, Feature17424, Feature7587, Feature19539 \n\t   Feature32158, Feature1965, Feature16089, Feature24758, Feature7593, Feature3295, Feature11888, Feature2318, Feature32017, Feature11419 \nPC_ 3 \nPositive:  Feature10681, Feature30657, Feature27508, Feature10682, Feature10701, Feature9799, Feature10700, Feature18945, Feature10680, Feature10679 \n\t   Feature10678, Feature10685, Feature23289, Feature23927, Feature10694, Feature10696, Feature21419, Feature2243, Feature25915, Feature17729 \n\t   Feature23476, Feature7465, Feature23451, Feature26139, Feature31683, Feature18431, Feature12405, Feature4028, Feature7669, Feature9601 \nNegative:  Feature7697, Feature7696, Feature4865, Feature9825, Feature12535, Feature19923, Feature6459, Feature2538, Feature29270, Feature14587 \n\t   Feature10421, Feature19444, Feature27143, Feature20143, Feature5519, Feature15067, Feature10867, Feature20164, Feature27373, Feature13865 \n\t   Feature10828, Feature10241, Feature10110, Feature31597, Feature14266, Feature22002, Feature22527, Feature10390, Feature28980, Feature26183 \nPC_ 4 \nPositive:  Feature10681, Feature10421, Feature7696, Feature4865, Feature30657, Feature27508, Feature7697, Feature12535, Feature9825, Feature10682 \n\t   Feature18945, Feature9799, Feature6459, Feature10701, Feature19923, Feature2538, Feature10867, Feature20143, Feature19444, Feature10685 \n\t   Feature14587, Feature29270, Feature15067, Feature10680, Feature10700, Feature27143, Feature5519, Feature10678, Feature23289, Feature20164 \nNegative:  Feature17040, Feature1958, Feature1963, Feature1965, Feature4028, Feature1956, Feature24758, Feature13126, Feature1901, Feature31959 \n\t   Feature232, Feature4088, Feature16745, Feature21054, Feature1636, Feature1957, Feature18938, Feature8803, Feature1903, Feature15831 \n\t   Feature13127, Feature19354, Feature16089, Feature19155, Feature10611, Feature13131, Feature7692, Feature595, Feature4026, Feature26245 \nPC_ 5 \nPositive:  Feature10608, Feature17040, Feature15831, Feature17443, Feature4088, Feature24011, Feature1636, Feature19254, Feature4582, Feature8803 \n\t   Feature24758, Feature25589, Feature8033, Feature20638, Feature27657, Feature27929, Feature20905, Feature13779, Feature25893, Feature22260 \n\t   Feature27827, Feature9383, Feature16960, Feature2760, Feature17357, Feature13127, Feature925, Feature11512, Feature13865, Feature532 \nNegative:  Feature22590, Feature7345, Feature31076, Feature4047, Feature17450, Feature26840, Feature28833, Feature7170, Feature8890, Feature16816 \n\t   Feature22589, Feature2317, Feature19180, Feature32158, Feature16916, Feature26825, Feature7593, Feature2318, Feature1958, Feature26839 \n\t   Feature30430, Feature7587, Feature1737, Feature9855, Feature1956, Feature2225, Feature22798, Feature31959, Feature232, Feature1957 \n</pre> In\u00a0[3]: Copied! <pre>%%R\n\nembeddings &lt;- Embeddings(data, \"tsne\")\nnormalized_counts &lt;- GetAssayData(data, layer = \"scale.data\") |&gt;\n    as.matrix() |&gt;\n    t()\n</pre> %%R  embeddings &lt;- Embeddings(data, \"tsne\") normalized_counts &lt;- GetAssayData(data, layer = \"scale.data\") |&gt;     as.matrix() |&gt;     t() In\u00a0[4]: Copied! <pre>import numpy as np\nimport rpy2.robjects\n\nembeddings = np.array(rpy2.robjects.globalenv['embeddings'])\nnormalized_counts = np.array(rpy2.robjects.globalenv[\"normalized_counts\"])\n</pre> import numpy as np import rpy2.robjects  embeddings = np.array(rpy2.robjects.globalenv['embeddings']) normalized_counts = np.array(rpy2.robjects.globalenv[\"normalized_counts\"]) In\u00a0[5]: Copied! <pre>%%R\n\nK &lt;- 8\nresult &lt;- scDEED(data, K = K, reduction.method = 'tsne', rerun = F, perplexity = perplexity)\ndubious &lt;- result$full_results |&gt;\n    filter(perplexity == perplexity) |&gt;\n    pull(dubious_cells) |&gt;\n    str_split(\",\")\n\ndubious &lt;- as.integer(dubious[[1]])\n\ndata &lt;- FindNeighbors(data, features = VariableFeatures(data), k.param = 50)\nG &lt;- data@graphs$RNA_nn\nN &lt;- map(dubious, ~ which(G[.x, ] &gt; 0)) |&gt;\n    set_names(dubious)\n</pre> %%R  K &lt;- 8 result &lt;- scDEED(data, K = K, reduction.method = 'tsne', rerun = F, perplexity = perplexity) dubious &lt;- result$full_results |&gt;     filter(perplexity == perplexity) |&gt;     pull(dubious_cells) |&gt;     str_split(\",\")  dubious &lt;- as.integer(dubious[[1]])  data &lt;- FindNeighbors(data, features = VariableFeatures(data), k.param = 50) G &lt;- data@graphs$RNA_nn N &lt;- map(dubious, ~ which(G[.x, ] &gt; 0)) |&gt;     set_names(dubious) <pre>[1] \"Permuting data\"\n  |======================================================================| 100%[1] \"Permutation finished\"\n</pre> <pre>Warning: Number of dimensions changing from 50 to 8\nComputing nearest neighbor graph\nComputing SNN\nIn addition: Warning messages:\n1: The `slot` argument of `GetAssayData()` is deprecated as of SeuratObject 5.0.0.\n\u2139 Please use the `layer` argument instead.\n\u2139 The deprecated feature was likely used in the scDEED package.\n  Please report the issue to the authors.\nThis warning is displayed once every 8 hours.\nCall `lifecycle::last_lifecycle_warnings()` to see where this warning was\ngenerated. \n2: The `slot` argument of `SetAssayData()` is deprecated as of SeuratObject 5.0.0.\n\u2139 Please use the `layer` argument instead.\n\u2139 The deprecated feature was likely used in the scDEED package.\n  Please report the issue to the authors.\nThis warning is displayed once every 8 hours.\nCall `lifecycle::last_lifecycle_warnings()` to see where this warning was\ngenerated. \n</pre> In\u00a0[6]: Copied! <pre>from distortions.geometry import Geometry, bind_metric, local_distortions\n\ngeom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": 20}, adjacency_kwds={\"radius\": 50}, laplacian_kwds={\"scaling_epps\": 5})\nH, Hvv, Hs = local_distortions(embeddings, normalized_counts, geom)\nembeddings = bind_metric(embeddings, Hvv, Hs)\nN = rpy2.robjects.globalenv[\"N\"]\nN_dict = {int(key): list(val) for key, val in N.items()}\n</pre> from distortions.geometry import Geometry, bind_metric, local_distortions  geom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": 20}, adjacency_kwds={\"radius\": 50}, laplacian_kwds={\"scaling_epps\": 5}) H, Hvv, Hs = local_distortions(embeddings, normalized_counts, geom) embeddings = bind_metric(embeddings, Hvv, Hs) N = rpy2.robjects.globalenv[\"N\"] N_dict = {int(key): list(val) for key, val in N.items()} In\u00a0[7]: Copied! <pre>from distortions.visualization import dplot\n\nplots = {}\nplots[\"scdeed_distort\"] = dplot(embeddings, width=440, height=440)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\")\\\n    .geom_ellipse(radiusMax=10, radiusMin=1)\\\n    .inter_edge_link(N=N_dict, stroke=\"#F25E7A\", highlightColor=\"#C83F58\", strokeWidth=.4, highlightStrokeWidth=5, threshold=10, backgroundOpacity=0.5)\n</pre> from distortions.visualization import dplot  plots = {} plots[\"scdeed_distort\"] = dplot(embeddings, width=440, height=440)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\")\\     .geom_ellipse(radiusMax=10, radiusMin=1)\\     .inter_edge_link(N=N_dict, stroke=\"#F25E7A\", highlightColor=\"#C83F58\", strokeWidth=.4, highlightStrokeWidth=5, threshold=10, backgroundOpacity=0.5) In\u00a0[8]: Copied! <pre>#[p.save(f\"../paper/figures/{k}.svg\") for k, p in plots.items()]\n</pre> #[p.save(f\"../paper/figures/{k}.svg\") for k, p in plots.items()] In\u00a0[9]: Copied! <pre>[display(p) for p in plots.values()]\n</pre> [display(p) for p in plots.values()] <pre>dplot(dataset=[{'embedding_0': 5.783105882455072, 'embedding_1': -12.634558999702302, 'x0': -0.303412665270283\u2026</pre> Out[9]: <pre>[None]</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorials/fixed_transform.html","title":"Understanding Isometrization with a Known Transformation","text":"In\u00a0[1]: Copied! <pre>import random\nimport numpy as np\nimport pandas as pd\nrandom.seed(20250409)\n\nN = 500\nu = np.random.uniform(0, 1, (N, 2))\nu_df = pd.DataFrame(u, columns=['x', 'y'])\n</pre> import random import numpy as np import pandas as pd random.seed(20250409)  N = 500 u = np.random.uniform(0, 1, (N, 2)) u_df = pd.DataFrame(u, columns=['x', 'y']) In\u00a0[2]: Copied! <pre>from distortions.geometry import bind_metric\nfrom distortions.visualization import dplot\n\ndef plot_transformation(f, H, Hvv, Hs, transformation_bw=2, metric_bw=20, width=450, height=450, radiusMin=1, radiusMax=10):\n    combined_df = bind_metric(f, Hvv, Hs)\n    combined_df[\"id\"] = combined_df.index\n\n    f_df = pd.DataFrame(f, columns=['x', 'y'])\n    embed_dict = {}\n    for n in range(len(f_df)):\n        embed_dict[n] = f_df.iloc[n, :]\n        embed_dict[n][\"id\"] = n\n\n    h_dict = {k: H[k] for k in range(len(H))}\n    return dplot(combined_df, width=width, height=height, labelFontSize=14)\\\n        .mapping(x=\"embedding_0\", y=\"embedding_1\")\\\n        .geom_ellipse(radiusMin=radiusMin, radiusMax=radiusMax, opacity=0.8)\\\n        .inter_isometry(metrics=h_dict, otherClasses=[\"ellipse\"], transformation_bw=transformation_bw, metric_bw=metric_bw, opacity=0.4, stroke=\"#c6c6c6\", strokeWidth=1.5)\\\n        .labs(x=\"x-axis\", y=\"y-axis\")\n</pre> from distortions.geometry import bind_metric from distortions.visualization import dplot  def plot_transformation(f, H, Hvv, Hs, transformation_bw=2, metric_bw=20, width=450, height=450, radiusMin=1, radiusMax=10):     combined_df = bind_metric(f, Hvv, Hs)     combined_df[\"id\"] = combined_df.index      f_df = pd.DataFrame(f, columns=['x', 'y'])     embed_dict = {}     for n in range(len(f_df)):         embed_dict[n] = f_df.iloc[n, :]         embed_dict[n][\"id\"] = n      h_dict = {k: H[k] for k in range(len(H))}     return dplot(combined_df, width=width, height=height, labelFontSize=14)\\         .mapping(x=\"embedding_0\", y=\"embedding_1\")\\         .geom_ellipse(radiusMin=radiusMin, radiusMax=radiusMax, opacity=0.8)\\         .inter_isometry(metrics=h_dict, otherClasses=[\"ellipse\"], transformation_bw=transformation_bw, metric_bw=metric_bw, opacity=0.4, stroke=\"#c6c6c6\", strokeWidth=1.5)\\         .labs(x=\"x-axis\", y=\"y-axis\") In\u00a0[3]: Copied! <pre>H = np.zeros((N, 2, 2))\nHvv = np.zeros((N, 2, 2))\nHs = np.zeros((N, 2))\n\nfor i in range(N):\n    H[i] = np.array([[1, 0], [0, 1]])\n    Hvv[i] = np.eye(2)\n    Hs[i] = [1, 1]\n</pre> H = np.zeros((N, 2, 2)) Hvv = np.zeros((N, 2, 2)) Hs = np.zeros((N, 2))  for i in range(N):     H[i] = np.array([[1, 0], [0, 1]])     Hvv[i] = np.eye(2)     Hs[i] = [1, 1] In\u00a0[4]: Copied! <pre>plots = {}\nplots[\"original\"] = plot_transformation(u, H, Hvv, Hs)\n</pre> plots = {} plots[\"original\"] = plot_transformation(u, H, Hvv, Hs) In\u00a0[5]: Copied! <pre>f = u.copy()\nf[:, 1] = f[:, 1] ** 2\n</pre> f = u.copy() f[:, 1] = f[:, 1] ** 2 In\u00a0[6]: Copied! <pre>plots[\"transformed\"] = plot_transformation(f, H, Hvv, Hs)\n</pre> plots[\"transformed\"] = plot_transformation(f, H, Hvv, Hs) In\u00a0[7]: Copied! <pre>for i in range(N):\n    H[i] = np.array([[1, 0], [0, 2 * f[i, 1]]])\n    Hvv[i] = np.eye(2)\n    Hs[i] = [1, 2 * f[i, 1]]\n\nplots[\"distortion\"] = plot_transformation(f, H, Hvv, Hs)\n</pre> for i in range(N):     H[i] = np.array([[1, 0], [0, 2 * f[i, 1]]])     Hvv[i] = np.eye(2)     Hs[i] = [1, 2 * f[i, 1]]  plots[\"distortion\"] = plot_transformation(f, H, Hvv, Hs) In\u00a0[8]: Copied! <pre>#[p.save(f\"../paper/figures/{k}.svg\") for k, p in plots.items()]\n</pre> #[p.save(f\"../paper/figures/{k}.svg\") for k, p in plots.items()] In\u00a0[9]: Copied! <pre>[display(p) for p in plots.values()]\n</pre> [display(p) for p in plots.values()] <pre>dplot(dataset=[{'embedding_0': 0.8448678500972645, 'embedding_1': 0.8949533007524632, 'x0': 1.0, 'y0': 0.0, 'x\u2026</pre> <pre>dplot(dataset=[{'embedding_0': 0.8448678500972645, 'embedding_1': 0.8009414105277287, 'x0': 1.0, 'y0': 0.0, 'x\u2026</pre> <pre>dplot(dataset=[{'embedding_0': 0.8448678500972645, 'embedding_1': 0.8009414105277287, 'x0': 1.0, 'y0': 0.0, 'x\u2026</pre> Out[9]: <pre>[None, None, None]</pre>"},{"location":"tutorials/hydra-80.html","title":"Comparing t-SNE Hyperparameters in the Hydra Atlas","text":"In\u00a0[1]: Copied! <pre>import random\nimport scanpy as sc\nimport numpy as np\nimport urllib.request\nimport tempfile\n\nrandom.seed(20250409)\n\ntemp_file = tempfile.mktemp(suffix=\".h5ad\")\n#urllib.request.urlretrieve(\"https://uwmadison.box.com/shared/static/gp1d9akvyq5r7a0rzxw27n86zlqe0d7f.h5ad\", temp_file)\n#adata = sc.read_h5ad(temp_file)\nadata = sc.read_h5ad(\"/Users/krissankaran/Downloads/hydra(2).h5ad\")\nadata.X = adata.X.todense()\n\nsc.pp.normalize_total(adata)\nsc.pp.log1p(adata)\nsc.pp.highly_variable_genes(adata, n_top_genes=1000)\n\nn_neighbors = 50\nix = np.random.choice(len(adata), 2000, replace=False)\nadata = adata[ix, adata.var.highly_variable]\nsc.pp.neighbors(adata, n_neighbors=n_neighbors)\nsc.tl.tsne(adata, n_pcs=30, perplexity=80)\n</pre> import random import scanpy as sc import numpy as np import urllib.request import tempfile  random.seed(20250409)  temp_file = tempfile.mktemp(suffix=\".h5ad\") #urllib.request.urlretrieve(\"https://uwmadison.box.com/shared/static/gp1d9akvyq5r7a0rzxw27n86zlqe0d7f.h5ad\", temp_file) #adata = sc.read_h5ad(temp_file) adata = sc.read_h5ad(\"/Users/krissankaran/Downloads/hydra(2).h5ad\") adata.X = adata.X.todense()  sc.pp.normalize_total(adata) sc.pp.log1p(adata) sc.pp.highly_variable_genes(adata, n_top_genes=1000)  n_neighbors = 50 ix = np.random.choice(len(adata), 2000, replace=False) adata = adata[ix, adata.var.highly_variable] sc.pp.neighbors(adata, n_neighbors=n_neighbors) sc.tl.tsne(adata, n_pcs=30, perplexity=80) In\u00a0[2]: Copied! <pre>from distortions.geometry import Geometry, bind_metric, local_distortions\n\nembedding = adata.obsm[\"X_tsne\"].copy()\nradius = 3 * np.mean(adata.obsp[\"distances\"].data)\ngeom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": 5})\nH, Hvv, Hs = local_distortions(embedding, adata.X, geom)\nembedding = bind_metric(embedding, Hvv, Hs)\nembedding[\"ident\"] = adata.obs[\"ident\"].str.split(\"-\").str[1].values\n</pre> from distortions.geometry import Geometry, bind_metric, local_distortions  embedding = adata.obsm[\"X_tsne\"].copy() radius = 3 * np.mean(adata.obsp[\"distances\"].data) geom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": 5}) H, Hvv, Hs = local_distortions(embedding, adata.X, geom) embedding = bind_metric(embedding, Hvv, Hs) embedding[\"ident\"] = adata.obs[\"ident\"].str.split(\"-\").str[1].values In\u00a0[3]: Copied! <pre>import altair as alt\nalt.data_transformers.enable(\"vegafusion\")\n\nalt.Chart(embedding).mark_circle(opacity=1).encode(\n    x=alt.X(\"embedding_0\"),\n    y=alt.Y(\"embedding_1\")\n).properties(width=400, height=400)\n</pre> import altair as alt alt.data_transformers.enable(\"vegafusion\")  alt.Chart(embedding).mark_circle(opacity=1).encode(     x=alt.X(\"embedding_0\"),     y=alt.Y(\"embedding_1\") ).properties(width=400, height=400) Out[3]: In\u00a0[4]: Copied! <pre>from distortions.visualization import dplot\nfrom distortions.geometry import neighborhoods\n\nplots = {}\nN = neighborhoods(adata, threshold=.2, outlier_factor=3, embed_key=\"X_tsne\", frame=[100, 100], method=\"window\")\nplots[\"hydra_link_80\"] = dplot(embedding, width=440, height=440)\\\n   .mapping(x=\"embedding_0\", y=\"embedding_1\")\\\n   .inter_edge_link(N=N, threshold=3, stroke=\"#F25E7A\", highlightColor=\"#F25E7A\", backgroundOpacity=0.2, strokeWidth=0.2, opacity=0.6)\\\n   .geom_ellipse(radiusMax=10, radiusMin=.8)\\\n   .labs(x=\"t-SNE 1\", y=\"t-SNE 2\")\n</pre> from distortions.visualization import dplot from distortions.geometry import neighborhoods  plots = {} N = neighborhoods(adata, threshold=.2, outlier_factor=3, embed_key=\"X_tsne\", frame=[100, 100], method=\"window\") plots[\"hydra_link_80\"] = dplot(embedding, width=440, height=440)\\    .mapping(x=\"embedding_0\", y=\"embedding_1\")\\    .inter_edge_link(N=N, threshold=3, stroke=\"#F25E7A\", highlightColor=\"#F25E7A\", backgroundOpacity=0.2, strokeWidth=0.2, opacity=0.6)\\    .geom_ellipse(radiusMax=10, radiusMin=.8)\\    .labs(x=\"t-SNE 1\", y=\"t-SNE 2\") In\u00a0[5]: Copied! <pre>metrics = {k: H[k] for k in range(len(H))}\ndplot(embedding, width=440, height=440)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\")\\\n    .inter_isometry(metrics=metrics, metrics_bw=.05, transformation_bw=.1)\\\n    .geom_ellipse(radiusMax=10, radiusMin=.8)\\\n    .labs(x=\"t-SNE 1\", y=\"t-SNE 2\")\n</pre> metrics = {k: H[k] for k in range(len(H))} dplot(embedding, width=440, height=440)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\")\\     .inter_isometry(metrics=metrics, metrics_bw=.05, transformation_bw=.1)\\     .geom_ellipse(radiusMax=10, radiusMin=.8)\\     .labs(x=\"t-SNE 1\", y=\"t-SNE 2\") Out[5]: <pre>dplot(dataset=[{'embedding_0': 1.100225567817688, 'embedding_1': -5.863574504852295, 'x0': -0.9939286243389406\u2026</pre> In\u00a0[6]: Copied! <pre>from distortions.geometry import neighborhood_distances\n\ndists = neighborhood_distances(adata, embed_key=\"X_tsne\")\ndplot(embedding, width=550, height=440)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\")\\\n    .geom_ellipse(radiusMax=8, radiusMin=.5)\\\n    .inter_boxplot(dists=dists, strokeWidth=0.2)\\\n    .labs(x = \"t-SNE 1\", y = \"t-SNE 2\")\n</pre> from distortions.geometry import neighborhood_distances  dists = neighborhood_distances(adata, embed_key=\"X_tsne\") dplot(embedding, width=550, height=440)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\")\\     .geom_ellipse(radiusMax=8, radiusMin=.5)\\     .inter_boxplot(dists=dists, strokeWidth=0.2)\\     .labs(x = \"t-SNE 1\", y = \"t-SNE 2\") Out[6]: <pre>dplot(dataset=[{'embedding_0': 1.100225567817688, 'embedding_1': -5.863574504852295, 'x0': -0.9939286243389406\u2026</pre> In\u00a0[7]: Copied! <pre>#[p.save(f\"../paper/figures/{k}.svg\") for k, p in plots.items()]\n</pre> #[p.save(f\"../paper/figures/{k}.svg\") for k, p in plots.items()] In\u00a0[8]: Copied! <pre>[display(p) for p in plots.values()]\n</pre> [display(p) for p in plots.values()] <pre>dplot(dataset=[{'embedding_0': 1.100225567817688, 'embedding_1': -5.863574504852295, 'x0': -0.9939286243389406\u2026</pre> Out[8]: <pre>[None]</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorials/link_data.html","title":"Analyzing Topology Failures with Interlocking Links","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport pandas as pd\nfrom distortions.geometry import Geometry, bind_metric, local_distortions\n</pre> import numpy as np import pandas as pd from distortions.geometry import Geometry, bind_metric, local_distortions In\u00a0[2]: Copied! <pre>import math\n    \ndef rotate(x, y, z):\n    u = x\n    cos_val = math.cos(0.4)\n    sin_val = math.sin(0.4)\n    v = cos_val * y + sin_val * z\n    w = -sin_val * y + cos_val * z\n    return [u, v, w]\n\ndef link_data(n, offset=1):\n    \"\"\"\n    https://github.com/kevinrobinson/umap-playground/blob/master/public/assets/demo-datas.js#L311\n    \"\"\"\n    points = []\n    for i in range(n):\n        t = 2 * math.pi * i / n\n        sin_t = math.sin(t)\n        cos_t = math.cos(t)\n        points.append(rotate(cos_t, sin_t, 0))\n        points.append(rotate(offset + cos_t, 0, sin_t))\n    \n    return np.array(points)\n</pre> import math      def rotate(x, y, z):     u = x     cos_val = math.cos(0.4)     sin_val = math.sin(0.4)     v = cos_val * y + sin_val * z     w = -sin_val * y + cos_val * z     return [u, v, w]  def link_data(n, offset=1):     \"\"\"     https://github.com/kevinrobinson/umap-playground/blob/master/public/assets/demo-datas.js#L311     \"\"\"     points = []     for i in range(n):         t = 2 * math.pi * i / n         sin_t = math.sin(t)         cos_t = math.cos(t)         points.append(rotate(cos_t, sin_t, 0))         points.append(rotate(offset + cos_t, 0, sin_t))          return np.array(points) In\u00a0[3]: Copied! <pre>from anndata import AnnData\nimport scanpy as sc\n\nM = 100\nn_neighbors = 50\ndata = link_data(M)\n\nadata = AnnData(X=data, obs=pd.DataFrame(range(2 * M)))\nsc.pp.neighbors(adata, n_neighbors=50)\nsc.tl.umap(adata)\nembedding = adata.obsm[\"X_umap\"].copy()\n</pre> from anndata import AnnData import scanpy as sc  M = 100 n_neighbors = 50 data = link_data(M)  adata = AnnData(X=data, obs=pd.DataFrame(range(2 * M))) sc.pp.neighbors(adata, n_neighbors=50) sc.tl.umap(adata) embedding = adata.obsm[\"X_umap\"].copy() In\u00a0[4]: Copied! <pre>radius = 3 * np.mean(adata.obsp[\"distances\"].data)\ngeom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": 5})\nH, Hvv, Hs = local_distortions(embedding, data, geom)\nembedding = bind_metric(embedding, Hvv, Hs)\nembedding[\"x_orig\"] = data[:, 0]\n</pre> radius = 3 * np.mean(adata.obsp[\"distances\"].data) geom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": 5}) H, Hvv, Hs = local_distortions(embedding, data, geom) embedding = bind_metric(embedding, Hvv, Hs) embedding[\"x_orig\"] = data[:, 0] In\u00a0[5]: Copied! <pre>from distortions.geometry import neighborhoods\nfrom distortions.visualization import dplot\n\nN = neighborhoods(adata, threshold=0.01, outlier_factor=2)\ndplot(embedding, width=900, height=500)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"x_orig\")\\\n    .inter_edge_link(N=N, threshold=1)\\\n    .geom_ellipse()\\\n    .scale_color()\n</pre> from distortions.geometry import neighborhoods from distortions.visualization import dplot  N = neighborhoods(adata, threshold=0.01, outlier_factor=2) dplot(embedding, width=900, height=500)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"x_orig\")\\     .inter_edge_link(N=N, threshold=1)\\     .geom_ellipse()\\     .scale_color() Out[5]: <pre>dplot(dataset=[{'embedding_0': 9.539716720581055, 'embedding_1': 3.1580326557159424, 'x0': -0.8638632514305921\u2026</pre> In\u00a0[6]: Copied! <pre>plots = []\nfor offset in np.linspace(0.5, 2.5, 5):\n\n    data = link_data(M, offset=offset)\n    adata = AnnData(X=data, obs=pd.DataFrame(range(2 * M)))\n    sc.pp.neighbors(adata, n_neighbors=50)\n    sc.tl.umap(adata)\n    embedding = adata.obsm[\"X_umap\"].copy()\n\n    H, Hvv, Hs = local_distortions(embedding, data, geom)\n    embedding = bind_metric(embedding, Hvv, Hs)\n    embedding[\"x_orig\"] = data[:, 0]\n\n    N = neighborhoods(adata, threshold=0.2, outlier_factor=2)\n    metrics = {k: H[k] for k in range(len(H))}\n    plots += [dplot(embedding, width=400, height=400)\\\n        .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"x_orig\")\\\n        .geom_ellipse()\\\n        .inter_edge_link(N=N, threshold=1)\\\n        .labs(title=f\"{offset} Units Apart\")\\\n        .scale_color()]\n</pre> plots = [] for offset in np.linspace(0.5, 2.5, 5):      data = link_data(M, offset=offset)     adata = AnnData(X=data, obs=pd.DataFrame(range(2 * M)))     sc.pp.neighbors(adata, n_neighbors=50)     sc.tl.umap(adata)     embedding = adata.obsm[\"X_umap\"].copy()      H, Hvv, Hs = local_distortions(embedding, data, geom)     embedding = bind_metric(embedding, Hvv, Hs)     embedding[\"x_orig\"] = data[:, 0]      N = neighborhoods(adata, threshold=0.2, outlier_factor=2)     metrics = {k: H[k] for k in range(len(H))}     plots += [dplot(embedding, width=400, height=400)\\         .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"x_orig\")\\         .geom_ellipse()\\         .inter_edge_link(N=N, threshold=1)\\         .labs(title=f\"{offset} Units Apart\")\\         .scale_color()] In\u00a0[7]: Copied! <pre>[display(p) for p in plots]\n</pre> [display(p) for p in plots] <pre>dplot(dataset=[{'embedding_0': 3.289219617843628, 'embedding_1': 13.244303703308105, 'x0': -0.6242006037121905\u2026</pre> <pre>dplot(dataset=[{'embedding_0': 9.539716720581055, 'embedding_1': 3.1580326557159424, 'x0': -0.8638632514305921\u2026</pre> <pre>dplot(dataset=[{'embedding_0': 12.08263111114502, 'embedding_1': 9.085368156433105, 'x0': -0.4536952649302679,\u2026</pre> <pre>dplot(dataset=[{'embedding_0': 0.22946549952030182, 'embedding_1': 0.14115360379219055, 'x0': -0.5723637280364\u2026</pre> <pre>dplot(dataset=[{'embedding_0': 7.340658664703369, 'embedding_1': 4.244654655456543, 'x0': -0.8520414657269931,\u2026</pre> Out[7]: <pre>[None, None, None, None, None]</pre>"},{"location":"tutorials/mammoth.html","title":"Analyzing Fragmentation in a Flattened Mammoth","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport pandas as pd\nfrom distortions.geometry import Geometry, bind_metric, local_distortions\n\nn_neighbors = 50\ndata = pd.read_json(\"https://raw.githubusercontent.com/krisrs1128/distortions-data/main/data/mammoth_3d.json\")\n</pre> import numpy as np import pandas as pd from distortions.geometry import Geometry, bind_metric, local_distortions  n_neighbors = 50 data = pd.read_json(\"https://raw.githubusercontent.com/krisrs1128/distortions-data/main/data/mammoth_3d.json\") In\u00a0[2]: Copied! <pre>from anndata import AnnData\nimport scanpy as sc\n\nadata = AnnData(X=data, obs=pd.DataFrame(index=data.index))\nsc.pp.neighbors(adata, n_neighbors=n_neighbors)\nsc.tl.umap(adata)\nembedding = adata.obsm[\"X_umap\"].copy()\n</pre> from anndata import AnnData import scanpy as sc  adata = AnnData(X=data, obs=pd.DataFrame(index=data.index)) sc.pp.neighbors(adata, n_neighbors=n_neighbors) sc.tl.umap(adata) embedding = adata.obsm[\"X_umap\"].copy() In\u00a0[3]: Copied! <pre>radius = 3 * np.mean(adata.obsp[\"distances\"].data)\ngeom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": 5})\nH, Hvv, Hs = local_distortions(embedding, data, geom)\nembedding = bind_metric(embedding, Hvv, Hs)\n</pre> radius = 3 * np.mean(adata.obsp[\"distances\"].data) geom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": 5}) H, Hvv, Hs = local_distortions(embedding, data, geom) embedding = bind_metric(embedding, Hvv, Hs) In\u00a0[4]: Copied! <pre>import plotly.express as px\n\nfig = px.scatter_3d(data, x='x', y='z', z='y')\nfig.update_traces(marker_size=1, marker_color=\"black\")\nfig\n</pre> import plotly.express as px  fig = px.scatter_3d(data, x='x', y='z', z='y') fig.update_traces(marker_size=1, marker_color=\"black\") fig <pre>\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[4], line 3\n      1 import plotly.express as px\n----&gt; 3 fig = px.scatter_3d(data, x='x', y='z', z='y')\n      4 fig.update_traces(marker_size=1, marker_color=\"black\")\n      5 fig\n\nFile /opt/miniconda3/envs/dist2/lib/python3.12/site-packages/plotly/express/_chart_types.py:791, in scatter_3d(data_frame, x, y, z, color, symbol, size, text, hover_name, hover_data, custom_data, error_x, error_x_minus, error_y, error_y_minus, error_z, error_z_minus, animation_frame, animation_group, category_orders, labels, size_max, color_discrete_sequence, color_discrete_map, color_continuous_scale, range_color, color_continuous_midpoint, symbol_sequence, symbol_map, opacity, log_x, log_y, log_z, range_x, range_y, range_z, title, subtitle, template, width, height)\n    744 def scatter_3d(\n    745     data_frame=None,\n    746     x=None,\n   (...)    785     height=None,\n    786 ) -&gt; go.Figure:\n    787     \"\"\"\n    788     In a 3D scatter plot, each row of `data_frame` is represented by a\n    789     symbol mark in 3D space.\n    790     \"\"\"\n--&gt; 791     return make_figure(args=locals(), constructor=go.Scatter3d)\n\nFile /opt/miniconda3/envs/dist2/lib/python3.12/site-packages/plotly/express/_core.py:2491, in make_figure(args, constructor, trace_patch, layout_patch)\n   2488 layout_patch = layout_patch or {}\n   2489 apply_default_cascade(args)\n-&gt; 2491 args = build_dataframe(args, constructor)\n   2492 if constructor in [go.Treemap, go.Sunburst, go.Icicle] and args[\"path\"] is not None:\n   2493     args = process_dataframe_hierarchy(args)\n\nFile /opt/miniconda3/envs/dist2/lib/python3.12/site-packages/plotly/express/_core.py:1737, in build_dataframe(args, constructor)\n   1734     args[\"color\"] = None\n   1735 # now that things have been prepped, we do the systematic rewriting of `args`\n-&gt; 1737 df_output, wide_id_vars = process_args_into_dataframe(\n   1738     args,\n   1739     wide_mode,\n   1740     var_name,\n   1741     value_name,\n   1742     is_pd_like,\n   1743     native_namespace,\n   1744 )\n   1745 df_output: nw.DataFrame\n   1746 # now that `df_output` exists and `args` contains only references, we complete\n   1747 # the special-case and wide-mode handling by further rewriting args and/or mutating\n   1748 # df_output\n\nFile /opt/miniconda3/envs/dist2/lib/python3.12/site-packages/plotly/express/_core.py:1338, in process_args_into_dataframe(args, wide_mode, var_name, value_name, is_pd_like, native_namespace)\n   1336         if argument == \"index\":\n   1337             err_msg += \"\\n To use the index, pass it in directly as `df.index`.\"\n-&gt; 1338         raise ValueError(err_msg)\n   1339 elif length and (actual_len := len(df_input)) != length:\n   1340     raise ValueError(\n   1341         \"All arguments should have the same length. \"\n   1342         \"The length of column argument `df[%s]` is %d, whereas the \"\n   (...)   1349         )\n   1350     )\n\nValueError: Value of 'x' is not the name of a column in 'data_frame'. Expected one of [0, 1, 2] but received: x</pre> In\u00a0[\u00a0]: Copied! <pre>import altair as alt\nalt.data_transformers.enable(\"vegafusion\")\n\nalt.Chart(embedding).mark_circle(color=\"black\").encode(\n    x=alt.X(\"embedding_0\"),\n    y=alt.Y(\"embedding_1\")\n).properties(width=450, height=350)\n</pre> import altair as alt alt.data_transformers.enable(\"vegafusion\")  alt.Chart(embedding).mark_circle(color=\"black\").encode(     x=alt.X(\"embedding_0\"),     y=alt.Y(\"embedding_1\") ).properties(width=450, height=350) In\u00a0[\u00a0]: Copied! <pre>from distortions.geometry import neighborhood_distances\n\ndistances = neighborhood_distances(adata)\nalt.Chart(distances).mark_boxplot(outliers=True).encode(\n    x=alt.X('true', bin={\"maxbins\": 20}),\n    y=alt.Y('embedding')\n)\n</pre> from distortions.geometry import neighborhood_distances  distances = neighborhood_distances(adata) alt.Chart(distances).mark_boxplot(outliers=True).encode(     x=alt.X('true', bin={\"maxbins\": 20}),     y=alt.Y('embedding') ) In\u00a0[\u00a0]: Copied! <pre>from distortions.geometry import neighborhoods\nfrom distortions.visualization import dplot\n\nplots = {}\nN = neighborhoods(adata, threshold=.1, outlier_factor=3)\nplots[\"mamoth_links\"] = dplot(embedding, height = 350, width=450)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\")\\\n    .inter_edge_link(N=N, strokeWidth=.2, opacity=0.7, threshold=4, stroke=\"#F25E7A\", highlightColor=\"#C83F58\")\\\n    .geom_ellipse(opacity=0.8, radiusMin=.5, radiusMax=10)\n</pre> from distortions.geometry import neighborhoods from distortions.visualization import dplot  plots = {} N = neighborhoods(adata, threshold=.1, outlier_factor=3) plots[\"mamoth_links\"] = dplot(embedding, height = 350, width=450)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\")\\     .inter_edge_link(N=N, strokeWidth=.2, opacity=0.7, threshold=4, stroke=\"#F25E7A\", highlightColor=\"#C83F58\")\\     .geom_ellipse(opacity=0.8, radiusMin=.5, radiusMax=10) In\u00a0[\u00a0]: Copied! <pre>metrics = {k: H[k] for k in range(len(H))}\nplots[\"mammoth_isometry\"] = dplot(embedding, height=350, width=450)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\")\\\n    .inter_isometry(metrics=metrics, transformation_bw=.5, metric_bw=.1)\\\n    .geom_ellipse(opacity=0.8, radiusMin=.5, radiusMax=10)\n</pre> metrics = {k: H[k] for k in range(len(H))} plots[\"mammoth_isometry\"] = dplot(embedding, height=350, width=450)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\")\\     .inter_isometry(metrics=metrics, transformation_bw=.5, metric_bw=.1)\\     .geom_ellipse(opacity=0.8, radiusMin=.5, radiusMax=10) In\u00a0[\u00a0]: Copied! <pre>plots[\"mammoth_box\"] = dplot(embedding, height=350, width=530)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\")\\\n    .geom_ellipse(radiusMax=10, radiusMin=.5)\\\n    .inter_boxplot(dists=distances, outlier_iqr=10, highlightColor=\"#F25E7A\", strokeWidth=0.4)\n</pre> plots[\"mammoth_box\"] = dplot(embedding, height=350, width=530)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\")\\     .geom_ellipse(radiusMax=10, radiusMin=.5)\\     .inter_boxplot(dists=distances, outlier_iqr=10, highlightColor=\"#F25E7A\", strokeWidth=0.4) In\u00a0[\u00a0]: Copied! <pre>[display(p) for p in plots.values()]\n</pre> [display(p) for p in plots.values()] In\u00a0[\u00a0]: Copied! <pre>#[p.save(f\"../paper/figures/{k}.svg\") for k, p in plots.items()]\n</pre> #[p.save(f\"../paper/figures/{k}.svg\") for k, p in plots.items()] In\u00a0[\u00a0]: Copied! <pre>len(N)\n</pre> len(N)"},{"location":"tutorials/pbmc.html","title":"PBMC Atlas","text":"In\u00a0[1]: Copied! <pre>import scanpy as sc\n\nadata = sc.datasets.pbmc3k_processed()\n</pre> import scanpy as sc  adata = sc.datasets.pbmc3k_processed() In\u00a0[2]: Copied! <pre>import random\nimport scanpy as sc\nrandom.seed(20250410)\n\nn_neighbors = 50\nsc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=40)\nsc.tl.umap(adata, init_pos = \"spectral\") # set to \"random\" for random initialization\nsc.tl.leiden(\n    adata,\n    key_added=\"clusters\",\n    resolution=0.5,\n    n_iterations=2,\n    flavor=\"igraph\",\n    directed=False,\n)\nmarker_genes_dict = {\n    \"B-cell\": [\"CD79A\", \"MS4A1\"],\n    \"Dendritic\": [\"FCER1A\", \"CST3\"],\n    \"Monocytes\": [\"FCGR3A\"],\n    \"NK\": [\"GNLY\", \"NKG7\"],\n    \"Other\": [\"IGLL1\"],\n    \"Plasma\": [\"IGJ\"],\n    \"T-cell\": [\"CD3D\"],\n}\n\ncluster2annotation = {\n    \"0\": \"Monocytes\",\n    \"1\": \"NK\",\n    \"2\": \"T-cell\",\n    \"3\": \"Dendritic\",\n    \"4\": \"Dendritic\",\n    \"5\": \"Plasma\",\n    \"6\": \"B-cell\",\n    \"7\": \"Dendritic\",\n    \"8\": \"Other\",\n}\n\nadata.obs[\"cell_type\"] = adata.obs[\"clusters\"].map(cluster2annotation).astype(\"category\")\n</pre> import random import scanpy as sc random.seed(20250410)  n_neighbors = 50 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=40) sc.tl.umap(adata, init_pos = \"spectral\") # set to \"random\" for random initialization sc.tl.leiden(     adata,     key_added=\"clusters\",     resolution=0.5,     n_iterations=2,     flavor=\"igraph\",     directed=False, ) marker_genes_dict = {     \"B-cell\": [\"CD79A\", \"MS4A1\"],     \"Dendritic\": [\"FCER1A\", \"CST3\"],     \"Monocytes\": [\"FCGR3A\"],     \"NK\": [\"GNLY\", \"NKG7\"],     \"Other\": [\"IGLL1\"],     \"Plasma\": [\"IGJ\"],     \"T-cell\": [\"CD3D\"], }  cluster2annotation = {     \"0\": \"Monocytes\",     \"1\": \"NK\",     \"2\": \"T-cell\",     \"3\": \"Dendritic\",     \"4\": \"Dendritic\",     \"5\": \"Plasma\",     \"6\": \"B-cell\",     \"7\": \"Dendritic\",     \"8\": \"Other\", }  adata.obs[\"cell_type\"] = adata.obs[\"clusters\"].map(cluster2annotation).astype(\"category\") In\u00a0[3]: Copied! <pre>from distortions.geometry import Geometry, bind_metric, local_distortions\nimport numpy as np\n\nembedding = adata.obsm[\"X_umap\"].copy()\nradius = 3 * np.mean(adata.obsp[\"distances\"].data)\ngeom = Geometry(\"brute\", laplacian_method=\"geometric\", laplacian_kwds={\"scaling_epps\": 5}, adjacency_kwds={\"n_neighbors\": n_neighbors}, affinity_kwds={\"radius\": radius})\nH, Hvv, Hs = local_distortions(embedding, adata.X, geom)\n\n# postprocessing\n#Hs[Hs &gt; 8] = 8 # for random plot\nHs[Hs &gt; 2.5] = 2.5\nHs /= Hs.mean()\nfor i in range(len(H)):\n    H[i] = Hvv[i] @ np.diag(Hs[i]) @ Hvv[i].T\n\nembedding = bind_metric(embedding, Hvv, Hs)\nembedding[\"cell_type\"] = adata.obs[\"cell_type\"].values\n</pre> from distortions.geometry import Geometry, bind_metric, local_distortions import numpy as np  embedding = adata.obsm[\"X_umap\"].copy() radius = 3 * np.mean(adata.obsp[\"distances\"].data) geom = Geometry(\"brute\", laplacian_method=\"geometric\", laplacian_kwds={\"scaling_epps\": 5}, adjacency_kwds={\"n_neighbors\": n_neighbors}, affinity_kwds={\"radius\": radius}) H, Hvv, Hs = local_distortions(embedding, adata.X, geom)  # postprocessing #Hs[Hs &gt; 8] = 8 # for random plot Hs[Hs &gt; 2.5] = 2.5 Hs /= Hs.mean() for i in range(len(H)):     H[i] = Hvv[i] @ np.diag(Hs[i]) @ Hvv[i].T  embedding = bind_metric(embedding, Hvv, Hs) embedding[\"cell_type\"] = adata.obs[\"cell_type\"].values In\u00a0[4]: Copied! <pre>import altair as alt\nimport pandas as pd\n\ndf_plot = pd.DataFrame({ \"s0\": Hs[:, 0], \"s1\": Hs[:, 1], \"cell_type\": embedding[\"cell_type\"] })\nsort_order = [\"Monocytes', 'NK', 'T-cell', 'Dendritic', 'Plasma', 'B-cell', 'Other\"]\nlambda_plot = alt.Chart(df_plot).mark_circle()\\\n    .encode(\n        x=alt.X(\"s0\", axis=alt.Axis(title=\"\u03bb\u2081\")),\n        y=alt.Y(\"s1\", axis=alt.Axis(title=\"\u03bb\u2082\")),\n        color=alt.Color(\"cell_type\", sort=sort_order).scale(scheme=\"category10\")\n    )\\\n    .configure_axis(grid=False)\n#lambda_plot.save(\"pbmc_lambda_plot.svg\")\n</pre> import altair as alt import pandas as pd  df_plot = pd.DataFrame({ \"s0\": Hs[:, 0], \"s1\": Hs[:, 1], \"cell_type\": embedding[\"cell_type\"] }) sort_order = [\"Monocytes', 'NK', 'T-cell', 'Dendritic', 'Plasma', 'B-cell', 'Other\"] lambda_plot = alt.Chart(df_plot).mark_circle()\\     .encode(         x=alt.X(\"s0\", axis=alt.Axis(title=\"\u03bb\u2081\")),         y=alt.Y(\"s1\", axis=alt.Axis(title=\"\u03bb\u2082\")),         color=alt.Color(\"cell_type\", sort=sort_order).scale(scheme=\"category10\")     )\\     .configure_axis(grid=False) #lambda_plot.save(\"pbmc_lambda_plot.svg\") In\u00a0[5]: Copied! <pre>alt.Chart(embedding).mark_circle(opacity=1).encode(\n    x=alt.X(\"embedding_0\"),\n    y=alt.Y(\"embedding_1\"),\n    color=alt.Color(\"cell_type\", sort=sort_order).scale(scheme=\"category10\")\n).properties(width=400, height=400)\\\n .configure_axis(grid=False)\n</pre> alt.Chart(embedding).mark_circle(opacity=1).encode(     x=alt.X(\"embedding_0\"),     y=alt.Y(\"embedding_1\"),     color=alt.Color(\"cell_type\", sort=sort_order).scale(scheme=\"category10\") ).properties(width=400, height=400)\\  .configure_axis(grid=False) Out[5]: In\u00a0[6]: Copied! <pre>from distortions.geometry import neighborhoods\nfrom distortions.visualization import dplot\n\nN = neighborhoods(adata, threshold=.2, outlier_factor=2)\nplots = {} \nplots[\"pbmc_links\"] = dplot(embedding, width=440, height=340)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\\n    .geom_ellipse(radiusMax=15, radiusMin=1)\\\n    .inter_edge_link(N=N, threshold=.1, strokeWidth=0.4)\\\n    .scale_color(legendTextSize=15)\\\n    .labs(x=\"UMAP 1\", y=\"UMAP 2\")\n</pre> from distortions.geometry import neighborhoods from distortions.visualization import dplot  N = neighborhoods(adata, threshold=.2, outlier_factor=2) plots = {}  plots[\"pbmc_links\"] = dplot(embedding, width=440, height=340)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\     .geom_ellipse(radiusMax=15, radiusMin=1)\\     .inter_edge_link(N=N, threshold=.1, strokeWidth=0.4)\\     .scale_color(legendTextSize=15)\\     .labs(x=\"UMAP 1\", y=\"UMAP 2\") In\u00a0[7]: Copied! <pre>from distortions.geometry import neighborhood_distances\n\ndists = neighborhood_distances(adata)\nplots[\"pbmc_boxplot\"] = dplot(embedding, width=540, height=340)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\\n    .geom_ellipse(radiusMax=15, radiusMin=1)\\\n    .inter_boxplot(dists=dists, strokeWidth=0.4, legendOffset=100)\\\n    .labs(x=\"UMAP 1\", y=\"UMAP 2\")\n</pre> from distortions.geometry import neighborhood_distances  dists = neighborhood_distances(adata) plots[\"pbmc_boxplot\"] = dplot(embedding, width=540, height=340)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\     .geom_ellipse(radiusMax=15, radiusMin=1)\\     .inter_boxplot(dists=dists, strokeWidth=0.4, legendOffset=100)\\     .labs(x=\"UMAP 1\", y=\"UMAP 2\") In\u00a0[8]: Copied! <pre>metrics = {k: H[k] for k in range(len(H))}\nplots[\"pbmc_isometry\"] = dplot(embedding, width=440, height=340)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\\n    .geom_ellipse(radiusMin=.7, radiusMax=8)\\\n    .inter_isometry(metrics=metrics, metric_bw=0.5, transformation_bw=0.2, strokeWidth=0.2)\\\n    .scale_color(legendTextSize=8)\\\n    .labs(x=\"UMAP 1\", y=\"UMAP 2\")\n</pre> metrics = {k: H[k] for k in range(len(H))} plots[\"pbmc_isometry\"] = dplot(embedding, width=440, height=340)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\     .geom_ellipse(radiusMin=.7, radiusMax=8)\\     .inter_isometry(metrics=metrics, metric_bw=0.5, transformation_bw=0.2, strokeWidth=0.2)\\     .scale_color(legendTextSize=8)\\     .labs(x=\"UMAP 1\", y=\"UMAP 2\") In\u00a0[9]: Copied! <pre>plots[\"pbmc_transform\"] = dplot(embedding, width=440, height=340)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"kernel_transform\")\\\n    .geom_ellipse(radiusMin=.7, radiusMax=8)\\\n    .inter_isometry(metrics=metrics, metric_bw=1, transformation_bw=0.2, strokeWidth=0.2)\\\n    .scale_color(legendTextSize=8)\\\n    .labs(x=\"UMAP 1\", y=\"UMAP 2\")\n\nplots[\"pbmc_metric\"] = dplot(embedding, width=440, height=340)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"kernel_metric\")\\\n    .geom_ellipse(radiusMin=.7, radiusMax=8)\\\n    .inter_isometry(metrics=metrics, metric_bw=1, transformation_bw=0.2, strokeWidth=0.2)\\\n    .scale_color(legendTextSize=8)\\\n    .labs(x=\"UMAP 1\", y=\"UMAP 2\")\n</pre> plots[\"pbmc_transform\"] = dplot(embedding, width=440, height=340)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"kernel_transform\")\\     .geom_ellipse(radiusMin=.7, radiusMax=8)\\     .inter_isometry(metrics=metrics, metric_bw=1, transformation_bw=0.2, strokeWidth=0.2)\\     .scale_color(legendTextSize=8)\\     .labs(x=\"UMAP 1\", y=\"UMAP 2\")  plots[\"pbmc_metric\"] = dplot(embedding, width=440, height=340)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"kernel_metric\")\\     .geom_ellipse(radiusMin=.7, radiusMax=8)\\     .inter_isometry(metrics=metrics, metric_bw=1, transformation_bw=0.2, strokeWidth=0.2)\\     .scale_color(legendTextSize=8)\\     .labs(x=\"UMAP 1\", y=\"UMAP 2\") In\u00a0[10]: Copied! <pre>#[p.save(f\"{k}.svg\") for k, p in plots.items()]\n</pre> #[p.save(f\"{k}.svg\") for k, p in plots.items()] In\u00a0[11]: Copied! <pre>[display(p) for p in plots.values()]\n</pre> [display(p) for p in plots.values()] <pre>dplot(dataset=[{'embedding_0': 5.796429634094238, 'embedding_1': 11.640312194824219, 'x0': -0.8577109625586664\u2026</pre> <pre>dplot(dataset=[{'embedding_0': 5.796429634094238, 'embedding_1': 11.640312194824219, 'x0': -0.8577109625586664\u2026</pre> <pre>dplot(dataset=[{'embedding_0': 5.796429634094238, 'embedding_1': 11.640312194824219, 'x0': -0.8577109625586664\u2026</pre> <pre>dplot(dataset=[{'embedding_0': 5.796429634094238, 'embedding_1': 11.640312194824219, 'x0': -0.8577109625586664\u2026</pre> <pre>dplot(dataset=[{'embedding_0': 5.796429634094238, 'embedding_1': 11.640312194824219, 'x0': -0.8577109625586664\u2026</pre> Out[11]: <pre>[None, None, None, None, None]</pre> In\u00a0[12]: Copied! <pre>print(len(N))\n</pre> print(len(N)) <pre>72\n</pre>"},{"location":"tutorials/svg.html","title":"Saving Interactions as SVG","text":"In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport pandas as pd\nfrom distortions.geometry import Geometry, bind_metric, local_distortions\n</pre> import numpy as np import pandas as pd from distortions.geometry import Geometry, bind_metric, local_distortions"},{"location":"tutorials/two_clusters.html","title":"Density Preservation in a Gaussian Mixture Dataset","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport pandas as pd\nfrom distortions.geometry import Geometry, bind_metric, local_distortions\nnp.random.seed(20250702)\n\ndef two_clusters_differential(n):\n    \"\"\"Two 2D clusters of different sizes.\"\"\"\n    points = []\n    for _ in range(n):\n        points.append([10 * np.random.normal(), 10 * np.random.normal()])\n        points.append([30 + np.random.normal(), np.random.normal()])\n    return np.array(points)\n</pre> import numpy as np import pandas as pd from distortions.geometry import Geometry, bind_metric, local_distortions np.random.seed(20250702)  def two_clusters_differential(n):     \"\"\"Two 2D clusters of different sizes.\"\"\"     points = []     for _ in range(n):         points.append([10 * np.random.normal(), 10 * np.random.normal()])         points.append([30 + np.random.normal(), np.random.normal()])     return np.array(points) In\u00a0[2]: Copied! <pre>from anndata import AnnData\nimport scanpy as sc\n\nM = 500\nn_neighbors = 50\ndata = two_clusters_differential(M)\n\nadata = AnnData(X=data, obs=pd.DataFrame(range(2 * M)))\nsc.pp.neighbors(adata, n_neighbors=n_neighbors)\nsc.tl.umap(adata)\nembedding = adata.obsm[\"X_umap\"].copy()\n\nradius = np.mean(adata.obsp[\"distances\"].data)\ngeom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": 1})\nH, Hvv, Hs = local_distortions(embedding, data, geom)\n\n# postprocessing\nHs[Hs &gt; 5] = 5\nHs /= Hs.mean()\nfor i in range(len(H)):\n    H[i] = Hvv[i] @ np.diag(Hs[i]) @ Hvv[i].T\n\nembedding = bind_metric(embedding, Hvv, Hs)\nembedding[\"cluster\"] = [\"A\", \"B\"] * M\n</pre> from anndata import AnnData import scanpy as sc  M = 500 n_neighbors = 50 data = two_clusters_differential(M)  adata = AnnData(X=data, obs=pd.DataFrame(range(2 * M))) sc.pp.neighbors(adata, n_neighbors=n_neighbors) sc.tl.umap(adata) embedding = adata.obsm[\"X_umap\"].copy()  radius = np.mean(adata.obsp[\"distances\"].data) geom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": 1}) H, Hvv, Hs = local_distortions(embedding, data, geom)  # postprocessing Hs[Hs &gt; 5] = 5 Hs /= Hs.mean() for i in range(len(H)):     H[i] = Hvv[i] @ np.diag(Hs[i]) @ Hvv[i].T  embedding = bind_metric(embedding, Hvv, Hs) embedding[\"cluster\"] = [\"A\", \"B\"] * M In\u00a0[\u00a0]: Copied! <pre>import altair as alt\n\ndf_plot = pd.DataFrame({ \"s0\": Hs[:, 0], \"s1\": Hs[:, 1], \"cluster\": embedding[\"cluster\"] })\nlambda_plot = alt.Chart(df_plot).mark_circle()\\\n    .encode(\n        x=alt.X(\"s0\", axis=alt.Axis(title=\"\u03bb\u2081\")),\n        y=alt.Y(\"s1\", axis=alt.Axis(title=\"\u03bb\u2082\")),\n        color=alt.Color(\"cluster\", scale=alt.Scale(domain=[\"A\", \"B\"], range=[\"#40e0d0\", \"#ff9d06\"]))\n    )\\\n    .configure_axis(grid=False)\n\n#lambda_plot.save(\"../paper/figures/two_clusters_lambda.svg\")\n</pre> import altair as alt  df_plot = pd.DataFrame({ \"s0\": Hs[:, 0], \"s1\": Hs[:, 1], \"cluster\": embedding[\"cluster\"] }) lambda_plot = alt.Chart(df_plot).mark_circle()\\     .encode(         x=alt.X(\"s0\", axis=alt.Axis(title=\"\u03bb\u2081\")),         y=alt.Y(\"s1\", axis=alt.Axis(title=\"\u03bb\u2082\")),         color=alt.Color(\"cluster\", scale=alt.Scale(domain=[\"A\", \"B\"], range=[\"#40e0d0\", \"#ff9d06\"]))     )\\     .configure_axis(grid=False)  #lambda_plot.save(\"../paper/figures/two_clusters_lambda.svg\") In\u00a0[4]: Copied! <pre>data = pd.DataFrame(data)\ndata[\"cluster\"] = embedding[\"cluster\"]\ndata.columns = [\"x\", \"y\", \"cluster\"]\ndata[\"s0\"] = 1\ndata[\"s1\"] = 1\n</pre> data = pd.DataFrame(data) data[\"cluster\"] = embedding[\"cluster\"] data.columns = [\"x\", \"y\", \"cluster\"] data[\"s0\"] = 1 data[\"s1\"] = 1 In\u00a0[5]: Copied! <pre>from distortions.visualization import dplot\n\nplots = {}\nplots[\"two_clusters\"] = dplot(data, width=450, height=350, labelFontSize=14)\\\n    .mapping(x=\"x\", y=\"y\", color=\"cluster\")\\\n    .scale_color(scheme=[\"turquoise\", \"orange\"])\\\n    .geom_ellipse(radiusMax=6, radiusMin=1)\\\n    .labs(x = \"Original 1\", y = \"Original 2\")\n</pre> from distortions.visualization import dplot  plots = {} plots[\"two_clusters\"] = dplot(data, width=450, height=350, labelFontSize=14)\\     .mapping(x=\"x\", y=\"y\", color=\"cluster\")\\     .scale_color(scheme=[\"turquoise\", \"orange\"])\\     .geom_ellipse(radiusMax=6, radiusMin=1)\\     .labs(x = \"Original 1\", y = \"Original 2\") In\u00a0[6]: Copied! <pre>from distortions.geometry import neighborhoods\n\nN = neighborhoods(adata, threshold=0.1, outlier_factor=3)\ndplot(embedding, width=450, height=350, labelFontSize=14)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cluster\")\\\n    .inter_edge_link(N=N, threshold=1, backgroundOpacity=0.8)\\\n    .scale_color(scheme=[\"turquoise\", \"orange\"])\\\n    .geom_ellipse(radiusMax=10, radiusMin=1)\\\n    .labs(x = \"UMAP1\", y = \"UMAP2\")\n</pre> from distortions.geometry import neighborhoods  N = neighborhoods(adata, threshold=0.1, outlier_factor=3) dplot(embedding, width=450, height=350, labelFontSize=14)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cluster\")\\     .inter_edge_link(N=N, threshold=1, backgroundOpacity=0.8)\\     .scale_color(scheme=[\"turquoise\", \"orange\"])\\     .geom_ellipse(radiusMax=10, radiusMin=1)\\     .labs(x = \"UMAP1\", y = \"UMAP2\") Out[6]: <pre>dplot(dataset=[{'embedding_0': -7.3624162673950195, 'embedding_1': 5.324365139007568, 'x0': -0.061769458747554\u2026</pre> In\u00a0[7]: Copied! <pre>metrics = {k: H[k] for k in range(len(H))}\nplots[\"two_clusters_isometry\"] = dplot(embedding, width=450, height=350, labelFontSize=14)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cluster\")\\\n    .geom_ellipse(radiusMin=1, radiusMax=10)\\\n    .inter_isometry(metrics=metrics, metric_bw=1, transformation_bw=.1, stroke=\"#f7f7f7\")\\\n    .scale_color(scheme=[\"turquoise\", \"orange\"])\\\n    .scale_size()\\\n    .labs(x=\"UMAP1\", y=\"UMAP2\")\n\nplots[\"two_clusters_metric\"] = dplot(embedding, width=450, height=350, labelFontSize=14)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"kernel_metric\")\\\n    .geom_ellipse(radiusMin=1, radiusMax=10)\\\n    .inter_isometry(metrics=metrics, metric_bw=1, transformation_bw=.1, stroke=\"#f7f7f7\")\\\n    .scale_color(scheme=[\"turquoise\", \"orange\"])\\\n    .scale_size()\\\n    .labs(x=\"UMAP1\", y=\"UMAP2\")\n\nplots[\"two_clusters_transform\"] = dplot(embedding, width=450, height=350, labelFontSize=14)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"kernel_transform\")\\\n    .geom_ellipse(radiusMin=1, radiusMax=10)\\\n    .inter_isometry(metrics=metrics, metric_bw=1, transformation_bw=.1, stroke=\"#f7f7f7\")\\\n    .scale_color(scheme=[\"turquoise\", \"orange\"])\\\n    .scale_size()\\\n    .labs(x=\"UMAP1\", y=\"UMAP2\")\n</pre> metrics = {k: H[k] for k in range(len(H))} plots[\"two_clusters_isometry\"] = dplot(embedding, width=450, height=350, labelFontSize=14)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cluster\")\\     .geom_ellipse(radiusMin=1, radiusMax=10)\\     .inter_isometry(metrics=metrics, metric_bw=1, transformation_bw=.1, stroke=\"#f7f7f7\")\\     .scale_color(scheme=[\"turquoise\", \"orange\"])\\     .scale_size()\\     .labs(x=\"UMAP1\", y=\"UMAP2\")  plots[\"two_clusters_metric\"] = dplot(embedding, width=450, height=350, labelFontSize=14)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"kernel_metric\")\\     .geom_ellipse(radiusMin=1, radiusMax=10)\\     .inter_isometry(metrics=metrics, metric_bw=1, transformation_bw=.1, stroke=\"#f7f7f7\")\\     .scale_color(scheme=[\"turquoise\", \"orange\"])\\     .scale_size()\\     .labs(x=\"UMAP1\", y=\"UMAP2\")  plots[\"two_clusters_transform\"] = dplot(embedding, width=450, height=350, labelFontSize=14)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"kernel_transform\")\\     .geom_ellipse(radiusMin=1, radiusMax=10)\\     .inter_isometry(metrics=metrics, metric_bw=1, transformation_bw=.1, stroke=\"#f7f7f7\")\\     .scale_color(scheme=[\"turquoise\", \"orange\"])\\     .scale_size()\\     .labs(x=\"UMAP1\", y=\"UMAP2\") In\u00a0[\u00a0]: Copied! <pre>#[p.save(f\"../paper/figures/{k}.svg\") for k, p in plots.items()]\n</pre> #[p.save(f\"../paper/figures/{k}.svg\") for k, p in plots.items()] Out[\u00a0]: <pre>[None, None, None, None]</pre> In\u00a0[9]: Copied! <pre>[display(p) for p in plots.values()]\n</pre> [display(p) for p in plots.values()] <pre>dplot(dataset=[{'x': -10.53549603766011, 'y': -1.8629896720824943, 'cluster': 'A', 's0': 1, 's1': 1}, {'x': 29\u2026</pre> <pre>dplot(dataset=[{'embedding_0': -7.3624162673950195, 'embedding_1': 5.324365139007568, 'x0': -0.061769458747554\u2026</pre> <pre>dplot(dataset=[{'embedding_0': -7.3624162673950195, 'embedding_1': 5.324365139007568, 'x0': -0.061769458747554\u2026</pre> <pre>dplot(dataset=[{'embedding_0': -7.3624162673950195, 'embedding_1': 5.324365139007568, 'x0': -0.061769458747554\u2026</pre> Out[9]: <pre>[None, None, None, None]</pre> <p>Here is an example with a random initialization.</p> In\u00a0[10]: Copied! <pre>sc.tl.umap(adata, init_pos=\"random\")\nembedding_random = adata.obsm[\"X_umap\"].copy()\n\nH, Hvv, Hs = local_distortions(embedding_random, data, geom)\nembedding_random = bind_metric(embedding_random, Hvv, Hs)\nembedding_random[\"cluster\"] = [\"A\", \"B\"] * M\n</pre> sc.tl.umap(adata, init_pos=\"random\") embedding_random = adata.obsm[\"X_umap\"].copy()  H, Hvv, Hs = local_distortions(embedding_random, data, geom) embedding_random = bind_metric(embedding_random, Hvv, Hs) embedding_random[\"cluster\"] = [\"A\", \"B\"] * M In\u00a0[11]: Copied! <pre>N = neighborhoods(adata, threshold=0.1, outlier_factor=2)\ndplot(embedding_random, width=450, height=350, labelFontSize=14)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cluster\")\\\n    .inter_edge_link(N=N, threshold=1, backgroundOpacity=0.8)\\\n    .scale_color(scheme=[\"turquoise\", \"orange\"])\\\n    .geom_ellipse(radiusMax=6, radiusMin=1)\n</pre> N = neighborhoods(adata, threshold=0.1, outlier_factor=2) dplot(embedding_random, width=450, height=350, labelFontSize=14)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cluster\")\\     .inter_edge_link(N=N, threshold=1, backgroundOpacity=0.8)\\     .scale_color(scheme=[\"turquoise\", \"orange\"])\\     .geom_ellipse(radiusMax=6, radiusMin=1) Out[11]: <pre>dplot(dataset=[{'embedding_0': 11.932002067565918, 'embedding_1': 3.433741331100464, 'x0': -0.8767524756933656\u2026</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"}]}