{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Distortions","text":"<p>The <code>distortions</code> package gives functions to compute and visualize the distortions that are introduced by nonlinear dimensionality reduction algorithms. It is designed to wrap arbitrary embedding methods and builds on the distortion estimation routines from the <code>megaman</code> package.  The resulting visualizations can let you interactively query properties that are not well preserved by the embedding. For example, the image below shows us selecting distances that are larger in the embedding space compared to the original data space. This allows us to describe the large-scale distortions induced by the embedding. For example, we can that some of the T cells have many neighbors with monocytes (to run this yourself, see the <code>PBMC Atlas</code> article).</p> <p></p> <p>Alternatively, we can study how the embedding warps distances more locally. Each ellipse in the figure below represents the way in which distances in the original data manifold are warped. By hovering over different regions of the map, we invert the warping in the region surrounding the mouse. For example, this shows that the T cells near the top and bottom of the T cell cluster are in fact more distant from each othoer than the static embedding would suggest.</p> <p></p>"},{"location":"index.html#quickstart","title":"Quickstart","text":"<p>You can install the package using:</p> <pre><code>python -m pip install distortions\n</code></pre> <p>Here's a small example on a UMAP applied to a simulated <code>AnnData</code> object. First we generate some random data and embeddings.</p> <pre><code>import anndata as ad\nimport scanpy as sc\nimport numpy as np\n\nadata = ad.AnnData(np.random.poisson(2, size=(100, 5)))\nsc.pp.neighbors(adata, n_neighbors=15)\nsc.tl.umap(adata)\n</code></pre> <p>Next we estimate the local distortions and bind the relevant ellipse information to our embeddings. The <code>Geometry</code> object comes from the <code>megaman</code> package and gives ways of representing the intrinsic geometry of a manifold.</p> <pre><code>from distortions.geometry import Geometry, bind_metric, local_distortions, neighborhoods\n\ngeom = Geometry(affinity_kwds={\"radius\": 2}, adjacency_kwds={\"n_neighbors\": 15})\n_, Hvv, Hs = local_distortions(adata.obsm[\"X_umap\"], adata.X, geom)\nembedding = bind_metric(adata.obsm[\"X_umap\"], Hvv, Hs)\n</code></pre> <p>Now we can make the visualization.</p> <pre><code>from distortions.visualization import dplot\n\nN = neighborhoods(adata, 1)\ndplot(embedding)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\")\\\n    .inter_edge_link(N=N)\\\n    .geom_ellipse()\n</code></pre> <p></p> <p>At a high level, the main functions exported by this package are:</p> <ul> <li><code>local_distortions</code>: Estimate the local distortion associated with each sample.</li> <li><code>neighborhoods</code>: Identify neighborhoods that have been fragmented by the embedding method. These are sets of points that had been close together in the original space but which are spread far apart in the embedding.</li> <li><code>dplot</code>: Initialize a distortion plot object. Different encodings and interactions can be layered on top of this initial call.</li> </ul> <p>Each <code>dplot</code> object has a few static (<code>geom</code>) and interactive (<code>inter</code>) layers that we can then assemble to create a distortion plot.</p> <ul> <li><code>geom_ellipse</code>: Draw an ellipse layer that encodes the local distortion associated with each sample.</li> <li><code>geom_hair</code>: Draw an line segment layer that encodes the local distortion associated with each sample. It's visually more compact than <code>geom_ellipse</code>, at the cost of only showing the ratio between ellipse axes lengths.</li> <li><code>inter_isometry</code>: Interactively isometrize from the region surrounding the mouse. This reduces the distortion around the mouse position, at the potential cost of increasing distortion globally.</li> <li><code>inter_edge_link</code>: Highlight distorted neighborhoods. This expects the output of <code>neighborhoods</code> as input. Hovering over one distorted neighborhood reveals all the edges that it's made up of.</li> <li><code>inter_boxplot</code>: Allow selection of outlying edges which have either much larger or smaller embedding distance relative to their original distance.</li> </ul> <p>The full function reference can be found here. You can find more realistic examples applying the package in the articles listed at the side of this page.</p>"},{"location":"index.html#help","title":"Help","text":"<p>You can reach us by creating an Issue in the package repository or sending an email to ksankaran@wisc.edu. We appreciate your trying out the package and will try our best to reply promptly.</p>"},{"location":"reference/api.html","title":"Function Reference","text":""},{"location":"reference/api.html#api-reference","title":"API Reference","text":""},{"location":"reference/api.html#distortionsgeometry","title":"<code>distortions.geometry</code>","text":""},{"location":"reference/api.html#distortions.geometry.Geometry","title":"<code>Geometry</code>","text":"<p>               Bases: <code>object</code></p> <p>The Geometry class stores the data, distance, affinity and laplacian matrices used by the various embedding methods and is the primary object passed to embedding functions.</p> <p>The Geometry class contains functions to compute the aforementioned matrices and allows for re-computation whenever necessary.</p> <p>Parameters:</p> Name Type Description Default <code>adjacency_method</code> <code>string {'auto', 'brute', 'pyflann', 'cyflann'}</code> <p>method for computing pairwise radius neighbors graph.</p> <code>'auto'</code> <code>adjacency_kwds</code> <code>dict</code> <p>dictionary containing keyword arguments for adjacency matrix. see distance.py docmuentation for arguments for each method. If new kwargs are passed to compute_adjacency_matrix then this dictionary will be updated.</p> <code>None</code> <code>affinity_method</code> <code>string {'auto', 'gaussian'}</code> <p>method of computing affinity matrix</p> <code>'auto'</code> <code>affinity_kwds</code> <code>dict</code> <p>dictionary containing keyword arguments for affinity matrix. see affinity.py documentation for arguments for each method. If new kwargs are passed to compute_affinity_matrix then this dictionary will be updated.</p> <code>None</code> <code>laplacian_method</code> <code>(string,)</code> <p>type of laplacian to be computed. Possibilities are {'symmetricnormalized', 'geometric', 'renormalized', 'unnormalized', 'randomwalk'} see laplacian.py for more information.</p> <code>'auto'</code> <code>laplacian_kwds</code> <code>dice</code> <p>dictionary containing keyword arguments for Laplacian matrix. see laplacian.py docmuentation for arguments for each method. If new kwargs are passed to compute_laplacian_matrix then this dictionary will be updated.</p> <code>None</code> <code>**kwargs</code> <p>additional arguments will be parsed and used to override values in the above dictionaries. For example: - <code>affinity_radius</code> will override <code>affinity_kwds['radius']</code> - <code>adjacency_n_neighbors</code> will override <code>adjacency_kwds['n_neighbors']</code> etc.</p> <code>{}</code> Source code in <code>distortions/geometry/geometry.py</code> <pre><code>class Geometry(object):\n    \"\"\"\n    The Geometry class stores the data, distance, affinity and laplacian\n    matrices used by the various embedding methods and is the primary\n    object passed to embedding functions.\n\n    The Geometry class contains functions to compute the aforementioned\n    matrices and allows for re-computation whenever necessary.\n\n    Parameters\n    ----------\n    adjacency_method : string {'auto', 'brute', 'pyflann', 'cyflann'}\n        method for computing pairwise radius neighbors graph.\n    adjacency_kwds : dict\n        dictionary containing keyword arguments for adjacency matrix.\n        see distance.py docmuentation for arguments for each method.\n        If new kwargs are passed to compute_adjacency_matrix then this\n        dictionary will be updated.\n    affinity_method : string {'auto', 'gaussian'}\n        method of computing affinity matrix\n    affinity_kwds : dict\n        dictionary containing keyword arguments for affinity matrix.\n        see affinity.py documentation for arguments for each method.\n        If new kwargs are passed to compute_affinity_matrix then this\n        dictionary will be updated.\n    laplacian_method : string,\n        type of laplacian to be computed. Possibilities are\n        {'symmetricnormalized', 'geometric', 'renormalized',\n        'unnormalized', 'randomwalk'} see laplacian.py for more information.\n    laplacian_kwds : dice\n        dictionary containing keyword arguments for Laplacian matrix.\n        see laplacian.py docmuentation for arguments for each method.\n        If new kwargs are passed to compute_laplacian_matrix then this\n        dictionary will be updated.\n    **kwargs :\n        additional arguments will be parsed and used to override values in\n        the above dictionaries. For example:\n        - `affinity_radius` will override `affinity_kwds['radius']`\n        - `adjacency_n_neighbors` will override `adjacency_kwds['n_neighbors']`\n        etc.\n    \"\"\"\n    def __init__(self, adjacency_method='auto', adjacency_kwds=None,\n                 affinity_method='auto', affinity_kwds=None,\n                 laplacian_method='auto',laplacian_kwds=None, **kwargs):\n        self.adjacency_method = adjacency_method\n        self.adjacency_kwds = dict(**(adjacency_kwds or {}))\n        self.affinity_method = affinity_method\n        self.affinity_kwds = dict(**(affinity_kwds or {}))\n        self.laplacian_method = laplacian_method\n        self.laplacian_kwds = dict(**(laplacian_kwds or {}))\n\n        # map extra keywords: e.g. affinity_radius -&gt; affinity_kwds['radius']\n        dicts = dict(adjaceny=self.adjacency_kwds,\n                     affinity=self.affinity_kwds,\n                     laplacian=self.laplacian_kwds)\n        for key, val in kwargs.items():\n            keysplit = key.split('_')\n            if keysplit[0] not in dicts:\n                raise ValueError('key `{0}` not valid'.format(key))\n            dicts[keysplit[0]]['_'.join(keysplit[1:])] = val\n\n        self.X = None\n        self.adjacency_matrix = None\n        self.affinity_matrix = None\n        self.laplacian_matrix = None\n        self.laplacian_symmetric = None\n        self.laplacian_weights = None\n\n    def set_radius(self, radius, override=True, X=None, n_components=2):\n        \"\"\"Set the radius for the adjacency and affinity computation\n\n        By default, this will override keyword arguments provided on\n        initialization.\n\n        Parameters\n        ----------\n        radius : float\n            radius to set for adjacency and affinity.\n        override : bool (default: True)\n            if False, then only set radius if not already defined in\n            `adjacency_args` and `affinity_args`.\n        X : ndarray or sparse (optional)\n            if provided, estimate a suitable radius from this data.\n        n_components : int (default=2)\n            the number of components to use when estimating the radius\n        \"\"\"\n        if radius &lt; 0:\n            raise ValueError(\"radius must be non-negative\")\n\n        if override or ('radius' not in self.adjacency_kwds and\n                        'n_neighbors' not in self.adjacency_kwds):\n            self.adjacency_kwds['radius'] = radius\n\n        if override or ('radius' not in self.affinity_kwds):\n            self.affinity_kwds['radius'] = radius\n\n    def set_matrix(self, X, input_type):\n        \"\"\"\n        Set the data matrix given the input type.\n\n        Parameters\n        ----------\n        X : array-like\n            Input matrix to set.\n        input_type : str\n            Type of matrix to set. Options: {'data', 'adjacency', 'affinity'}\n        \"\"\"\n        if input_type == 'data':\n            self.set_data_matrix(X)\n        elif input_type == 'adjacency':\n            self.set_adjacency_matrix(X)\n        elif input_type == 'affinity':\n            self.set_affinity_matrix(X)\n        else:\n            raise ValueError(\"Unrecognized input_type: {0}\".format(input_type))\n\n\n    def compute_adjacency_matrix(self, copy=False, **kwargs):\n        \"\"\"\n        This function will compute the adjacency matrix.\n        In order to acquire the existing adjacency matrix use\n        self.adjacency_matrix as comptute_adjacency_matrix() will re-compute\n        the adjacency matrix.\n\n        Parameters\n        ----------\n        copy : boolean, whether to return a copied version of the adjacency matrix\n        **kwargs : see distance.py docmuentation for arguments for each method.\n\n        Returns\n        -------\n        self.adjacency_matrix : sparse matrix (N_obs, N_obs)\n            Non explicit 0.0 values should be considered not connected.\n        \"\"\"\n        if self.X is None:\n            raise ValueError(distance_error_msg)\n\n        kwds = self.adjacency_kwds.copy()\n        kwds.update(kwargs)\n        self.adjacency_matrix = compute_adjacency_matrix(self.X,\n                                                         self.adjacency_method,\n                                                         **kwds)\n        if copy:\n            return self.adjacency_matrix.copy()\n        else:\n            return self.adjacency_matrix\n\n    def compute_affinity_matrix(self, copy=False, **kwargs):\n        \"\"\"\n        This function will compute the affinity matrix. In order to\n        acquire the existing affinity matrix use self.affinity_matrix as\n        comptute_affinity_matrix() will re-compute the affinity matrix.\n\n        Parameters\n        ----------\n        copy : boolean\n            whether to return a copied version of the affinity matrix\n        **kwargs :\n            see affinity.py docmuentation for arguments for each method.\n\n        Returns\n        -------\n        self.affinity_matrix : sparse matrix (N_obs, N_obs)\n            contains the pairwise affinity values using the Guassian kernel\n            and bandwidth equal to the affinity_radius\n        \"\"\"\n        if self.adjacency_matrix is None:\n            self.compute_adjacency_matrix()\n\n        kwds = self.affinity_kwds.copy()\n        kwds.update(kwargs)\n        self.affinity_matrix = compute_affinity_matrix(self.adjacency_matrix,\n                                                       self.affinity_method,\n                                                       **kwds)\n        if copy:\n            return self.affinity_matrix.copy()\n        else:\n            return self.affinity_matrix\n\n    def compute_laplacian_matrix(self, copy=True, return_lapsym=False, **kwargs):\n        \"\"\"\n        Note: this function will compute the laplacian matrix. In order to acquire\n            the existing laplacian matrix use self.laplacian_matrix as\n            compute_laplacian_matrix() will re-compute the laplacian matrix.\n\n        Parameters\n        ----------\n        copy : boolean, whether to return copied version of the self.laplacian_matrix\n        return_lapsym : boolean, if True returns additionally the symmetrized version of\n            the requested laplacian and the re-normalization weights.\n        **kwargs : see laplacian.py docmuentation for arguments for each method.\n\n        Returns\n        -------\n        self.laplacian_matrix : sparse matrix (N_obs, N_obs).\n            The requested laplacian.\n        self.laplacian_symmetric : sparse matrix (N_obs, N_obs)\n            The symmetric laplacian.\n        self.laplacian_weights : ndarray (N_obs,)\n            The renormalization weights used to make\n            laplacian_matrix from laplacian_symmetric\n        \"\"\"\n        if self.affinity_matrix is None:\n            self.compute_affinity_matrix()\n\n        kwds = self.laplacian_kwds.copy()\n        kwds.update(kwargs)\n        kwds['full_output'] = return_lapsym\n        result = compute_laplacian_matrix(self.affinity_matrix,\n                                          self.laplacian_method,\n                                          **kwds)\n        if return_lapsym:\n            (self.laplacian_matrix,\n             self.laplacian_symmetric,\n             self.laplacian_weights) = result\n        else:\n            self.laplacian_matrix = result\n\n        if copy:\n            return self.laplacian_matrix.copy()\n        else:\n            return self.laplacian_matrix\n\n    def set_data_matrix(self, X):\n        \"\"\"\n        Set the data matrix.\n\n        Parameters\n        ----------\n        X : array-like, shape (n_samples, n_features)\n            The original data set to input.\n        \"\"\"\n        #X = check_array(X, accept_sparse=sparse_formats)\n        self.X = X\n\n    def set_adjacency_matrix(self, adjacency_mat):\n        \"\"\"\n        Set the adjacency matrix.\n\n        Parameters\n        ----------\n        adjacency_mat : sparse matrix, shape (n_samples, n_samples)\n            The adjacency matrix to input.\n        \"\"\"\n        #adjacency_mat = check_array(adjacency_mat, accept_sparse=sparse_formats)\n        if adjacency_mat.shape[0] != adjacency_mat.shape[1]:\n            raise ValueError(\"adjacency matrix is not square\")\n        self.adjacency_matrix = adjacency_mat\n\n    def set_affinity_matrix(self, affinity_mat):\n        \"\"\"\n        Set the affinity matrix.\n\n        Parameters\n        ----------\n        affinity_mat : sparse matrix (N_obs, N_obs).\n            The adjacency matrix to input.\n        \"\"\"\n        #affinity_mat = check_array(affinity_mat, accept_sparse=sparse_formats)\n        if affinity_mat.shape[0] != affinity_mat.shape[1]:\n            raise ValueError(\"affinity matrix is not square\")\n        self.affinity_matrix = affinity_mat\n\n    def set_laplacian_matrix(self, laplacian_mat):\n        \"\"\"\n        Set the Laplacian matrix.\n\n        Parameters\n        ----------\n        laplacian_mat : sparse matrix (N_obs, N_obs).\n            The Laplacian matrix to input.\n        \"\"\"\n        #laplacian_mat = check_array(laplacian_mat, accept_sparse = sparse_formats)\n        if laplacian_mat.shape[0] != laplacian_mat.shape[1]:\n            raise ValueError(\"Laplacian matrix is not square\")\n        self.laplacian_matrix = laplacian_mat\n\n    def delete_data_matrix(self):\n        \"\"\"Delete the data matrix from the Geometry object.\"\"\"\n        self.X = None\n\n    def delete_adjacency_matrix(self):\n        \"\"\"Delete the adjacency matrix from the Geometry object.\"\"\"\n        self.adjacency_matrix = None\n\n    def delete_affinity_matrix(self):\n        \"\"\"Delete the affinity matrix from the Geometry object.\"\"\"\n        self.affinity_matrix = None\n\n    def delete_laplacian_matrix(self):\n        \"\"\"Delete the Laplacian matrix from the Geometry object.\"\"\"\n        self.laplacian_matrix = None\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.Geometry.compute_adjacency_matrix","title":"<code>compute_adjacency_matrix(copy=False, **kwargs)</code>","text":"<p>This function will compute the adjacency matrix. In order to acquire the existing adjacency matrix use self.adjacency_matrix as comptute_adjacency_matrix() will re-compute the adjacency matrix.</p> <p>Parameters:</p> Name Type Description Default <code>copy</code> <code>boolean, whether to return a copied version of the adjacency matrix</code> <code>False</code> <code>**kwargs</code> <code>see distance.py docmuentation for arguments for each method.</code> <code>{}</code> <p>Returns:</p> Type Description <code>self.adjacency_matrix : sparse matrix (N_obs, N_obs)</code> <p>Non explicit 0.0 values should be considered not connected.</p> Source code in <code>distortions/geometry/geometry.py</code> <pre><code>def compute_adjacency_matrix(self, copy=False, **kwargs):\n    \"\"\"\n    This function will compute the adjacency matrix.\n    In order to acquire the existing adjacency matrix use\n    self.adjacency_matrix as comptute_adjacency_matrix() will re-compute\n    the adjacency matrix.\n\n    Parameters\n    ----------\n    copy : boolean, whether to return a copied version of the adjacency matrix\n    **kwargs : see distance.py docmuentation for arguments for each method.\n\n    Returns\n    -------\n    self.adjacency_matrix : sparse matrix (N_obs, N_obs)\n        Non explicit 0.0 values should be considered not connected.\n    \"\"\"\n    if self.X is None:\n        raise ValueError(distance_error_msg)\n\n    kwds = self.adjacency_kwds.copy()\n    kwds.update(kwargs)\n    self.adjacency_matrix = compute_adjacency_matrix(self.X,\n                                                     self.adjacency_method,\n                                                     **kwds)\n    if copy:\n        return self.adjacency_matrix.copy()\n    else:\n        return self.adjacency_matrix\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.Geometry.compute_affinity_matrix","title":"<code>compute_affinity_matrix(copy=False, **kwargs)</code>","text":"<p>This function will compute the affinity matrix. In order to acquire the existing affinity matrix use self.affinity_matrix as comptute_affinity_matrix() will re-compute the affinity matrix.</p> <p>Parameters:</p> Name Type Description Default <code>copy</code> <code>boolean</code> <p>whether to return a copied version of the affinity matrix</p> <code>False</code> <code>**kwargs</code> <p>see affinity.py docmuentation for arguments for each method.</p> <code>{}</code> <p>Returns:</p> Type Description <code>self.affinity_matrix : sparse matrix (N_obs, N_obs)</code> <p>contains the pairwise affinity values using the Guassian kernel and bandwidth equal to the affinity_radius</p> Source code in <code>distortions/geometry/geometry.py</code> <pre><code>def compute_affinity_matrix(self, copy=False, **kwargs):\n    \"\"\"\n    This function will compute the affinity matrix. In order to\n    acquire the existing affinity matrix use self.affinity_matrix as\n    comptute_affinity_matrix() will re-compute the affinity matrix.\n\n    Parameters\n    ----------\n    copy : boolean\n        whether to return a copied version of the affinity matrix\n    **kwargs :\n        see affinity.py docmuentation for arguments for each method.\n\n    Returns\n    -------\n    self.affinity_matrix : sparse matrix (N_obs, N_obs)\n        contains the pairwise affinity values using the Guassian kernel\n        and bandwidth equal to the affinity_radius\n    \"\"\"\n    if self.adjacency_matrix is None:\n        self.compute_adjacency_matrix()\n\n    kwds = self.affinity_kwds.copy()\n    kwds.update(kwargs)\n    self.affinity_matrix = compute_affinity_matrix(self.adjacency_matrix,\n                                                   self.affinity_method,\n                                                   **kwds)\n    if copy:\n        return self.affinity_matrix.copy()\n    else:\n        return self.affinity_matrix\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.Geometry.compute_laplacian_matrix","title":"<code>compute_laplacian_matrix(copy=True, return_lapsym=False, **kwargs)</code>","text":"<p>Note: this function will compute the laplacian matrix. In order to acquire     the existing laplacian matrix use self.laplacian_matrix as     compute_laplacian_matrix() will re-compute the laplacian matrix.</p> <p>Parameters:</p> Name Type Description Default <code>copy</code> <code>boolean, whether to return copied version of the self.laplacian_matrix</code> <code>True</code> <code>return_lapsym</code> <code>boolean, if True returns additionally the symmetrized version of</code> <p>the requested laplacian and the re-normalization weights.</p> <code>False</code> <code>**kwargs</code> <code>see laplacian.py docmuentation for arguments for each method.</code> <code>{}</code> <p>Returns:</p> Type Description <code>self.laplacian_matrix : sparse matrix (N_obs, N_obs).</code> <p>The requested laplacian.</p> <code>self.laplacian_symmetric : sparse matrix (N_obs, N_obs)</code> <p>The symmetric laplacian.</p> <code>self.laplacian_weights : ndarray (N_obs,)</code> <p>The renormalization weights used to make laplacian_matrix from laplacian_symmetric</p> Source code in <code>distortions/geometry/geometry.py</code> <pre><code>def compute_laplacian_matrix(self, copy=True, return_lapsym=False, **kwargs):\n    \"\"\"\n    Note: this function will compute the laplacian matrix. In order to acquire\n        the existing laplacian matrix use self.laplacian_matrix as\n        compute_laplacian_matrix() will re-compute the laplacian matrix.\n\n    Parameters\n    ----------\n    copy : boolean, whether to return copied version of the self.laplacian_matrix\n    return_lapsym : boolean, if True returns additionally the symmetrized version of\n        the requested laplacian and the re-normalization weights.\n    **kwargs : see laplacian.py docmuentation for arguments for each method.\n\n    Returns\n    -------\n    self.laplacian_matrix : sparse matrix (N_obs, N_obs).\n        The requested laplacian.\n    self.laplacian_symmetric : sparse matrix (N_obs, N_obs)\n        The symmetric laplacian.\n    self.laplacian_weights : ndarray (N_obs,)\n        The renormalization weights used to make\n        laplacian_matrix from laplacian_symmetric\n    \"\"\"\n    if self.affinity_matrix is None:\n        self.compute_affinity_matrix()\n\n    kwds = self.laplacian_kwds.copy()\n    kwds.update(kwargs)\n    kwds['full_output'] = return_lapsym\n    result = compute_laplacian_matrix(self.affinity_matrix,\n                                      self.laplacian_method,\n                                      **kwds)\n    if return_lapsym:\n        (self.laplacian_matrix,\n         self.laplacian_symmetric,\n         self.laplacian_weights) = result\n    else:\n        self.laplacian_matrix = result\n\n    if copy:\n        return self.laplacian_matrix.copy()\n    else:\n        return self.laplacian_matrix\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.Geometry.delete_adjacency_matrix","title":"<code>delete_adjacency_matrix()</code>","text":"<p>Delete the adjacency matrix from the Geometry object.</p> Source code in <code>distortions/geometry/geometry.py</code> <pre><code>def delete_adjacency_matrix(self):\n    \"\"\"Delete the adjacency matrix from the Geometry object.\"\"\"\n    self.adjacency_matrix = None\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.Geometry.delete_affinity_matrix","title":"<code>delete_affinity_matrix()</code>","text":"<p>Delete the affinity matrix from the Geometry object.</p> Source code in <code>distortions/geometry/geometry.py</code> <pre><code>def delete_affinity_matrix(self):\n    \"\"\"Delete the affinity matrix from the Geometry object.\"\"\"\n    self.affinity_matrix = None\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.Geometry.delete_data_matrix","title":"<code>delete_data_matrix()</code>","text":"<p>Delete the data matrix from the Geometry object.</p> Source code in <code>distortions/geometry/geometry.py</code> <pre><code>def delete_data_matrix(self):\n    \"\"\"Delete the data matrix from the Geometry object.\"\"\"\n    self.X = None\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.Geometry.delete_laplacian_matrix","title":"<code>delete_laplacian_matrix()</code>","text":"<p>Delete the Laplacian matrix from the Geometry object.</p> Source code in <code>distortions/geometry/geometry.py</code> <pre><code>def delete_laplacian_matrix(self):\n    \"\"\"Delete the Laplacian matrix from the Geometry object.\"\"\"\n    self.laplacian_matrix = None\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.Geometry.set_adjacency_matrix","title":"<code>set_adjacency_matrix(adjacency_mat)</code>","text":"<p>Set the adjacency matrix.</p> <p>Parameters:</p> Name Type Description Default <code>adjacency_mat</code> <code>sparse matrix, shape (n_samples, n_samples)</code> <p>The adjacency matrix to input.</p> required Source code in <code>distortions/geometry/geometry.py</code> <pre><code>def set_adjacency_matrix(self, adjacency_mat):\n    \"\"\"\n    Set the adjacency matrix.\n\n    Parameters\n    ----------\n    adjacency_mat : sparse matrix, shape (n_samples, n_samples)\n        The adjacency matrix to input.\n    \"\"\"\n    #adjacency_mat = check_array(adjacency_mat, accept_sparse=sparse_formats)\n    if adjacency_mat.shape[0] != adjacency_mat.shape[1]:\n        raise ValueError(\"adjacency matrix is not square\")\n    self.adjacency_matrix = adjacency_mat\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.Geometry.set_affinity_matrix","title":"<code>set_affinity_matrix(affinity_mat)</code>","text":"<p>Set the affinity matrix.</p> <p>Parameters:</p> Name Type Description Default <code>affinity_mat</code> <code>sparse matrix (N_obs, N_obs).</code> <p>The adjacency matrix to input.</p> required Source code in <code>distortions/geometry/geometry.py</code> <pre><code>def set_affinity_matrix(self, affinity_mat):\n    \"\"\"\n    Set the affinity matrix.\n\n    Parameters\n    ----------\n    affinity_mat : sparse matrix (N_obs, N_obs).\n        The adjacency matrix to input.\n    \"\"\"\n    #affinity_mat = check_array(affinity_mat, accept_sparse=sparse_formats)\n    if affinity_mat.shape[0] != affinity_mat.shape[1]:\n        raise ValueError(\"affinity matrix is not square\")\n    self.affinity_matrix = affinity_mat\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.Geometry.set_data_matrix","title":"<code>set_data_matrix(X)</code>","text":"<p>Set the data matrix.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>(array - like, shape(n_samples, n_features))</code> <p>The original data set to input.</p> required Source code in <code>distortions/geometry/geometry.py</code> <pre><code>def set_data_matrix(self, X):\n    \"\"\"\n    Set the data matrix.\n\n    Parameters\n    ----------\n    X : array-like, shape (n_samples, n_features)\n        The original data set to input.\n    \"\"\"\n    #X = check_array(X, accept_sparse=sparse_formats)\n    self.X = X\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.Geometry.set_laplacian_matrix","title":"<code>set_laplacian_matrix(laplacian_mat)</code>","text":"<p>Set the Laplacian matrix.</p> <p>Parameters:</p> Name Type Description Default <code>laplacian_mat</code> <code>sparse matrix (N_obs, N_obs).</code> <p>The Laplacian matrix to input.</p> required Source code in <code>distortions/geometry/geometry.py</code> <pre><code>def set_laplacian_matrix(self, laplacian_mat):\n    \"\"\"\n    Set the Laplacian matrix.\n\n    Parameters\n    ----------\n    laplacian_mat : sparse matrix (N_obs, N_obs).\n        The Laplacian matrix to input.\n    \"\"\"\n    #laplacian_mat = check_array(laplacian_mat, accept_sparse = sparse_formats)\n    if laplacian_mat.shape[0] != laplacian_mat.shape[1]:\n        raise ValueError(\"Laplacian matrix is not square\")\n    self.laplacian_matrix = laplacian_mat\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.Geometry.set_matrix","title":"<code>set_matrix(X, input_type)</code>","text":"<p>Set the data matrix given the input type.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array - like</code> <p>Input matrix to set.</p> required <code>input_type</code> <code>str</code> <p>Type of matrix to set. Options: {'data', 'adjacency', 'affinity'}</p> required Source code in <code>distortions/geometry/geometry.py</code> <pre><code>def set_matrix(self, X, input_type):\n    \"\"\"\n    Set the data matrix given the input type.\n\n    Parameters\n    ----------\n    X : array-like\n        Input matrix to set.\n    input_type : str\n        Type of matrix to set. Options: {'data', 'adjacency', 'affinity'}\n    \"\"\"\n    if input_type == 'data':\n        self.set_data_matrix(X)\n    elif input_type == 'adjacency':\n        self.set_adjacency_matrix(X)\n    elif input_type == 'affinity':\n        self.set_affinity_matrix(X)\n    else:\n        raise ValueError(\"Unrecognized input_type: {0}\".format(input_type))\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.Geometry.set_radius","title":"<code>set_radius(radius, override=True, X=None, n_components=2)</code>","text":"<p>Set the radius for the adjacency and affinity computation</p> <p>By default, this will override keyword arguments provided on initialization.</p> <p>Parameters:</p> Name Type Description Default <code>radius</code> <code>float</code> <p>radius to set for adjacency and affinity.</p> required <code>override</code> <code>bool (default: True)</code> <p>if False, then only set radius if not already defined in <code>adjacency_args</code> and <code>affinity_args</code>.</p> <code>True</code> <code>X</code> <code>ndarray or sparse(optional)</code> <p>if provided, estimate a suitable radius from this data.</p> <code>None</code> <code>n_components</code> <code>int(default=2)</code> <p>the number of components to use when estimating the radius</p> <code>2</code> Source code in <code>distortions/geometry/geometry.py</code> <pre><code>def set_radius(self, radius, override=True, X=None, n_components=2):\n    \"\"\"Set the radius for the adjacency and affinity computation\n\n    By default, this will override keyword arguments provided on\n    initialization.\n\n    Parameters\n    ----------\n    radius : float\n        radius to set for adjacency and affinity.\n    override : bool (default: True)\n        if False, then only set radius if not already defined in\n        `adjacency_args` and `affinity_args`.\n    X : ndarray or sparse (optional)\n        if provided, estimate a suitable radius from this data.\n    n_components : int (default=2)\n        the number of components to use when estimating the radius\n    \"\"\"\n    if radius &lt; 0:\n        raise ValueError(\"radius must be non-negative\")\n\n    if override or ('radius' not in self.adjacency_kwds and\n                    'n_neighbors' not in self.adjacency_kwds):\n        self.adjacency_kwds['radius'] = radius\n\n    if override or ('radius' not in self.affinity_kwds):\n        self.affinity_kwds['radius'] = radius\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.bind_metric","title":"<code>bind_metric(embedding, Hvv, Hs)</code>","text":"<p>Combine embedding coordinates with local Riemannian metric information.</p> <p>Parameters:</p> Name Type Description Default <code>embedding</code> <code>(ndarray, shape(n_samples, n_embedding_dims))</code> <p>The low-dimensional embedding of the data. This should be the same array as the <code>embedding</code> argument passed to <code>local_distortions</code>.</p> required <code>Hvv</code> <code>(ndarray, shape(n_samples, n_embedding_dims, n_embedding_dims))</code> <p>The singular vectors of the dual Riemannian metric tensor for each sample, as returned by <code>local_distortions</code>.</p> required <code>Hs</code> <code>(ndarray, shape(n_samples, n_embedding_dims))</code> <p>The singular values of the dual Riemannian metric tensor for each sample, as returned by <code>local_distortions</code>.</p> required <p>Returns:</p> Name Type Description <code>combined</code> <code>DataFrame</code> <p>A DataFrame containing the embedding coordinates, the singular vectors and singular values of the local dual Riemannian metric for each sample, and an additional column \"angle\" computed from the first two singular vector components.</p> Notes <p>This function is intended to facilitate analysis and visualization by merging the embedding and local metric information into a single tabular structure.</p> Source code in <code>distortions/geometry/rmetric.py</code> <pre><code>def bind_metric(embedding, Hvv, Hs):\n    \"\"\"\n    Combine embedding coordinates with local Riemannian metric information.\n\n    Parameters\n    ----------\n    embedding : np.ndarray, shape (n_samples, n_embedding_dims)\n        The low-dimensional embedding of the data. This should be the same array\n        as the `embedding` argument passed to `local_distortions`.\n    Hvv : np.ndarray, shape (n_samples, n_embedding_dims, n_embedding_dims)\n        The singular vectors of the dual Riemannian metric tensor for each sample,\n        as returned by `local_distortions`.\n    Hs : np.ndarray, shape (n_samples, n_embedding_dims)\n        The singular values of the dual Riemannian metric tensor for each sample,\n        as returned by `local_distortions`.\n\n    Returns\n    -------\n    combined : pd.DataFrame\n        A DataFrame containing the embedding coordinates, the singular vectors and\n        singular values of the local dual Riemannian metric for each sample, and\n        an additional column \"angle\" computed from the first two singular vector\n        components.\n\n    Notes\n    -----\n    This function is intended to facilitate analysis and visualization by merging\n    the embedding and local metric information into a single tabular structure.\n    \"\"\"\n    K = embedding.shape[1]\n    Hvv_df = pd.concat([arrays_to_df(Hvv), arrays_to_df(Hs)], axis=1)\n    embedding_df = pd.DataFrame(embedding, columns=[f\"embedding_{i}\" for i in range(K)])\n    embedding_df = embedding_df.reset_index(drop=True)\n    Hvv_df = Hvv_df.reset_index(drop=True)\n\n    # merge the embedding and metric data\n    combined = pd.concat([embedding_df, Hvv_df], axis=1)\n    metric_columns = sum([[f\"x{i}\", f\"y{i}\"] for i in range(K)], []) + [f\"s{i}\" for i in range(K)]\n    combined.columns = list(embedding_df.columns) + metric_columns\n    combined[\"angle\"] = np.arctan(combined.y1 / combined.x1) * (180 / np.pi)\n    return combined\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.boxplot_data","title":"<code>boxplot_data(x, y, nbin=10, outlier_iqr=3, **kwargs)</code>","text":"<p>Compute boxplot statistics and identify outliers within distance bins.</p> <p>This function divides the x-values (typically true distances) into bins and computes boxplot statistics for the y-values (typically embedding distances) within each bin. It identifies outliers using the IQR method.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array - like</code> <p>Input values used for binning (typically true/original distances).</p> required <code>y</code> <code>array - like</code> <p>Target values for which to compute statistics (typically embedding distances).</p> required <code>nbin</code> <code>int</code> <p>Number of bins to divide the x-value range into.</p> <code>10</code> <code>outlier_iqr</code> <code>float</code> <p>IQR multiplier for outlier detection. Values beyond Q1 - outlier_iqrIQR or Q3 + outlier_iqrIQR within each bin are considered outliers.</p> <code>3</code> <code>**kwargs</code> <code>keyword arguments</code> <p>Additional keyword arguments (currently unused).</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>summaries</code> <code>DataFrame</code> <p>DataFrame with boxplot statistics for each bin containing columns: - 'bin_id': bin identifier - 'q1', 'q2', 'q3': quartile values - 'min', 'max': minimum and maximum values - 'iqr': interquartile range - 'lower', 'upper': outlier detection bounds - 'bin': string representation of bin range</p> <code>outliers</code> <code>DataFrame</code> <p>DataFrame with outlier information containing columns: - 'index': original index of outlier point - 'bin_id': which bin the outlier belongs to - 'bin': string representation of bin range - 'value': the outlier y-value</p> Source code in <code>distortions/geometry/neighborhoods.py</code> <pre><code>def boxplot_data(x, y, nbin=10, outlier_iqr=3, **kwargs):\n    \"\"\"\n    Compute boxplot statistics and identify outliers within distance bins.\n\n    This function divides the x-values (typically true distances) into bins and\n    computes boxplot statistics for the y-values (typically embedding distances)\n    within each bin. It identifies outliers using the IQR method.\n\n    Parameters\n    ----------\n    x : array-like\n        Input values used for binning (typically true/original distances).\n    y : array-like\n        Target values for which to compute statistics (typically embedding distances).\n    nbin : int, default=10\n        Number of bins to divide the x-value range into.\n    outlier_iqr : float, default=3\n        IQR multiplier for outlier detection. Values beyond Q1 - outlier_iqr*IQR\n        or Q3 + outlier_iqr*IQR within each bin are considered outliers.\n    **kwargs : keyword arguments\n        Additional keyword arguments (currently unused).\n\n    Returns\n    -------\n    summaries : pd.DataFrame\n        DataFrame with boxplot statistics for each bin containing columns:\n        - 'bin_id': bin identifier\n        - 'q1', 'q2', 'q3': quartile values\n        - 'min', 'max': minimum and maximum values\n        - 'iqr': interquartile range\n        - 'lower', 'upper': outlier detection bounds\n        - 'bin': string representation of bin range\n    outliers : pd.DataFrame  \n        DataFrame with outlier information containing columns:\n        - 'index': original index of outlier point\n        - 'bin_id': which bin the outlier belongs to\n        - 'bin': string representation of bin range\n        - 'value': the outlier y-value\n    \"\"\"\n    # divide the data into nbin groups, and compute quantiles in each\n    bin_ids, bin_edges = pd.cut(x, bins=nbin, labels=False, retbins=True)\n    bin_edges = np.round(bin_edges, 1)\n\n    summaries = (\n        pd.DataFrame({'bin_id': bin_ids, 'y': y})\n        .groupby('bin_id', as_index=False)['y']\n        .agg(q1=lambda v: np.percentile(v, 25),\n             q2=lambda v: np.percentile(v, 50),\n             q3=lambda v: np.percentile(v, 75),\n             min='min', max='max')\n    )\n    summaries['iqr'] = summaries.q3 - summaries.q1\n    summaries['lower'] = np.maximum(summaries.q2 - outlier_iqr * summaries.iqr, summaries['min'])\n    summaries['upper'] = np.minimum(summaries.q2 + outlier_iqr * summaries.iqr, summaries['max'])\n    summaries['bin'] = summaries['bin_id'].map(lambda b: f\"{bin_edges[b]}-{bin_edges[b + 1]}\")\n\n    # compute outliers according to the IQR above\n    outliers = [\n        {\"index\": i, \"bin_id\": int(b), \"bin\": f\"{bin_edges[b]}-{bin_edges[b + 1]}\", \"value\": val}\n        for i, (b, val) in enumerate(zip(bin_ids, y))\n        if not np.isnan(b) and (\n            val &lt; summaries.loc[b, 'q1'] - outlier_iqr * summaries.loc[b, 'iqr'] or\n            val &gt; summaries.loc[b, 'q3'] + outlier_iqr * summaries.loc[b, 'iqr']\n        )\n    ]\n    return summaries, pd.DataFrame(outliers)\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.local_distortions","title":"<code>local_distortions(embedding, data, geom)</code>","text":"<p>Compute local Riemannian metric distortions for each sample.</p> <p>Parameters:</p> Name Type Description Default <code>embedding</code> <code>(ndarray, shape(n_samples, n_embedding_dims))</code> <p>Low-dimensional embedding of the data. Each row corresponds to a sample, and each column corresponds to an embedding dimension.</p> required <code>data</code> <code>(ndarray, shape(n_samples, n_features))</code> <p>Original high-dimensional data. Each row is a sample, each column a feature.</p> required <code>geom</code> <code>Geometry</code> <p>An instance of the Geometry class (from geometry.py) that provides methods for setting the data matrix and computing the Laplacian matrix.</p> required <p>Returns:</p> Name Type Description <code>H</code> <code>ndarray</code> <p>Dual Riemannian metric tensor for each sample.</p> <code>Hvv</code> <code>ndarray</code> <p>Singular vectors of the dual metric tensor for each sample.</p> <code>Hs</code> <code>ndarray</code> <p>Singular values of the dual metric tensor for each sample.</p> Notes <p>This function sets the data matrix in the provided Geometry object, computes the Laplacian matrix, and then estimates the local Riemannian metric distortions in the embedding space using the original data.</p> Source code in <code>distortions/geometry/rmetric.py</code> <pre><code>def local_distortions(embedding, data, geom):\n    \"\"\"\n    Compute local Riemannian metric distortions for each sample.\n\n    Parameters\n    ----------\n    embedding : np.ndarray, shape (n_samples, n_embedding_dims)\n        Low-dimensional embedding of the data. Each row corresponds to a sample,\n        and each column corresponds to an embedding dimension.\n    data : np.ndarray, shape (n_samples, n_features)\n        Original high-dimensional data. Each row is a sample, each column a feature.\n    geom : Geometry\n        An instance of the Geometry class (from geometry.py) that provides\n        methods for setting the data matrix and computing the Laplacian matrix.\n\n    Returns\n    -------\n    H : np.ndarray\n        Dual Riemannian metric tensor for each sample.\n    Hvv : np.ndarray\n        Singular vectors of the dual metric tensor for each sample.\n    Hs : np.ndarray\n        Singular values of the dual metric tensor for each sample.\n\n    Notes\n    -----\n    This function sets the data matrix in the provided Geometry object,\n    computes the Laplacian matrix, and then estimates the local Riemannian\n    metric distortions in the embedding space using the original data.\n    \"\"\"\n    geom.set_data_matrix(data)\n    L = geom.compute_laplacian_matrix()\n    _, _, Hvv, Hs, _, H = riemann_metric(embedding, L, n_dim=2)\n    return H, Hvv, Hs\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.neighborhood_distances","title":"<code>neighborhood_distances(adata, embed_key='X_umap')</code>","text":"<p>Compute pairwise distances between samples and their neighbors in both original and embedding spaces.</p> <p>This function calculates pairwise distances between each sample and its neighbors in the original high-dimensional space and compares them with distances in the reduced embedding space. This is useful for analyzing how well the embedding preserves local neighborhood structure.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>Annotated data matrix. Must contain a precomputed embedding (e.g., UMAP or t-SNE) in <code>obsm[embed_key]</code> and a neighbor graph in <code>obsp[\"distances\"]</code>.</p> required <code>embed_key</code> <code>str</code> <p>Key in <code>adata.obsm</code> where the embedding coordinates are stored.</p> <code>\"X_umap\"</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with columns:     - 'center': index of the sample (cell)     - 'neighbor': index of the neighbor sample     - 'true': distance in the original space (from <code>adata.obsp[\"distances\"]</code>)     - 'embedding': distance in the embedding space (from <code>adata.obsm[embed_key]</code>)</p> Notes <p>The number of neighbors is determined by the structure of the neighbor graph in <code>adata.obsp[\"distances\"]</code>. The function assumes that the embedding and neighbor graph have already been computed.</p> Source code in <code>distortions/geometry/neighborhoods.py</code> <pre><code>def neighborhood_distances(adata, embed_key=\"X_umap\"):\n    \"\"\"\n    Compute pairwise distances between samples and their neighbors in both original and embedding spaces.\n\n    This function calculates pairwise distances between each sample and its\n    neighbors in the original high-dimensional space and compares them with\n    distances in the reduced embedding space. This is useful for analyzing\n    how well the embedding preserves local neighborhood structure.\n\n    Parameters\n    ----------\n    adata : anndata.AnnData\n        Annotated data matrix. Must contain a precomputed embedding (e.g., UMAP or t-SNE) in `obsm[embed_key]`\n        and a neighbor graph in `obsp[\"distances\"]`.\n    embed_key : str, default=\"X_umap\"\n        Key in `adata.obsm` where the embedding coordinates are stored.\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame with columns:\n            - 'center': index of the sample (cell)\n            - 'neighbor': index of the neighbor sample\n            - 'true': distance in the original space (from `adata.obsp[\"distances\"]`)\n            - 'embedding': distance in the embedding space (from `adata.obsm[embed_key]`)\n\n    Notes\n    -----\n    The number of neighbors is determined by the structure of the neighbor graph in `adata.obsp[\"distances\"]`.\n    The function assumes that the embedding and neighbor graph have already been computed.\n    \"\"\"\n    knn_graph = adata.obsp[\"distances\"]\n    dist_list = []\n\n    for ix in range(len(adata)):\n        neighbors = knn_graph[ix].nonzero()[1]\n        true = knn_graph[ix, neighbors].toarray().flatten()\n        embedding = cdist(\n            [adata.obsm[embed_key][ix, :]], \n            adata.obsm[embed_key][neighbors, :]\n        ).flatten()\n        dist_list.append(pd.DataFrame({\n            \"center\": [ix] * len(neighbors), \n            \"neighbor\": neighbors,\n            \"true\": true,\n            \"embedding\": embedding\n        }))\n\n    return pd.concat(dist_list)\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.local_distortions","title":"<code>local_distortions(embedding, data, geom)</code>","text":"<p>Compute local Riemannian metric distortions for each sample.</p> <p>Parameters:</p> Name Type Description Default <code>embedding</code> <code>(ndarray, shape(n_samples, n_embedding_dims))</code> <p>Low-dimensional embedding of the data. Each row corresponds to a sample, and each column corresponds to an embedding dimension.</p> required <code>data</code> <code>(ndarray, shape(n_samples, n_features))</code> <p>Original high-dimensional data. Each row is a sample, each column a feature.</p> required <code>geom</code> <code>Geometry</code> <p>An instance of the Geometry class (from geometry.py) that provides methods for setting the data matrix and computing the Laplacian matrix.</p> required <p>Returns:</p> Name Type Description <code>H</code> <code>ndarray</code> <p>Dual Riemannian metric tensor for each sample.</p> <code>Hvv</code> <code>ndarray</code> <p>Singular vectors of the dual metric tensor for each sample.</p> <code>Hs</code> <code>ndarray</code> <p>Singular values of the dual metric tensor for each sample.</p> Notes <p>This function sets the data matrix in the provided Geometry object, computes the Laplacian matrix, and then estimates the local Riemannian metric distortions in the embedding space using the original data.</p> Source code in <code>distortions/geometry/rmetric.py</code> <pre><code>def local_distortions(embedding, data, geom):\n    \"\"\"\n    Compute local Riemannian metric distortions for each sample.\n\n    Parameters\n    ----------\n    embedding : np.ndarray, shape (n_samples, n_embedding_dims)\n        Low-dimensional embedding of the data. Each row corresponds to a sample,\n        and each column corresponds to an embedding dimension.\n    data : np.ndarray, shape (n_samples, n_features)\n        Original high-dimensional data. Each row is a sample, each column a feature.\n    geom : Geometry\n        An instance of the Geometry class (from geometry.py) that provides\n        methods for setting the data matrix and computing the Laplacian matrix.\n\n    Returns\n    -------\n    H : np.ndarray\n        Dual Riemannian metric tensor for each sample.\n    Hvv : np.ndarray\n        Singular vectors of the dual metric tensor for each sample.\n    Hs : np.ndarray\n        Singular values of the dual metric tensor for each sample.\n\n    Notes\n    -----\n    This function sets the data matrix in the provided Geometry object,\n    computes the Laplacian matrix, and then estimates the local Riemannian\n    metric distortions in the embedding space using the original data.\n    \"\"\"\n    geom.set_data_matrix(data)\n    L = geom.compute_laplacian_matrix()\n    _, _, Hvv, Hs, _, H = riemann_metric(embedding, L, n_dim=2)\n    return H, Hvv, Hs\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.neighborhoods","title":"<code>neighborhoods</code>","text":""},{"location":"reference/api.html#distortions.geometry.neighborhoods.boxplot_data","title":"<code>boxplot_data(x, y, nbin=10, outlier_iqr=3, **kwargs)</code>","text":"<p>Compute boxplot statistics and identify outliers within distance bins.</p> <p>This function divides the x-values (typically true distances) into bins and computes boxplot statistics for the y-values (typically embedding distances) within each bin. It identifies outliers using the IQR method.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array - like</code> <p>Input values used for binning (typically true/original distances).</p> required <code>y</code> <code>array - like</code> <p>Target values for which to compute statistics (typically embedding distances).</p> required <code>nbin</code> <code>int</code> <p>Number of bins to divide the x-value range into.</p> <code>10</code> <code>outlier_iqr</code> <code>float</code> <p>IQR multiplier for outlier detection. Values beyond Q1 - outlier_iqrIQR or Q3 + outlier_iqrIQR within each bin are considered outliers.</p> <code>3</code> <code>**kwargs</code> <code>keyword arguments</code> <p>Additional keyword arguments (currently unused).</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>summaries</code> <code>DataFrame</code> <p>DataFrame with boxplot statistics for each bin containing columns: - 'bin_id': bin identifier - 'q1', 'q2', 'q3': quartile values - 'min', 'max': minimum and maximum values - 'iqr': interquartile range - 'lower', 'upper': outlier detection bounds - 'bin': string representation of bin range</p> <code>outliers</code> <code>DataFrame</code> <p>DataFrame with outlier information containing columns: - 'index': original index of outlier point - 'bin_id': which bin the outlier belongs to - 'bin': string representation of bin range - 'value': the outlier y-value</p> Source code in <code>distortions/geometry/neighborhoods.py</code> <pre><code>def boxplot_data(x, y, nbin=10, outlier_iqr=3, **kwargs):\n    \"\"\"\n    Compute boxplot statistics and identify outliers within distance bins.\n\n    This function divides the x-values (typically true distances) into bins and\n    computes boxplot statistics for the y-values (typically embedding distances)\n    within each bin. It identifies outliers using the IQR method.\n\n    Parameters\n    ----------\n    x : array-like\n        Input values used for binning (typically true/original distances).\n    y : array-like\n        Target values for which to compute statistics (typically embedding distances).\n    nbin : int, default=10\n        Number of bins to divide the x-value range into.\n    outlier_iqr : float, default=3\n        IQR multiplier for outlier detection. Values beyond Q1 - outlier_iqr*IQR\n        or Q3 + outlier_iqr*IQR within each bin are considered outliers.\n    **kwargs : keyword arguments\n        Additional keyword arguments (currently unused).\n\n    Returns\n    -------\n    summaries : pd.DataFrame\n        DataFrame with boxplot statistics for each bin containing columns:\n        - 'bin_id': bin identifier\n        - 'q1', 'q2', 'q3': quartile values\n        - 'min', 'max': minimum and maximum values\n        - 'iqr': interquartile range\n        - 'lower', 'upper': outlier detection bounds\n        - 'bin': string representation of bin range\n    outliers : pd.DataFrame  \n        DataFrame with outlier information containing columns:\n        - 'index': original index of outlier point\n        - 'bin_id': which bin the outlier belongs to\n        - 'bin': string representation of bin range\n        - 'value': the outlier y-value\n    \"\"\"\n    # divide the data into nbin groups, and compute quantiles in each\n    bin_ids, bin_edges = pd.cut(x, bins=nbin, labels=False, retbins=True)\n    bin_edges = np.round(bin_edges, 1)\n\n    summaries = (\n        pd.DataFrame({'bin_id': bin_ids, 'y': y})\n        .groupby('bin_id', as_index=False)['y']\n        .agg(q1=lambda v: np.percentile(v, 25),\n             q2=lambda v: np.percentile(v, 50),\n             q3=lambda v: np.percentile(v, 75),\n             min='min', max='max')\n    )\n    summaries['iqr'] = summaries.q3 - summaries.q1\n    summaries['lower'] = np.maximum(summaries.q2 - outlier_iqr * summaries.iqr, summaries['min'])\n    summaries['upper'] = np.minimum(summaries.q2 + outlier_iqr * summaries.iqr, summaries['max'])\n    summaries['bin'] = summaries['bin_id'].map(lambda b: f\"{bin_edges[b]}-{bin_edges[b + 1]}\")\n\n    # compute outliers according to the IQR above\n    outliers = [\n        {\"index\": i, \"bin_id\": int(b), \"bin\": f\"{bin_edges[b]}-{bin_edges[b + 1]}\", \"value\": val}\n        for i, (b, val) in enumerate(zip(bin_ids, y))\n        if not np.isnan(b) and (\n            val &lt; summaries.loc[b, 'q1'] - outlier_iqr * summaries.loc[b, 'iqr'] or\n            val &gt; summaries.loc[b, 'q3'] + outlier_iqr * summaries.loc[b, 'iqr']\n        )\n    ]\n    return summaries, pd.DataFrame(outliers)\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.neighborhoods.broken_knn","title":"<code>broken_knn(embedding, k=2, z_thresh=1.0)</code>","text":"<p>Determine broken points in embedding space using k-NN distances and Z-score thresholding.</p> <p>This function identifies potentially problematic points in an embedding by computing their average k-nearest neighbor distances, calculating Z-scores, and flagging points that exceed the threshold as broken or isolated.</p> <p>Parameters:</p> Name Type Description Default <code>embedding</code> <code>(array - like, shape(n_samples, n_features))</code> <p>The embedding coordinates for all samples.</p> required <code>k</code> <code>int</code> <p>Number of nearest neighbors to consider for distance calculation.</p> <code>2</code> <code>z_thresh</code> <code>float</code> <p>Z-score threshold for identifying broken points. Points with Z-scores greater than or equal to this value are considered broken.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>list of int</code> <p>List of indices of broken points, sorted by descending Z-score. If no points exceed the threshold, returns the single point with the highest Z-score.</p> Source code in <code>distortions/geometry/neighborhoods.py</code> <pre><code>def broken_knn(embedding, k=2, z_thresh=1.0):\n    \"\"\"\n    Determine broken points in embedding space using k-NN distances and Z-score thresholding.\n\n    This function identifies potentially problematic points in an embedding by\n    computing their average k-nearest neighbor distances, calculating Z-scores,\n    and flagging points that exceed the threshold as broken or isolated.\n\n    Parameters\n    ----------\n    embedding : array-like, shape (n_samples, n_features)\n        The embedding coordinates for all samples.\n    k : int, default=2\n        Number of nearest neighbors to consider for distance calculation.\n    z_thresh : float, default=1.0\n        Z-score threshold for identifying broken points. Points with Z-scores\n        greater than or equal to this value are considered broken.\n\n    Returns\n    -------\n    list of int\n        List of indices of broken points, sorted by descending Z-score.\n        If no points exceed the threshold, returns the single point with\n        the highest Z-score.\n    \"\"\"\n    sub = embedding\n    nbr_sub = NearestNeighbors(n_neighbors=k).fit(sub)\n    d_sub, _ = nbr_sub.kneighbors(sub)\n    d1 = d_sub.mean(axis=1) \n\n    # 2) Z-score &amp; threshold\n    mu, sigma = d1.mean(), d1.std()\n    z = (d1 - mu) / sigma\n    locs = np.where(z &gt;= z_thresh)[0]\n    if len(locs)==0:\n        locs = [int(np.argmax(z))]\n\n    # 3) rank by descending Z-score\n    locs = sorted(locs, key=lambda i: z[i], reverse=True)\n    return locs\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.neighborhoods.identify_broken_box","title":"<code>identify_broken_box(dists, outlier_factor=3, nbin=10)</code>","text":"<p>Identify broken links using boxplot-based outlier detection within distance bins.</p> <p>This helper function bins the true distances and identifies outliers in the embedding distances within each bin using boxplot criteria.</p> <p>Parameters:</p> Name Type Description Default <code>dists</code> <code>DataFrame</code> <p>DataFrame with 'true' and 'embedding' distance columns.</p> required <code>outlier_factor</code> <code>float</code> <p>IQR multiplier for outlier detection threshold.</p> <code>3</code> <code>nbin</code> <code>int</code> <p>Number of bins to divide the true distance range into.</p> <code>10</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Copy of input distances DataFrame with additional 'brokenness' boolean column indicating which links are identified as broken outliers.</p> Source code in <code>distortions/geometry/neighborhoods.py</code> <pre><code>def identify_broken_box(dists, outlier_factor=3, nbin=10):\n    \"\"\"\n    Identify broken links using boxplot-based outlier detection within distance bins.\n\n    This helper function bins the true distances and identifies outliers in the\n    embedding distances within each bin using boxplot criteria.\n\n    Parameters\n    ----------\n    dists : pd.DataFrame\n        DataFrame with 'true' and 'embedding' distance columns.\n    outlier_factor : float, default=3\n        IQR multiplier for outlier detection threshold.\n    nbin : int, default=10\n        Number of bins to divide the true distance range into.\n\n    Returns\n    -------\n    pd.DataFrame\n        Copy of input distances DataFrame with additional 'brokenness' boolean column\n        indicating which links are identified as broken outliers.\n    \"\"\"\n    _, outliers = boxplot_data(dists[\"true\"], dists[\"embedding\"], nbin, outlier_factor)\n    brokenness = dists.copy()\n    brokenness = brokenness.reset_index()\n    brokenness[\"brokenness\"] = False\n    brokenness.loc[outliers[\"index\"].values, \"brokenness\"] = True\n    return brokenness\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.neighborhoods.identify_broken_window","title":"<code>identify_broken_window(dists, outlier_factor=3, percentiles=[75, 25], frame=[50, 50])</code>","text":"<p>Identify broken links using sliding window smoothing and residual analysis.</p> <p>This helper function applies a sliding window median filter to the distance relationship and identifies links where the embedding distance significantly exceeds the smoothed expectation.</p> <p>Parameters:</p> Name Type Description Default <code>dists</code> <code>DataFrame</code> <p>DataFrame with 'true' and 'embedding' distance columns.</p> required <code>outlier_factor</code> <code>float</code> <p>Multiplier for IQR-based outlier threshold in residual analysis.</p> <code>3</code> <code>percentiles</code> <code>list of float</code> <p>Percentiles used for IQR calculation.</p> <code>[75, 25]</code> <code>frame</code> <code>list of int</code> <p>Window frame size [before, after] for sliding median calculation.</p> <code>[50, 50]</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with original columns plus: - 'embedding_smooth': smoothed embedding distances - 'residual': difference between actual and smoothed embedding distances - 'brokenness': boolean indicating broken links</p> Source code in <code>distortions/geometry/neighborhoods.py</code> <pre><code>def identify_broken_window(dists, outlier_factor=3, percentiles=[75, 25], frame=[50, 50]):\n    \"\"\"\n    Identify broken links using sliding window smoothing and residual analysis.\n\n    This helper function applies a sliding window median filter to the distance\n    relationship and identifies links where the embedding distance significantly\n    exceeds the smoothed expectation.\n\n    Parameters\n    ----------\n    dists : pd.DataFrame\n        DataFrame with 'true' and 'embedding' distance columns.\n    outlier_factor : float, default=3\n        Multiplier for IQR-based outlier threshold in residual analysis.\n    percentiles : list of float, default=[75, 25]\n        Percentiles used for IQR calculation.\n    frame : list of int, default=[50, 50]\n        Window frame size [before, after] for sliding median calculation.\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame with original columns plus:\n        - 'embedding_smooth': smoothed embedding distances\n        - 'residual': difference between actual and smoothed embedding distances  \n        - 'brokenness': boolean indicating broken links\n    \"\"\"\n    line = alt.Chart(dists).transform_window(\n        embedding_smooth='median(embedding)',\n        sort=[alt.SortField('true')],\n        frame=frame\n    ).mark_line().encode(\n        x='true:Q',\n        y='embedding_smooth:Q'\n    )\n\n    result = extract_data(line).drop_duplicates()\n    result[\"residual\"] = result[\"embedding\"] - result[\"embedding_smooth\"]\n    result[\"brokenness\"] = result[\"residual\"] &gt; result[\"embedding_smooth\"] + \\\n        outlier_factor * iqr(result[\"residual\"], percentiles)\n    return result\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.neighborhoods.iqr","title":"<code>iqr(x, percentiles)</code>","text":"<p>Calculate the interquartile range between given percentiles.</p> <p>This function computes the difference between two percentiles of the input array, typically used to measure the spread of data.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array - like</code> <p>Input array for which to calculate the interquartile range.</p> required <code>percentiles</code> <code>array-like of length 2</code> <p>Two percentile values (e.g., [25, 75] for standard IQR). The function returns the difference between the higher and lower percentiles.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The interquartile range (difference between the specified percentiles).</p> Source code in <code>distortions/geometry/neighborhoods.py</code> <pre><code>def iqr(x, percentiles):\n    \"\"\"\n    Calculate the interquartile range between given percentiles.\n\n    This function computes the difference between two percentiles of the\n    input array, typically used to measure the spread of data.\n\n    Parameters\n    ----------\n    x : array-like\n        Input array for which to calculate the interquartile range.\n    percentiles : array-like of length 2\n        Two percentile values (e.g., [25, 75] for standard IQR).\n        The function returns the difference between the higher and lower percentiles.\n\n    Returns\n    -------\n    float\n        The interquartile range (difference between the specified percentiles).\n    \"\"\"\n    return np.subtract(*np.percentile(x, percentiles))\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.neighborhoods.neighbor_generator","title":"<code>neighbor_generator(embedding, broken_locations=[], number_neighbor=10)</code>","text":"<p>Generate neighbor lists for broken points in the embedding space.</p> <p>This function finds nearest neighbors for specified broken points (or automatically detected ones) in the embedding space. It's useful for understanding the local neighborhood structure around problematic points.</p> <p>Parameters:</p> Name Type Description Default <code>embedding</code> <code>(array - like, shape(n_samples, n_features))</code> <p>The embedding coordinates for all samples.</p> required <code>broken_locations</code> <code>list of int</code> <p>Indices of broken points for which to generate neighbors. If empty, automatically detects broken points using broken_knn().</p> <code>[]</code> <code>number_neighbor</code> <code>int</code> <p>Number of nearest neighbors to find for each broken point.</p> <code>10</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary mapping broken point indices (int) to lists of their  nearest neighbor indices, excluding the point itself.</p> Source code in <code>distortions/geometry/neighborhoods.py</code> <pre><code>def neighbor_generator(embedding, broken_locations = [], number_neighbor=10):\n    \"\"\"\n    Generate neighbor lists for broken points in the embedding space.\n\n    This function finds nearest neighbors for specified broken points (or\n    automatically detected ones) in the embedding space. It's useful for\n    understanding the local neighborhood structure around problematic points.\n\n    Parameters\n    ----------\n    embedding : array-like, shape (n_samples, n_features)\n        The embedding coordinates for all samples.\n    broken_locations : list of int, default=[]\n        Indices of broken points for which to generate neighbors. If empty,\n        automatically detects broken points using broken_knn().\n    number_neighbor : int, default=10\n        Number of nearest neighbors to find for each broken point.\n\n    Returns\n    -------\n    dict\n        Dictionary mapping broken point indices (int) to lists of their \n        nearest neighbor indices, excluding the point itself.\n    \"\"\"\n    if len(broken_locations) == 0:\n        broken_locations = broken_knn(embedding)\n    nbr_full = NearestNeighbors(n_neighbors=number_neighbor+1).fit(embedding)\n    isolated = {}\n    for idx in broken_locations:\n        _, neigh = nbr_full.kneighbors([embedding[idx]])\n        isolated[int(idx)] = neigh[0][1:].tolist()  # drop self\n    return isolated\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.neighborhoods.neighborhood_distances","title":"<code>neighborhood_distances(adata, embed_key='X_umap')</code>","text":"<p>Compute pairwise distances between samples and their neighbors in both original and embedding spaces.</p> <p>This function calculates pairwise distances between each sample and its neighbors in the original high-dimensional space and compares them with distances in the reduced embedding space. This is useful for analyzing how well the embedding preserves local neighborhood structure.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>Annotated data matrix. Must contain a precomputed embedding (e.g., UMAP or t-SNE) in <code>obsm[embed_key]</code> and a neighbor graph in <code>obsp[\"distances\"]</code>.</p> required <code>embed_key</code> <code>str</code> <p>Key in <code>adata.obsm</code> where the embedding coordinates are stored.</p> <code>\"X_umap\"</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with columns:     - 'center': index of the sample (cell)     - 'neighbor': index of the neighbor sample     - 'true': distance in the original space (from <code>adata.obsp[\"distances\"]</code>)     - 'embedding': distance in the embedding space (from <code>adata.obsm[embed_key]</code>)</p> Notes <p>The number of neighbors is determined by the structure of the neighbor graph in <code>adata.obsp[\"distances\"]</code>. The function assumes that the embedding and neighbor graph have already been computed.</p> Source code in <code>distortions/geometry/neighborhoods.py</code> <pre><code>def neighborhood_distances(adata, embed_key=\"X_umap\"):\n    \"\"\"\n    Compute pairwise distances between samples and their neighbors in both original and embedding spaces.\n\n    This function calculates pairwise distances between each sample and its\n    neighbors in the original high-dimensional space and compares them with\n    distances in the reduced embedding space. This is useful for analyzing\n    how well the embedding preserves local neighborhood structure.\n\n    Parameters\n    ----------\n    adata : anndata.AnnData\n        Annotated data matrix. Must contain a precomputed embedding (e.g., UMAP or t-SNE) in `obsm[embed_key]`\n        and a neighbor graph in `obsp[\"distances\"]`.\n    embed_key : str, default=\"X_umap\"\n        Key in `adata.obsm` where the embedding coordinates are stored.\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame with columns:\n            - 'center': index of the sample (cell)\n            - 'neighbor': index of the neighbor sample\n            - 'true': distance in the original space (from `adata.obsp[\"distances\"]`)\n            - 'embedding': distance in the embedding space (from `adata.obsm[embed_key]`)\n\n    Notes\n    -----\n    The number of neighbors is determined by the structure of the neighbor graph in `adata.obsp[\"distances\"]`.\n    The function assumes that the embedding and neighbor graph have already been computed.\n    \"\"\"\n    knn_graph = adata.obsp[\"distances\"]\n    dist_list = []\n\n    for ix in range(len(adata)):\n        neighbors = knn_graph[ix].nonzero()[1]\n        true = knn_graph[ix, neighbors].toarray().flatten()\n        embedding = cdist(\n            [adata.obsm[embed_key][ix, :]], \n            adata.obsm[embed_key][neighbors, :]\n        ).flatten()\n        dist_list.append(pd.DataFrame({\n            \"center\": [ix] * len(neighbors), \n            \"neighbor\": neighbors,\n            \"true\": true,\n            \"embedding\": embedding\n        }))\n\n    return pd.concat(dist_list)\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.neighborhoods.neighborhoods","title":"<code>neighborhoods(adata, outlier_factor=3, threshold=0.2, method='box', percentiles=[75, 25], frame=[50, 50], nbin=10, **kwargs)</code>","text":"<p>Identify broken neighborhoods in embeddings using different methods.</p> <p>This function serves as the main interface for detecting broken neighborhoods in dimensionality reduction embeddings. It supports multiple methods for identifying outliers and broken links between original and embedding spaces.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>Annotated data matrix with precomputed embedding and neighbor graph.</p> required <code>outlier_factor</code> <code>float</code> <p>Factor used to determine outlier threshold. Higher values are more permissive (fewer outliers detected).</p> <code>3</code> <code>threshold</code> <code>float</code> <p>Proportion threshold for flagging samples as having broken neighborhoods. Centers with more than this proportion of broken neighbors are flagged.</p> <code>0.2  </code> <code>method</code> <code>str</code> <p>Method for identifying broken neighborhoods. Options: - \"box\": Uses boxplot-based outlier detection - \"window\": Uses sliding window smoothing with residual analysis</p> <code>\"box\"</code> <code>percentiles</code> <code>list of float</code> <p>Percentiles used for IQR calculation in windowing method.</p> <code>[75, 25]</code> <code>frame</code> <code>list of int</code> <p>Window frame size [before, after] for sliding window smoothing.</p> <code>[50, 50]</code> <code>nbin</code> <code>int</code> <p>Number of bins for boxplot method.</p> <code>10</code> <code>**kwargs</code> <code>keyword arguments</code> <p>Additional arguments passed to neighborhood_distances().</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary mapping center indices to lists of their neighbor indices for samples with broken neighborhoods.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If an unsupported method is specified.</p> Source code in <code>distortions/geometry/neighborhoods.py</code> <pre><code>def neighborhoods(adata, outlier_factor=3, threshold=0.2, method=\"box\",\n                  percentiles=[75, 25], frame=[50, 50], nbin=10, **kwargs):\n    \"\"\"\n    Identify broken neighborhoods in embeddings using different methods.\n\n    This function serves as the main interface for detecting broken neighborhoods\n    in dimensionality reduction embeddings. It supports multiple methods for\n    identifying outliers and broken links between original and embedding spaces.\n\n    Parameters\n    ----------\n    adata : anndata.AnnData\n        Annotated data matrix with precomputed embedding and neighbor graph.\n    outlier_factor : float, default=3\n        Factor used to determine outlier threshold. Higher values are more\n        permissive (fewer outliers detected).\n    threshold : float, default=0.2  \n        Proportion threshold for flagging samples as having broken neighborhoods.\n        Centers with more than this proportion of broken neighbors are flagged.\n    method : str, default=\"box\"\n        Method for identifying broken neighborhoods. Options:\n        - \"box\": Uses boxplot-based outlier detection\n        - \"window\": Uses sliding window smoothing with residual analysis\n    percentiles : list of float, default=[75, 25]\n        Percentiles used for IQR calculation in windowing method.\n    frame : list of int, default=[50, 50]\n        Window frame size [before, after] for sliding window smoothing.\n    nbin : int, default=10\n        Number of bins for boxplot method.\n    **kwargs : keyword arguments\n        Additional arguments passed to neighborhood_distances().\n\n    Returns\n    -------\n    dict\n        Dictionary mapping center indices to lists of their neighbor indices\n        for samples with broken neighborhoods.\n\n    Raises\n    ------\n    NotImplementedError\n        If an unsupported method is specified.\n    \"\"\"\n    if method == \"box\":\n        return neighborhoods_box(adata, outlier_factor, threshold, nbin, **kwargs)\n    if method == \"window\":\n        return neighborhoods_window(adata, outlier_factor, threshold, percentiles, frame, **kwargs)\n    else:\n        return NotImplementedError(f\"Method {method} not implemented for broken neighborhood construction.\")\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.neighborhoods.neighborhoods_box","title":"<code>neighborhoods_box(adata, outlier_factor=3, threshold=0.2, nbin=10, **kwargs)</code>","text":"<p>Identify broken neighborhoods using boxplot-based outlier detection.</p> <p>This method bins the true distances and computes boxplot statistics within each bin. Links are considered broken if their embedding distance is an outlier relative to other links with similar true distances.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>Annotated data matrix with precomputed embedding and neighbor graph.</p> required <code>outlier_factor</code> <code>float</code> <p>IQR multiplier for boxplot outlier detection. Values beyond Q1 - outlier_factorIQR or Q3 + outlier_factorIQR are outliers.</p> <code>3</code> <code>threshold</code> <code>float</code> <p>Proportion threshold for flagging samples as having broken neighborhoods.</p> <code>0.2</code> <code>nbin</code> <code>int</code> <p>Number of bins to divide the true distance range into.</p> <code>10</code> <code>**kwargs</code> <code>keyword arguments</code> <p>Additional arguments passed to neighborhood_distances().</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary mapping center indices to lists of their neighbor indices for samples with broken neighborhoods.</p> Source code in <code>distortions/geometry/neighborhoods.py</code> <pre><code>def neighborhoods_box(adata, outlier_factor=3, threshold=0.2, nbin=10, **kwargs):\n    \"\"\"\n    Identify broken neighborhoods using boxplot-based outlier detection.\n\n    This method bins the true distances and computes boxplot statistics within\n    each bin. Links are considered broken if their embedding distance is an\n    outlier relative to other links with similar true distances.\n\n    Parameters\n    ----------\n    adata : anndata.AnnData\n        Annotated data matrix with precomputed embedding and neighbor graph.\n    outlier_factor : float, default=3\n        IQR multiplier for boxplot outlier detection. Values beyond\n        Q1 - outlier_factor*IQR or Q3 + outlier_factor*IQR are outliers.\n    threshold : float, default=0.2\n        Proportion threshold for flagging samples as having broken neighborhoods.\n    nbin : int, default=10\n        Number of bins to divide the true distance range into.\n    **kwargs : keyword arguments\n        Additional arguments passed to neighborhood_distances().\n\n    Returns\n    -------\n    dict\n        Dictionary mapping center indices to lists of their neighbor indices\n        for samples with broken neighborhoods.\n    \"\"\"\n    dists = neighborhood_distances(adata, **kwargs)\n    brokenness = identify_broken_box(dists, outlier_factor, nbin)\n    return threshold_links(dists, brokenness, threshold)\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.neighborhoods.neighborhoods_window","title":"<code>neighborhoods_window(adata, outlier_factor=3, threshold=0.2, percentiles=[75, 25], frame=[50, 50], **kwargs)</code>","text":"<p>Identify broken neighborhoods using window-based smoothing and residual analysis.</p> <p>This method applies a sliding window median filter to the distance relationships and identifies outliers based on residuals from the smoothed curve. Points with large positive residuals indicate broken neighborhoods where embedding distances are much larger than expected.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>Annotated data matrix with precomputed embedding and neighbor graph.</p> required <code>outlier_factor</code> <code>float</code> <p>Multiplier for IQR-based outlier threshold. Residuals greater than median + outlier_factor * IQR are considered broken.</p> <code>3</code> <code>threshold</code> <code>float</code> <p>Proportion threshold for flagging samples as having broken neighborhoods.</p> <code>0.2</code> <code>percentiles</code> <code>list of float</code> <p>Percentiles used for IQR calculation in residual analysis.</p> <code>[75, 25]</code> <code>frame</code> <code>list of int</code> <p>Window frame size [before, after] for sliding median calculation.</p> <code>[50, 50]</code> <code>**kwargs</code> <code>keyword arguments</code> <p>Additional arguments passed to neighborhood_distances().</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary mapping center indices to lists of their neighbor indices for samples with broken neighborhoods.</p> Source code in <code>distortions/geometry/neighborhoods.py</code> <pre><code>def neighborhoods_window(adata, outlier_factor=3, threshold=0.2, percentiles=[75, 25], frame=[50, 50], **kwargs):\n    \"\"\"\n    Identify broken neighborhoods using window-based smoothing and residual analysis.\n\n    This method applies a sliding window median filter to the distance relationships\n    and identifies outliers based on residuals from the smoothed curve. Points with\n    large positive residuals indicate broken neighborhoods where embedding distances\n    are much larger than expected.\n\n    Parameters\n    ----------\n    adata : anndata.AnnData\n        Annotated data matrix with precomputed embedding and neighbor graph.\n    outlier_factor : float, default=3\n        Multiplier for IQR-based outlier threshold. Residuals greater than\n        median + outlier_factor * IQR are considered broken.\n    threshold : float, default=0.2\n        Proportion threshold for flagging samples as having broken neighborhoods.\n    percentiles : list of float, default=[75, 25]\n        Percentiles used for IQR calculation in residual analysis.\n    frame : list of int, default=[50, 50]\n        Window frame size [before, after] for sliding median calculation.\n    **kwargs : keyword arguments\n        Additional arguments passed to neighborhood_distances().\n\n    Returns\n    -------\n    dict\n        Dictionary mapping center indices to lists of their neighbor indices\n        for samples with broken neighborhoods.\n    \"\"\"\n    dists = neighborhood_distances(adata, **kwargs)\n    brokenness = identify_broken_window(dists, outlier_factor, percentiles, frame)\n    return threshold_links(dists, brokenness, threshold)\n</code></pre>"},{"location":"reference/api.html#distortions.geometry.neighborhoods.threshold_links","title":"<code>threshold_links(dists, brokenness, threshold=0.2)</code>","text":"<p>Flag samples with high proportions of broken neighborhood links.</p> <p>This function identifies samples where the proportion of broken neighborhood links exceeds a specified threshold, indicating problematic embedding regions.</p> <p>Parameters:</p> Name Type Description Default <code>dists</code> <code>DataFrame</code> <p>DataFrame containing distance information with 'center' and 'neighbor' columns.</p> required <code>brokenness</code> <code>DataFrame</code> <p>DataFrame with 'center' and 'brokenness' columns indicating broken links.</p> required <code>threshold</code> <code>float</code> <p>Proportion threshold for flagging samples. Centers with more than this proportion of broken neighbors are included in the output.</p> <code>0.2</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary mapping center indices (int) to lists of their neighbor indices for samples exceeding the brokenness threshold.</p> Source code in <code>distortions/geometry/neighborhoods.py</code> <pre><code>def threshold_links(dists, brokenness, threshold=0.2):\n    \"\"\"\n    Flag samples with high proportions of broken neighborhood links.\n\n    This function identifies samples where the proportion of broken neighborhood\n    links exceeds a specified threshold, indicating problematic embedding regions.\n\n    Parameters\n    ----------\n    dists : pd.DataFrame\n        DataFrame containing distance information with 'center' and 'neighbor' columns.\n    brokenness : pd.DataFrame\n        DataFrame with 'center' and 'brokenness' columns indicating broken links.\n    threshold : float, default=0.2\n        Proportion threshold for flagging samples. Centers with more than this\n        proportion of broken neighbors are included in the output.\n\n    Returns\n    -------\n    dict\n        Dictionary mapping center indices (int) to lists of their neighbor indices\n        for samples exceeding the brokenness threshold.\n    \"\"\"\n    brokenness = brokenness.reset_index()\n    centers = brokenness.center.unique()\n    summary_dict = {}\n\n    for i in range(len(centers)):\n        subset = brokenness[brokenness[\"center\"] == centers[i]]\n        if np.mean(subset[\"brokenness\"]) &gt; threshold:\n            brokenness.loc[i, \"brokenness\"] = True\n            summary_dict[centers[i]] = [int(z) for z in dists[dists.center == centers[i]].neighbor.values]\n    return summary_dict\n</code></pre>"},{"location":"reference/api.html#distortionsvisualization","title":"<code>distortions.visualization</code>","text":""},{"location":"reference/api.html#distortions.visualization.dplot","title":"<code>dplot</code>","text":"<p>               Bases: <code>AnyWidget</code></p> <p>Interactive Distortion Plot Widget</p> <p>This class provides an interactive widget for visualizing distortion metrics computed on datasets, with a ggplot2-like syntax for adding graphical marks and overlaying distortion criteria. It is designed for use in Jupyter environments and leverages the anywidget and traitlets libraries for interactivity. You can pause mouseover interactivity by holding down the control key.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input dataset to visualize. Must be convertible to a list of records.</p> required <code>*args</code> <code>tuple</code> <p>Additional positional arguments passed to the parent AnyWidget.</p> <code>()</code> <code>**kwargs</code> <code>dict</code> <p>Additional keyword arguments passed to the parent AnyWidget and used as visualization options.</p> <code>{}</code> <p>Methods:</p> Name Description <code>mapping</code> <p>Specify the mapping from data columns to visual properties.</p> <code>geom_ellipse</code> <p>Add an ellipse layer to the plot.</p> <code>geom_hair</code> <p>Add a hair (small oriented lines) layer to the plot.</p> <code>labs</code> <p>Add labels to the plot.</p> <code>geom_edge_link</code> <p>Add edge link geometry to the plot.</p> <code>inter_edge_link</code> <p>Add interactive edge link geometry to the plot.</p> <code>inter_isometry</code> <p>Add interactive isometry overlays to the plot.</p> <code>scale_color</code> <p>Add a color scale to the plot.</p> <code>scale_size</code> <p>Add a size scale to the plot.</p> <code>inter_boxplot</code> <p>Add an interactive boxplot layer for distortion metrics, using provided distance summaries and outlier information.</p> <code>save</code> <p>Save the current view to SVG.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; df = pd.DataFrame({...})\n&gt;&gt;&gt; dplot(df).mapping(x='embedding_1', y='embedding_2').geom_ellipse()\n</code></pre> Source code in <code>distortions/visualization/interactive.py</code> <pre><code>class dplot(anywidget.AnyWidget):\n    \"\"\"\n    Interactive Distortion Plot Widget\n\n    This class provides an interactive widget for visualizing distortion metrics\n    computed on datasets, with a ggplot2-like syntax for adding graphical marks\n    and overlaying distortion criteria. It is designed for use in Jupyter\n    environments and leverages the anywidget and traitlets libraries for\n    interactivity. You can pause mouseover interactivity by holding down the\n    control key.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        The input dataset to visualize. Must be convertible to a list of records.\n    *args : tuple\n        Additional positional arguments passed to the parent AnyWidget.\n    **kwargs : dict\n        Additional keyword arguments passed to the parent AnyWidget and used as\n        visualization options.\n\n    Methods\n    -------\n    mapping(**kwargs)\n        Specify the mapping from data columns to visual properties.\n    geom_ellipse(**kwargs)\n        Add an ellipse layer to the plot.\n    geom_hair(**kwargs)\n        Add a hair (small oriented lines) layer to the plot.\n    labs(**kwargs)\n        Add labels to the plot.\n    geom_edge_link(**kwargs)\n        Add edge link geometry to the plot.\n    inter_edge_link(**kwargs)\n        Add interactive edge link geometry to the plot.\n    inter_isometry(**kwargs)\n        Add interactive isometry overlays to the plot.\n    scale_color(**kwargs)\n        Add a color scale to the plot.\n    scale_size(**kwargs)\n        Add a size scale to the plot.\n    inter_boxplot(dists, **kwargs)\n        Add an interactive boxplot layer for distortion metrics, using provided\n        distance summaries and outlier information.\n    save(filename)\n        Save the current view to SVG.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import pandas as pd\n    &gt;&gt;&gt; df = pd.DataFrame({...})\n    &gt;&gt;&gt; dplot(df).mapping(x='embedding_1', y='embedding_2').geom_ellipse()\n    \"\"\"\n    widget_dir = Path(__file__).parent / \"widget\"\n    _esm = widget_dir / \"render.js\"\n    _mapping = traitlets.Dict().tag(sync=True)\n    dataset = traitlets.List().tag(sync=True)\n    layers = traitlets.List().tag(sync=True)\n    neighbors = traitlets.List().tag(sync=True)\n    distance_summaries = traitlets.List().tag(sync=True)\n    outliers = traitlets.List().tag(sync=True)\n    options = traitlets.Dict().tag(sync=True)\n    elem_svg = traitlets.Unicode().tag(sync=True)\n\n    def __init__(self, df, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.dataset = df.to_dict(\"records\")\n        self.options = kwargs\n\n    def mapping(self, **kwargs):\n        \"\"\"\n        Specify the Mapping \n        \"\"\"\n        kwargs = {\"angle\": \"angle\", \"a\": \"s1\", \"b\": \"s0\", **kwargs}\n        self._mapping = kwargs\n        return self\n\n    def geom_ellipse(self, **kwargs):\n        self.layers = self.layers + [{\"type\": \"geom_ellipse\", \"options\": kwargs}]\n        return self\n\n    def geom_hair(self, **kwargs):\n        self.layers = self.layers + [{'type': 'geom_hair', 'options': kwargs}]\n        return self\n\n    def labs(self, **kwargs):\n        self.layers = self.layers + [{\"type\": \"labs\", \"options\": kwargs}]\n        return self\n\n    def geom_edge_link(self, **kwargs):\n        self.layers = self.layers + [{\"type\": \"geom_edge_link\", \"options\": kwargs}]\n        return self\n\n    def inter_edge_link(self, **kwargs):\n        self.layers = self.layers + [{\"type\": \"inter_edge_link\", \"options\": kwargs}]\n        return self\n\n    def inter_isometry(self, **kwargs):\n        self.layers = self.layers + [{\"type\": \"inter_isometry\", \"options\": kwargs}]\n        return self\n\n    def scale_color(self, **kwargs):\n        self.layers = self.layers + [{\"type\": \"scale_color\", \"options\": kwargs}]\n        return self\n\n    def scale_size(self, **kwargs):\n        self.layers = self.layers + [{\"type\": \"scale_size\", \"options\": kwargs}]\n        return self\n\n    def inter_boxplot(self, dists, **kwargs):\n        summaries, outliers = boxplot_data(dists[\"true\"], dists[\"embedding\"], **kwargs)\n        outliers[\"center\"] = dists.center.values[outliers[\"index\"].values]\n        outliers[\"neighbor\"] = dists.neighbor.values[outliers[\"index\"].values]\n\n        # pass the related data to the visualization\n        self.layers = self.layers + [{\"type\": \"inter_boxplot\", \"options\": kwargs}]\n        self.distance_summaries = summaries.to_dict(\"records\")\n        self.outliers = outliers.to_dict(\"records\")\n        return self\n\n    def save(self, filename=\"plot.svg\"):\n        self.send({\"type\": \"save\"})\n        with open(filename, \"w\") as f:\n            f.write(self.elem_svg)\n        f.close()\n</code></pre>"},{"location":"reference/api.html#distortions.visualization.dplot.mapping","title":"<code>mapping(**kwargs)</code>","text":"<p>Specify the Mapping</p> Source code in <code>distortions/visualization/interactive.py</code> <pre><code>def mapping(self, **kwargs):\n    \"\"\"\n    Specify the Mapping \n    \"\"\"\n    kwargs = {\"angle\": \"angle\", \"a\": \"s1\", \"b\": \"s0\", **kwargs}\n    self._mapping = kwargs\n    return self\n</code></pre>"},{"location":"reference/api.html#distortions.visualization.scanpy_umap","title":"<code>scanpy_umap(adata, max_cells=200, n_neighbors=10, n_pcs=40)</code>","text":"<p>Runs UMAP visualization on an AnnData object with basic preprocessing.</p> <p>This wrapper function filters genes by minimum count, applies log transformation, selects highly variable genes, computes neighbors in PCA space, and runs UMAP.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>AnnData experiment object containing the data to filter, transform, and apply UMAP to.</p> required <code>max_cells</code> <code>int, optional (default: 200)</code> <p>Maximum number of cells to use for visualization.</p> <code>200</code> <code>n_neighbors</code> <code>int, optional (default: 10)</code> <p>Number of neighbors to use for constructing the neighborhood graph.</p> <code>10</code> <code>n_pcs</code> <code>int, optional (default: 40)</code> <p>Number of principal components to use for neighborhood graph construction.</p> <code>40</code> <p>Returns:</p> Name Type Description <code>adata</code> <code>AnnData</code> <p>The AnnData object after preprocessing and UMAP computation.</p> Notes <p>The function modifies the input AnnData object in place.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scanpy as sc\n&gt;&gt;&gt; from distortion.visualization import scanpy_umap\n&gt;&gt;&gt; adata = sc.datasets.pbmc3k()\n&gt;&gt;&gt; adata_umap = scanpy_umap(adata, max_cells=100, n_neighbors=15, n_pcs=30)\n&gt;&gt;&gt; sc.pl.umap(adata_umap)\n</code></pre> Source code in <code>distortions/visualization/umap.py</code> <pre><code>def scanpy_umap(adata, max_cells=200, n_neighbors=10, n_pcs=40):\n    \"\"\"\n    Runs UMAP visualization on an AnnData object with basic preprocessing.\n\n    This wrapper function filters genes by minimum count, applies log\n    transformation, selects highly variable genes, computes neighbors in PCA\n    space, and runs UMAP.\n\n    Parameters\n    ----------\n    adata : anndata.AnnData\n        AnnData experiment object containing the data to filter, transform, and\n        apply UMAP to.\n    max_cells : int, optional (default: 200)\n        Maximum number of cells to use for visualization.\n    n_neighbors : int, optional (default: 10)\n        Number of neighbors to use for constructing the neighborhood graph.\n    n_pcs : int, optional (default: 40)\n        Number of principal components to use for neighborhood graph construction.\n\n    Returns\n    -------\n    adata : anndata.AnnData\n        The AnnData object after preprocessing and UMAP computation.\n\n    Notes\n    -----\n    The function modifies the input AnnData object in place.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import scanpy as sc\n    &gt;&gt;&gt; from distortion.visualization import scanpy_umap\n    &gt;&gt;&gt; adata = sc.datasets.pbmc3k()\n    &gt;&gt;&gt; adata_umap = scanpy_umap(adata, max_cells=100, n_neighbors=15, n_pcs=30)\n    &gt;&gt;&gt; sc.pl.umap(adata_umap)\n    \"\"\"\n    adata = adata[:max_cells, :]\n\n    # Preprocess the dataset\n    sc.pp.filter_genes(adata, min_counts=1)\n    sc.pp.log1p(adata)\n    sc.pp.highly_variable_genes(adata, min_mean=0.5, min_disp=0.5)\n    adata = adata[:, adata.var.highly_variable]\n\n    # Run UMAP\n    sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=n_pcs)\n    sc.tl.umap(adata)\n    return adata\n</code></pre>"},{"location":"tutorials/c_elegans.html","title":"C elegans","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom distortions.geometry import neighborhoods, Geometry, local_distortions, bind_metric\nfrom distortions.visualization import dplot\nimport numpy as np\nimport scanpy as sc\nimport altair as alt\n</pre> import numpy as np import pandas as pd import matplotlib.pyplot as plt from distortions.geometry import neighborhoods, Geometry, local_distortions, bind_metric from distortions.visualization import dplot import numpy as np import scanpy as sc import altair as alt In\u00a0[2]: Copied! <pre># Read data directly from GitHub\ndata_url = \"https://raw.githubusercontent.com/krisrs1128/distortions-data/main/data/c-elegans_qc_final.txt\"\nmetadata_url = \"https://raw.githubusercontent.com/krisrs1128/distortions-data/main/data/c-elegans_qc_final_metadata.txt\"\n\ndata = np.loadtxt(data_url, delimiter=\"\\t\")\nmetadata = pd.read_csv(metadata_url, sep=\",\")\n\nprint(\"Data shape:\", data.shape)\nprint(\"Metadata shape:\", metadata.shape)\n</pre> # Read data directly from GitHub data_url = \"https://raw.githubusercontent.com/krisrs1128/distortions-data/main/data/c-elegans_qc_final.txt\" metadata_url = \"https://raw.githubusercontent.com/krisrs1128/distortions-data/main/data/c-elegans_qc_final_metadata.txt\"  data = np.loadtxt(data_url, delimiter=\"\\t\") metadata = pd.read_csv(metadata_url, sep=\",\")  print(\"Data shape:\", data.shape) print(\"Metadata shape:\", metadata.shape) <pre>Data shape: (86024, 100)\nMetadata shape: (86024, 15)\n</pre> In\u00a0[3]: Copied! <pre># chech min max value of data\nprint(\"Data min value:\", np.min(data))\nprint(\"Data max value:\", np.max(data))\n</pre> # chech min max value of data print(\"Data min value:\", np.min(data)) print(\"Data max value:\", np.max(data)) <pre>Data min value: -20.558958\nData max value: 26.90514\n</pre> In\u00a0[4]: Copied! <pre>metadata\n</pre> metadata Out[4]: Unnamed: 0 cell n.umi time.point batch Size_Factor cell.type cell.subtype plot.cell.type raw.embryo.time embryo.time embryo.time.bin raw.embryo.time.bin lineage passed_initial_QC_or_later_whitelisted 0 AAACCTGAGACAATAC-300.1.1 AAACCTGAGACAATAC-300.1.1 1630 300_minutes Waterston_300_minutes 1.023195 Body_wall_muscle BWM_head_row_1 BWM_head_row_1 360 380.0 330-390 330-390 MSxpappp True 1 AAACCTGAGGGCTCTC-300.1.1 AAACCTGAGGGCTCTC-300.1.1 2319 300_minutes Waterston_300_minutes 1.458210 NaN NaN NaN 260 220.0 210-270 210-270 MSxapaap True 2 AAACCTGAGTGCGTGA-300.1.1 AAACCTGAGTGCGTGA-300.1.1 3719 300_minutes Waterston_300_minutes 2.338283 NaN NaN NaN 270 230.0 210-270 270-330 NaN True 3 AAACCTGAGTTGAGTA-300.1.1 AAACCTGAGTTGAGTA-300.1.1 4251 300_minutes Waterston_300_minutes 2.659051 Body_wall_muscle BWM_anterior BWM_anterior 260 280.0 270-330 210-270 Dxap True 4 AAACCTGCAAGACGTG-300.1.1 AAACCTGCAAGACGTG-300.1.1 1003 300_minutes Waterston_300_minutes 0.629610 Ciliated_amphid_neuron AFD AFD 350 350.0 330-390 330-390 ABalpppapav/ABpraaaapav True ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 86019 TCTGAGACATGTCGAT-b02 TCTGAGACATGTCGAT-b02 585 mixed Murray_b02 0.364709 Rectal_gland Rectal_gland Rectal_gland 390 700.0 &gt; 650 390-450 NaN True 86020 TCTGAGACATGTCTCC-b02 TCTGAGACATGTCTCC-b02 510 mixed Murray_b02 0.323907 NaN NaN NaN 510 470.0 450-510 510-580 NaN True 86021 TGGCCAGCACGAAGCA-b02 TGGCCAGCACGAAGCA-b02 843 mixed Murray_b02 0.529174 NaN NaN NaN 400 470.0 450-510 390-450 NaN True 86022 TGGCGCACAGGCAGTA-b02 TGGCGCACAGGCAGTA-b02 636 mixed Murray_b02 0.397979 NaN NaN NaN 330 350.0 330-390 330-390 NaN True 86023 TGGGCGTTCAGGCCCA-b02 TGGGCGTTCAGGCCCA-b02 1132 mixed Murray_b02 0.706820 NaN NaN NaN 260 265.0 210-270 210-270 NaN True <p>86024 rows \u00d7 15 columns</p> In\u00a0[5]: Copied! <pre>colors = pd.Categorical(metadata['cell.type']).codes\nlabel_pick = [24, 14, 2, 34]\nfrom collections import defaultdict\n\ndef sampling(source, num_sample, label_pick):    \n    class_indices = defaultdict(list)\n    for idx, label in enumerate(source):\n        class_indices[label].append(idx)\n\n    # Randomly sample points from each class\n    rng = np.random.default_rng(seed=42)  # Set a seed for reproducibility\n    sampled_indices = []\n    for label, indices in class_indices.items():\n        if label in label_pick:\n            n_class_samples = min(len(indices), num_sample)  # Equal sampling\n            sampled_indices.extend(rng.choice(indices, n_class_samples, replace=False))\n    return sampled_indices\n\nsampled_indices = sampling(colors, 1000, label_pick)\n</pre> colors = pd.Categorical(metadata['cell.type']).codes label_pick = [24, 14, 2, 34] from collections import defaultdict  def sampling(source, num_sample, label_pick):         class_indices = defaultdict(list)     for idx, label in enumerate(source):         class_indices[label].append(idx)      # Randomly sample points from each class     rng = np.random.default_rng(seed=42)  # Set a seed for reproducibility     sampled_indices = []     for label, indices in class_indices.items():         if label in label_pick:             n_class_samples = min(len(indices), num_sample)  # Equal sampling             sampled_indices.extend(rng.choice(indices, n_class_samples, replace=False))     return sampled_indices  sampled_indices = sampling(colors, 1000, label_pick) In\u00a0[6]: Copied! <pre>from scipy.spatial import KDTree\nimport os\n\ncache_file = \"data/c_elegans_distances.npy\"\nif os.path.exists(cache_file):\n    dists = np.load(cache_file)\nelse:\n    tree = KDTree(data)\n    dists, _ = tree.query(data, k=3)\n    os.makedirs(\"data\", exist_ok=True)\n    np.save(cache_file, dists)\n</pre> from scipy.spatial import KDTree import os  cache_file = \"data/c_elegans_distances.npy\" if os.path.exists(cache_file):     dists = np.load(cache_file) else:     tree = KDTree(data)     dists, _ = tree.query(data, k=3)     os.makedirs(\"data\", exist_ok=True)     np.save(cache_file, dists) In\u00a0[7]: Copied! <pre>n_neighbors = 10\nradius = 3 * np.mean(dists)\ngeom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": 5})\n</pre> n_neighbors = 10 radius = 3 * np.mean(dists) geom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": 5}) In\u00a0[8]: Copied! <pre># set random seed for reproducibility\nnp.random.seed(42)\nimport umap\nembedding_dumap = umap.UMAP(n_neighbors=10, n_components=2, n_epochs=500, densmap = True).fit_transform(data)\nembedding_umap = umap.UMAP(n_neighbors=10, n_components=2, n_epochs=500, densmap = False).fit_transform(data)\n</pre> # set random seed for reproducibility np.random.seed(42) import umap embedding_dumap = umap.UMAP(n_neighbors=10, n_components=2, n_epochs=500, densmap = True).fit_transform(data) embedding_umap = umap.UMAP(n_neighbors=10, n_components=2, n_epochs=500, densmap = False).fit_transform(data) In\u00a0[9]: Copied! <pre>plt.figure(figsize=(8, 6))\nfig_umpa =plt.scatter(embedding_umap[:, 0], embedding_umap[:, 1], \n            c=pd.Categorical(metadata['cell.type']).codes, cmap='viridis', s=1)\nplt.colorbar(fig_umpa, label='Cell Type')\nplt.title(\"UMAP Embedding of C.elegans Dataset\")\nplt.xlabel(\"Dimension 1\")\nplt.ylabel(\"Dimension 2\")\nplt.show()\n</pre> plt.figure(figsize=(8, 6)) fig_umpa =plt.scatter(embedding_umap[:, 0], embedding_umap[:, 1],              c=pd.Categorical(metadata['cell.type']).codes, cmap='viridis', s=1) plt.colorbar(fig_umpa, label='Cell Type') plt.title(\"UMAP Embedding of C.elegans Dataset\") plt.xlabel(\"Dimension 1\") plt.ylabel(\"Dimension 2\") plt.show() In\u00a0[10]: Copied! <pre>plt.figure(figsize=(8, 6))\nfig_umpa =plt.scatter(embedding_dumap[:, 0], embedding_dumap[:, 1], \n            c=pd.Categorical(metadata['cell.type']).codes, cmap='viridis', s=1)\nplt.colorbar(fig_umpa, label='Cell Type')\nplt.title(\"DenseUMAP Embedding of C.elegans Dataset\")\nplt.xlabel(\"Dimension 1\")\nplt.ylabel(\"Dimension 2\")\nplt.show()\n</pre> plt.figure(figsize=(8, 6)) fig_umpa =plt.scatter(embedding_dumap[:, 0], embedding_dumap[:, 1],              c=pd.Categorical(metadata['cell.type']).codes, cmap='viridis', s=1) plt.colorbar(fig_umpa, label='Cell Type') plt.title(\"DenseUMAP Embedding of C.elegans Dataset\") plt.xlabel(\"Dimension 1\") plt.ylabel(\"Dimension 2\") plt.show() In\u00a0[11]: Copied! <pre># transfer a numpy data to anndata\nimport anndata as ad\nadata = ad.AnnData(X=data[sampled_indices])\nadata.X.shape\nadata.obsm[\"X_UMAP\"] = embedding_umap[sampled_indices]\nadata.obsm[\"X_DenseUMAP\"] = embedding_dumap[sampled_indices]\nadata.obs[\"cell_type\"] = metadata['cell.type'].values[sampled_indices]\nsc.pp.neighbors(adata, n_neighbors=50, n_pcs=40, method='gauss')\n</pre> # transfer a numpy data to anndata import anndata as ad adata = ad.AnnData(X=data[sampled_indices]) adata.X.shape adata.obsm[\"X_UMAP\"] = embedding_umap[sampled_indices] adata.obsm[\"X_DenseUMAP\"] = embedding_dumap[sampled_indices] adata.obs[\"cell_type\"] = metadata['cell.type'].values[sampled_indices] sc.pp.neighbors(adata, n_neighbors=50, n_pcs=40, method='gauss') In\u00a0[12]: Copied! <pre>umap_embed_test = adata.obsm[\"X_UMAP\"].copy()\ngeom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": radius})\nH, Hvv, Hs = local_distortions(umap_embed_test, adata.X, geom)\numap_embed_test = bind_metric(umap_embed_test, Hvv, Hs)\numap_embed_test[\"cell_type\"] = adata.obs[\"cell_type\"].values\n</pre> umap_embed_test = adata.obsm[\"X_UMAP\"].copy() geom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": radius}) H, Hvv, Hs = local_distortions(umap_embed_test, adata.X, geom) umap_embed_test = bind_metric(umap_embed_test, Hvv, Hs) umap_embed_test[\"cell_type\"] = adata.obs[\"cell_type\"].values In\u00a0[13]: Copied! <pre>N = neighborhoods(adata, threshold=.2, outlier_factor=2, method=\"box\", embed_key=\"X_UMAP\")\ndplot(umap_embed_test, width=600, height=500)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\\n    .geom_ellipse(radiusMax=8, radiusMin=2)\\\n    .scale_color(legendTextSize=8)\\\n    .labs(x=\"UMAP 1\", y=\"UMAP 2\")\\\n    .inter_edge_link(N=N, threshold=1, backgroundOpacity=0.4, strokeWidth=0.1, strokeOpacity=1, highlightStrokeWidth=0.1)\n</pre> N = neighborhoods(adata, threshold=.2, outlier_factor=2, method=\"box\", embed_key=\"X_UMAP\") dplot(umap_embed_test, width=600, height=500)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\     .geom_ellipse(radiusMax=8, radiusMin=2)\\     .scale_color(legendTextSize=8)\\     .labs(x=\"UMAP 1\", y=\"UMAP 2\")\\     .inter_edge_link(N=N, threshold=1, backgroundOpacity=0.4, strokeWidth=0.1, strokeOpacity=1, highlightStrokeWidth=0.1) Out[13]: <pre>dplot(dataset=[{'embedding_0': 10.636955261230469, 'embedding_1': 18.214107513427734, 'x0': -0.998865286620071\u2026</pre> In\u00a0[14]: Copied! <pre>from distortions.geometry import Geometry, bind_metric, local_distortions\ndumap_embed_test = adata.obsm[\"X_DenseUMAP\"].copy()\ngeom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": radius})\nH, Hvv, Hs = local_distortions(dumap_embed_test, adata.X, geom)\ndumap_embed_test = bind_metric(dumap_embed_test, Hvv, Hs)\ndumap_embed_test[\"cell_type\"] = adata.obs[\"cell_type\"].values\n</pre> from distortions.geometry import Geometry, bind_metric, local_distortions dumap_embed_test = adata.obsm[\"X_DenseUMAP\"].copy() geom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": radius}) H, Hvv, Hs = local_distortions(dumap_embed_test, adata.X, geom) dumap_embed_test = bind_metric(dumap_embed_test, Hvv, Hs) dumap_embed_test[\"cell_type\"] = adata.obs[\"cell_type\"].values In\u00a0[15]: Copied! <pre>N = neighborhoods(adata, threshold=.02, outlier_factor=2, method=\"box\", embed_key=\"X_UMAP\")\ndplot(dumap_embed_test, width=600, height=500)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\\n    .geom_ellipse()\\\n    .scale_color(legendTextSize=8)\\\n    .labs(x=\"DenseUMAP 1\", y=\"DenseUMAP 2\")\\\n    .inter_edge_link(N=N, threshold=1, backgroundOpacity=0.4, strokeWidth=0.1, strokeOpacity=1, highlightStrokeWidth=0.1)\n</pre> N = neighborhoods(adata, threshold=.02, outlier_factor=2, method=\"box\", embed_key=\"X_UMAP\") dplot(dumap_embed_test, width=600, height=500)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\     .geom_ellipse()\\     .scale_color(legendTextSize=8)\\     .labs(x=\"DenseUMAP 1\", y=\"DenseUMAP 2\")\\     .inter_edge_link(N=N, threshold=1, backgroundOpacity=0.4, strokeWidth=0.1, strokeOpacity=1, highlightStrokeWidth=0.1) Out[15]: <pre>dplot(dataset=[{'embedding_0': 9.927645683288574, 'embedding_1': -8.331454277038574, 'x0': -0.968463598100212,\u2026</pre> In\u00a0[16]: Copied! <pre>from distortions.geometry.neighborhoods import broken_knn, neighbor_generator\n\nbrokens = broken_knn(adata.obsm['X_UMAP'], k=5, z_thresh=2.0) # after I found the broken points\nbroken_neighbors = neighbor_generator(embedding_umap, [sampled_indices[i] for i in brokens], number_neighbor=10) # generate neighbor dict\nbroken_neighbors\n</pre> from distortions.geometry.neighborhoods import broken_knn, neighbor_generator  brokens = broken_knn(adata.obsm['X_UMAP'], k=5, z_thresh=2.0) # after I found the broken points broken_neighbors = neighbor_generator(embedding_umap, [sampled_indices[i] for i in brokens], number_neighbor=10) # generate neighbor dict broken_neighbors Out[16]: <pre>{73596: [4790, 20777, 20592, 34552, 69932, 20679, 11239, 23261, 12437, 20814],\n 57113: [50740, 56052, 55824, 53409, 55883, 56289, 56291, 58650, 48031, 44480],\n 69022: [76169, 59019, 84128, 43318, 42690, 83836, 82810, 67851, 31736, 83955],\n 79172: [46841, 66448, 33095, 48760, 47431, 41317, 73999, 49526, 63919, 50035],\n 71449: [32523, 47674, 65961, 60491, 62498, 13213, 75565, 71256, 76123, 49298],\n 59924: [21397, 39275, 57965, 63187, 24867, 59895, 10637, 24850, 68423, 67306],\n 64777: [13451, 23890, 6839, 32386, 18627, 17142, 19383, 23016, 31263, 5605],\n 80834: [77493, 68701, 85706, 80412, 85578, 85757, 85647, 68668, 85769, 85826],\n 70453: [817, 12541, 14284, 76336, 74305, 77080, 60713, 10751, 18440, 30693],\n 75236: [60542, 780, 10798, 22846, 30778, 27245, 26109, 2079, 76429, 30503],\n 68059: [62136, 66227, 70784, 62867, 78662, 72500, 64976, 66587, 70216, 63369],\n 62722: [62919, 65028, 62264, 62429, 62725, 77038, 80216, 61650, 70985, 62765],\n 61274: [65389, 68249, 65212, 70852, 65520, 65929, 71376, 63263, 75422, 64530],\n 54434: [54452, 59624, 57734, 67078, 51405, 51788, 41012, 55406, 50642, 51476],\n 81224: [43411, 80382, 41434, 66496, 60493, 42547, 40668, 33337, 31214, 79213],\n 72548: [30281, 37517, 4071, 36882, 25586, 79841, 7270, 14822, 19600, 23459],\n 64462: [72286, 18027, 9620, 62778, 74971, 80563, 79574, 24270, 76387, 15590],\n 78572: [77789, 69839, 78682, 69485, 71745, 79708, 65289, 79919, 75196, 77081],\n 32915: [67948, 17569, 27162, 61772, 29359, 78800, 24149, 73089, 38308, 77084],\n 72859: [18201, 63522, 80704, 25442, 78030, 35822, 25783, 80231, 61824, 64988],\n 75329: [64910, 62824, 63635, 60728, 60266, 65678, 65752, 7076, 75507, 32825],\n 13328: [79350, 14794, 12242, 3528, 3579, 28892, 3655, 15647, 26497, 60221],\n 59885: [62142, 62070, 21349, 66732, 74762, 61905, 61021, 66813, 72615, 74571],\n 71544: [9482, 67430, 14829, 85203, 32300, 11964, 80717, 9425, 70786, 12299],\n 64060: [75138, 85225, 79396, 81013, 2299, 63488, 69758, 75708, 85181, 64141],\n 65681: [62377, 14271, 7136, 38293, 31445, 30540, 35841, 65222, 18700, 84092],\n 21151: [21898, 32850, 13110, 22928, 37913, 11545, 17491, 33502, 25790, 37304],\n 61956: [67857, 62743, 62504, 63670, 67164, 63158, 65257, 60869, 66944, 67460],\n 51939: [54478, 82165, 55961, 50304, 33504, 33874, 46396, 58382, 85949, 82158],\n 62072: [64364, 57730, 25338, 85917, 3037, 74562, 5911, 69672, 84346, 69700],\n 61514: [19833, 5356, 13988, 12722, 549, 8994, 15227, 12061, 11214, 71167],\n 78750: [56809, 53204, 58925, 52371, 53237, 50984, 56514, 54917, 53245, 55661],\n 44731: [51310, 58514, 84572, 40800, 45632, 56277, 79822, 43679, 62424, 51440],\n 45632: [58514, 44731, 43679, 40800, 51310, 56175, 56277, 79822, 53690, 84572],\n 74330: [73666, 60525, 62212, 34669, 62369, 10163, 22708, 61714, 75011, 78672],\n 6103: [43628, 4684, 50250, 42477, 32988, 17920, 42361, 64720, 19974, 37688],\n 74828: [72991, 79126, 14034, 71809, 3231, 9173, 12561, 70728, 62141, 79676],\n 28570: [60538, 42853, 60885, 60563, 24165, 42998, 72802, 72797, 56538, 45947],\n 44472: [49038, 54279, 75080, 26101, 34729, 19974, 50250, 21345, 49189, 43628],\n 79234: [67770, 52229, 40637, 55303, 60828, 46416, 82074, 79301, 50618, 43367],\n 63889: [20498, 77774, 9507, 67266, 74794, 65987, 36366, 33775, 68988, 6722],\n 55779: [50622, 58149, 70480, 59466, 58632, 53769, 73354, 63322, 59215, 53612],\n 53740: [71478, 35405, 31321, 53155, 51846, 50003, 53349, 57492, 52219, 59215],\n 48210: [49955, 3056, 32087, 249, 50083, 79017, 18936, 28037, 68299, 72254],\n 62904: [45602, 68470, 48204, 45092, 78559, 50053, 40368, 53349, 50003, 53155],\n 68470: [45602, 62904, 48204, 45092, 78559, 50053, 40368, 53349, 50003, 53155],\n 71955: [84994, 85054, 84975, 85049, 84962, 85041, 85069, 85045, 84963, 84966],\n 62089: [25753, 29380, 51184, 18178, 212, 73313, 37591, 19811, 19977, 21360],\n 57162: [25609, 57668, 83625, 21750, 39333, 20135, 50368, 33283, 26782, 33472],\n 78782: [65457, 57521, 59599, 53334, 57800, 54664, 54333, 41282, 53011, 55212],\n 43377: [21190, 3137, 21027, 71653, 49749, 21899, 10292, 29266, 12141, 28663],\n 61651: [65913, 42914, 64730, 65722, 60336, 28361, 66822, 61437, 65843, 60497]}</pre> In\u00a0[17]: Copied! <pre>#broken_neighbors[52388]\nbroken_neighbors[57113]\n</pre> #broken_neighbors[52388] broken_neighbors[57113] Out[17]: <pre>[50740, 56052, 55824, 53409, 55883, 56289, 56291, 58650, 48031, 44480]</pre> In\u00a0[18]: Copied! <pre>#point = 52388\npoint = 57113\nadata_add = ad.AnnData(X=data[sampled_indices+ broken_neighbors[point]])\nadata_add.obsm[\"X_DUMAP\"] = embedding_umap[sampled_indices + broken_neighbors[point]]\n</pre> #point = 52388 point = 57113 adata_add = ad.AnnData(X=data[sampled_indices+ broken_neighbors[point]]) adata_add.obsm[\"X_DUMAP\"] = embedding_umap[sampled_indices + broken_neighbors[point]] In\u00a0[19]: Copied! <pre>from distortions.visualization import dplot\ngeom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": radius})\nH, Hvv, Hs = local_distortions(adata.obsm['X_DenseUMAP'], adata.X, geom)\nembedding_test_1 = bind_metric(embedding_umap[sampled_indices], Hvv, Hs)\nembedding_test_1[\"cell_type\"] = pd.Categorical(metadata['cell.type'])[sampled_indices]\nmetrics = {k: H[k] for k in range(len(H))}\ndplot(embedding_test_1, width=900, height=500)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", angle=\"angle\", a=\"s0\", b=\"s1\", color=\"cell_type\")\\\n    .geom_ellipse()\\\n    .inter_isometry(metrics=metrics, metric_bw=3, transformation_bw=1)\\\n    .scale_color()\\\n    .labs(x=\"x-axis\", y=\"y-axis\")\n</pre> from distortions.visualization import dplot geom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": radius}) H, Hvv, Hs = local_distortions(adata.obsm['X_DenseUMAP'], adata.X, geom) embedding_test_1 = bind_metric(embedding_umap[sampled_indices], Hvv, Hs) embedding_test_1[\"cell_type\"] = pd.Categorical(metadata['cell.type'])[sampled_indices] metrics = {k: H[k] for k in range(len(H))} dplot(embedding_test_1, width=900, height=500)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", angle=\"angle\", a=\"s0\", b=\"s1\", color=\"cell_type\")\\     .geom_ellipse()\\     .inter_isometry(metrics=metrics, metric_bw=3, transformation_bw=1)\\     .scale_color()\\     .labs(x=\"x-axis\", y=\"y-axis\") Out[19]: <pre>dplot(dataset=[{'embedding_0': 10.636955261230469, 'embedding_1': 18.214107513427734, 'x0': -0.968463598100212\u2026</pre> In\u00a0[20]: Copied! <pre>geom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": 5})\nH, Hvv, Hs = local_distortions(adata_add.obsm[\"X_DUMAP\"], adata_add.X, geom)\nembedding_test_2 = bind_metric(embedding_dumap[sampled_indices + broken_neighbors[point]], Hvv, Hs)\nembedding_test_2[\"cell_type\"] = pd.Categorical(metadata['cell.type'])[sampled_indices + broken_neighbors[point]]\nmetrics = {k: H[k] for k in range(len(H))}\ndplot(embedding_test_2, width=900, height=500)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", angle=\"angle\", a=\"s0\", b=\"s1\", color=\"cell_type\")\\\n    .geom_ellipse()\\\n    .inter_isometry(metrics=metrics, metric_bw=3, transformation_bw=1)\\\n    .scale_color()\\\n    .labs(x=\"x-axis\", y=\"y-axis\")\n</pre> geom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": 5}) H, Hvv, Hs = local_distortions(adata_add.obsm[\"X_DUMAP\"], adata_add.X, geom) embedding_test_2 = bind_metric(embedding_dumap[sampled_indices + broken_neighbors[point]], Hvv, Hs) embedding_test_2[\"cell_type\"] = pd.Categorical(metadata['cell.type'])[sampled_indices + broken_neighbors[point]] metrics = {k: H[k] for k in range(len(H))} dplot(embedding_test_2, width=900, height=500)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", angle=\"angle\", a=\"s0\", b=\"s1\", color=\"cell_type\")\\     .geom_ellipse()\\     .inter_isometry(metrics=metrics, metric_bw=3, transformation_bw=1)\\     .scale_color()\\     .labs(x=\"x-axis\", y=\"y-axis\") Out[20]: <pre>dplot(dataset=[{'embedding_0': 9.927645683288574, 'embedding_1': -8.331454277038574, 'x0': -0.9988652866200365\u2026</pre> In\u00a0[21]: Copied! <pre>dplot(embedding_test_1, width=700, height=500)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", angle=\"angle\", a=\"s0\", b=\"s1\", color=\"cell_type\")\\\n    .geom_hair(radiusMin=1, radiusMax=20)\\\n    .scale_color(legendTextSize=7)\\\n    .labs(x=\"UMAP-x\", y=\"UMAP-y\")\n</pre> dplot(embedding_test_1, width=700, height=500)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", angle=\"angle\", a=\"s0\", b=\"s1\", color=\"cell_type\")\\     .geom_hair(radiusMin=1, radiusMax=20)\\     .scale_color(legendTextSize=7)\\     .labs(x=\"UMAP-x\", y=\"UMAP-y\") Out[21]: <pre>dplot(dataset=[{'embedding_0': 10.636955261230469, 'embedding_1': 18.214107513427734, 'x0': -0.968463598100212\u2026</pre> In\u00a0[22]: Copied! <pre>dplot(embedding_test_2, width=700, height=500)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", angle=\"angle\", a=\"s0\", b=\"s1\", color=\"cell_type\")\\\n    .geom_hair()\\\n    .scale_color(legendTextSize=7)\\\n    .labs(x=\"DensMAP-x\", y=\"DensMAP-y\")\n</pre> dplot(embedding_test_2, width=700, height=500)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", angle=\"angle\", a=\"s0\", b=\"s1\", color=\"cell_type\")\\     .geom_hair()\\     .scale_color(legendTextSize=7)\\     .labs(x=\"DensMAP-x\", y=\"DensMAP-y\") Out[22]: <pre>dplot(dataset=[{'embedding_0': 9.927645683288574, 'embedding_1': -8.331454277038574, 'x0': -0.9988652866200365\u2026</pre> In\u00a0[23]: Copied! <pre>rng = np.random.default_rng(seed=42)\n\ncell_types = metadata['cell.type'].dropna().unique()\nselected_types = rng.choice(cell_types, size=10, replace=False)\n\nn_per_type = 5000\nrandom_indices = []\nfor ct in selected_types:\n    idx = metadata.index[metadata['cell.type'] == ct].to_numpy()\n    k = min(len(idx), n_per_type)\n    random_indices.extend(rng.choice(idx, size=k, replace=False).tolist())\n\n\nadata_random = ad.AnnData(X=data[random_indices])\nadata_random.obsm[\"X_UMAP\"] = embedding_umap[random_indices]\nadata_random.obsm[\"X_UMAP\"][:, 1] = -adata_random.obsm[\"X_UMAP\"][:, 1]\nadata_random.obsm[\"X_UMAP\"]\n\nadata_random.obsm[\"X_DenseUMAP\"] = embedding_dumap[random_indices]\nadata_random.obs[\"cell_type\"] = metadata['cell.type'].values[random_indices]\nsc.pp.neighbors(adata_random, n_neighbors=50, n_pcs=40, method='gauss')\n</pre> rng = np.random.default_rng(seed=42)  cell_types = metadata['cell.type'].dropna().unique() selected_types = rng.choice(cell_types, size=10, replace=False)  n_per_type = 5000 random_indices = [] for ct in selected_types:     idx = metadata.index[metadata['cell.type'] == ct].to_numpy()     k = min(len(idx), n_per_type)     random_indices.extend(rng.choice(idx, size=k, replace=False).tolist())   adata_random = ad.AnnData(X=data[random_indices]) adata_random.obsm[\"X_UMAP\"] = embedding_umap[random_indices] adata_random.obsm[\"X_UMAP\"][:, 1] = -adata_random.obsm[\"X_UMAP\"][:, 1] adata_random.obsm[\"X_UMAP\"]  adata_random.obsm[\"X_DenseUMAP\"] = embedding_dumap[random_indices] adata_random.obs[\"cell_type\"] = metadata['cell.type'].values[random_indices] sc.pp.neighbors(adata_random, n_neighbors=50, n_pcs=40, method='gauss') In\u00a0[24]: Copied! <pre>selected_types\n</pre> selected_types Out[24]: <pre>array(['Arcade_cell', 'Glia', 'Pharyngeal_neuron',\n       'Intestinal_and_rectal_muscle', 'Pharyngeal_marginal_cell',\n       'M_cell', 'Excretory_duct_and_pore', 'Hypodermis', 'Intestine',\n       'Rectal_gland'], dtype=object)</pre> In\u00a0[25]: Copied! <pre>umap_embed_test = adata_random.obsm[\"X_UMAP\"].copy()\ngeom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": 2})\nH, Hvv, Hs = local_distortions(umap_embed_test, adata_random.X, geom)\numap_embed_test = bind_metric(umap_embed_test, Hvv, Hs)\numap_embed_test[\"cell_type\"] = adata_random.obs[\"cell_type\"].values\nsummary = {\"umap_kappa\": Hs[:, 0] / Hs[:, 1], \"umap_vol\": Hs[:, 0] * Hs[:, 1]}\n\nplots = {}\nN = {\n    \"UMAP\": neighborhoods(adata_random, threshold=.4, outlier_factor=3, embed_key=\"X_UMAP\"),\n    \"DensMAP\": neighborhoods(adata_random, threshold=.4, outlier_factor=3, embed_key=\"X_DenseUMAP\")\n}\n\nplots[\"UMAP_p\"] = dplot(umap_embed_test, width=600, height=500)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\\n    .geom_ellipse(radiusMin=1, radiusMax=20)\\\n    .scale_color(legendTextSize=8)\\\n    .labs(x=\"UMAP 1\", y=\"UMAP 2\")\\\n    .inter_edge_link(N=N[\"UMAP\"], threshold=1, backgroundOpacity=0.3, strokeWidth=0.1, strokeOpacity=1, highlightStrokeWidth=1)\n</pre> umap_embed_test = adata_random.obsm[\"X_UMAP\"].copy() geom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": 2}) H, Hvv, Hs = local_distortions(umap_embed_test, adata_random.X, geom) umap_embed_test = bind_metric(umap_embed_test, Hvv, Hs) umap_embed_test[\"cell_type\"] = adata_random.obs[\"cell_type\"].values summary = {\"umap_kappa\": Hs[:, 0] / Hs[:, 1], \"umap_vol\": Hs[:, 0] * Hs[:, 1]}  plots = {} N = {     \"UMAP\": neighborhoods(adata_random, threshold=.4, outlier_factor=3, embed_key=\"X_UMAP\"),     \"DensMAP\": neighborhoods(adata_random, threshold=.4, outlier_factor=3, embed_key=\"X_DenseUMAP\") }  plots[\"UMAP_p\"] = dplot(umap_embed_test, width=600, height=500)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\     .geom_ellipse(radiusMin=1, radiusMax=20)\\     .scale_color(legendTextSize=8)\\     .labs(x=\"UMAP 1\", y=\"UMAP 2\")\\     .inter_edge_link(N=N[\"UMAP\"], threshold=1, backgroundOpacity=0.3, strokeWidth=0.1, strokeOpacity=1, highlightStrokeWidth=1) In\u00a0[26]: Copied! <pre>dumap_embed_test = adata_random.obsm[\"X_DenseUMAP\"].copy()\ngeom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": 2})\nH, Hvv, Hs = local_distortions(dumap_embed_test, adata_random.X, geom)\ndumap_embed_test = bind_metric(dumap_embed_test, Hvv, Hs)\ndumap_embed_test[\"cell_type\"] = adata_random.obs[\"cell_type\"].values\nplots[\"DensMAP_p\"] = dplot(dumap_embed_test, width=600, height=500)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\\n    .geom_ellipse(radiusMin=1, radiusMax=20)\\\n    .scale_color(legendTextSize=8)\\\n    .labs(x=\"DensMAP 1\", y=\"DensMAP 2\")\\\n    .inter_edge_link(N=N[\"DensMAP\"], threshold=1, backgroundOpacity=0.3, strokeWidth=0.1, strokeOpacity=1, highlightStrokeWidth=1)\n</pre> dumap_embed_test = adata_random.obsm[\"X_DenseUMAP\"].copy() geom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": 2}) H, Hvv, Hs = local_distortions(dumap_embed_test, adata_random.X, geom) dumap_embed_test = bind_metric(dumap_embed_test, Hvv, Hs) dumap_embed_test[\"cell_type\"] = adata_random.obs[\"cell_type\"].values plots[\"DensMAP_p\"] = dplot(dumap_embed_test, width=600, height=500)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\     .geom_ellipse(radiusMin=1, radiusMax=20)\\     .scale_color(legendTextSize=8)\\     .labs(x=\"DensMAP 1\", y=\"DensMAP 2\")\\     .inter_edge_link(N=N[\"DensMAP\"], threshold=1, backgroundOpacity=0.3, strokeWidth=0.1, strokeOpacity=1, highlightStrokeWidth=1) In\u00a0[27]: Copied! <pre>metrics = {k: H[k] for k in range(len(H))}\nplots[\"normal_hair\"] = dplot(umap_embed_test, width=600, height=500)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", angle=\"angle\", a=\"s0\", b=\"s1\", color=\"cell_type\")\\\n    .geom_hair(radiusMin=1)\\\n    .scale_color(legendTextSize=7)\\\n    .labs(x=\"UMAP 1\", y=\"UMAP 2\")\\\n    .inter_edge_link(N=N[\"UMAP\"], threshold=1, backgroundOpacity=0.3, strokeWidth=0.1, strokeOpacity=1, highlightStrokeWidth=1, otherClasses=[\"hair\"])\n</pre> metrics = {k: H[k] for k in range(len(H))} plots[\"normal_hair\"] = dplot(umap_embed_test, width=600, height=500)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", angle=\"angle\", a=\"s0\", b=\"s1\", color=\"cell_type\")\\     .geom_hair(radiusMin=1)\\     .scale_color(legendTextSize=7)\\     .labs(x=\"UMAP 1\", y=\"UMAP 2\")\\     .inter_edge_link(N=N[\"UMAP\"], threshold=1, backgroundOpacity=0.3, strokeWidth=0.1, strokeOpacity=1, highlightStrokeWidth=1, otherClasses=[\"hair\"]) In\u00a0[28]: Copied! <pre>plots[\"dense_hair\"] = dplot(dumap_embed_test, width=600, height=500)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", angle=\"angle\", a=\"s0\", b=\"s1\", color=\"cell_type\")\\\n    .geom_hair(radiusMin=1)\\\n    .scale_color(legendTextSize=8)\\\n    .labs(x=\"DensMAP 1\", y=\"DensMAP 2\")\\\n    .inter_edge_link(N=N[\"DensMAP\"], threshold=1, backgroundOpacity=0.3, strokeWidth=0.1, strokeOpacity=1, highlightStrokeWidth=1, otherClasses=[\"hair\"])\n</pre> plots[\"dense_hair\"] = dplot(dumap_embed_test, width=600, height=500)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", angle=\"angle\", a=\"s0\", b=\"s1\", color=\"cell_type\")\\     .geom_hair(radiusMin=1)\\     .scale_color(legendTextSize=8)\\     .labs(x=\"DensMAP 1\", y=\"DensMAP 2\")\\     .inter_edge_link(N=N[\"DensMAP\"], threshold=1, backgroundOpacity=0.3, strokeWidth=0.1, strokeOpacity=1, highlightStrokeWidth=1, otherClasses=[\"hair\"]) In\u00a0[29]: Copied! <pre>summary[\"densmap_kappa\"] = Hs[:, 0] / Hs[:, 1]\nsummary[\"densmap_vol\"] = Hs[:, 0] * Hs[:, 1]\ndf_kappa = pd.concat([\n    pd.DataFrame({'ratio': np.log(summary[\"umap_kappa\"]), 'method': 'umap', 'cell_type': adata_random.obs['cell_type']}),\n    pd.DataFrame({'ratio': np.log(summary[\"densmap_kappa\"]), 'method': 'densmap'})\n])\n\nkappa_p = alt.Chart(df_kappa).mark_bar(opacity=0.8).encode(\n    x=alt.X('ratio', bin=alt.Bin(maxbins=50), title=\"\"),\n    y=alt.Y('count()', stack=None),\n    color=alt.Color('method:N', legend=alt.Legend(title=\"Method\"))\n).properties(width=400, height=300)\n#kappa_p.save(\"../../paper/figures/kappa_p.svg\")\n</pre> summary[\"densmap_kappa\"] = Hs[:, 0] / Hs[:, 1] summary[\"densmap_vol\"] = Hs[:, 0] * Hs[:, 1] df_kappa = pd.concat([     pd.DataFrame({'ratio': np.log(summary[\"umap_kappa\"]), 'method': 'umap', 'cell_type': adata_random.obs['cell_type']}),     pd.DataFrame({'ratio': np.log(summary[\"densmap_kappa\"]), 'method': 'densmap'}) ])  kappa_p = alt.Chart(df_kappa).mark_bar(opacity=0.8).encode(     x=alt.X('ratio', bin=alt.Bin(maxbins=50), title=\"\"),     y=alt.Y('count()', stack=None),     color=alt.Color('method:N', legend=alt.Legend(title=\"Method\")) ).properties(width=400, height=300) #kappa_p.save(\"../../paper/figures/kappa_p.svg\") In\u00a0[35]: Copied! <pre>[p.save(f\"{k}.svg\") for k, p in plots.items()]\n</pre> [p.save(f\"{k}.svg\") for k, p in plots.items()] Out[35]: <pre>[None, None, None, None]</pre> In\u00a0[36]: Copied! <pre>[display(p) for p in plots.values()]\n</pre> [display(p) for p in plots.values()] <pre>dplot(dataset=[{'embedding_0': 2.621859312057495, 'embedding_1': -6.672133445739746, 'x0': -0.8586917522648949\u2026</pre> <pre>dplot(dataset=[{'embedding_0': -0.2700165808200836, 'embedding_1': 2.211699962615967, 'x0': -0.157491850843188\u2026</pre> <pre>dplot(dataset=[{'embedding_0': 2.621859312057495, 'embedding_1': -6.672133445739746, 'x0': -0.8586917522648949\u2026</pre> <pre>dplot(dataset=[{'embedding_0': -0.2700165808200836, 'embedding_1': 2.211699962615967, 'x0': -0.157491850843188\u2026</pre> Out[36]: <pre>[None, None, None, None]</pre> In\u00a0[32]: Copied! <pre>from tqdm.notebook import tqdm\n\nthresholds = np.arange(0.05, 1.0, 0.05)\nnum_keys = {\"UMAP\": [], \"DensMAP\": []}\n\nfor t in tqdm(thresholds, desc=\"Calculating neighborhood sizes...\"):\n    N_umap = neighborhoods(adata_random, threshold=t, outlier_factor=3, embed_key=\"X_UMAP\")\n    N_densmap = neighborhoods(adata_random, threshold=t, outlier_factor=3, embed_key=\"X_DenseUMAP\")\n    num_keys[\"UMAP\"].append(len(N_umap))\n    num_keys[\"DensMAP\"].append(len(N_densmap))\n</pre> from tqdm.notebook import tqdm  thresholds = np.arange(0.05, 1.0, 0.05) num_keys = {\"UMAP\": [], \"DensMAP\": []}  for t in tqdm(thresholds, desc=\"Calculating neighborhood sizes...\"):     N_umap = neighborhoods(adata_random, threshold=t, outlier_factor=3, embed_key=\"X_UMAP\")     N_densmap = neighborhoods(adata_random, threshold=t, outlier_factor=3, embed_key=\"X_DenseUMAP\")     num_keys[\"UMAP\"].append(len(N_umap))     num_keys[\"DensMAP\"].append(len(N_densmap)) <pre>Calculating neighborhood sizes...:   0%|          | 0/19 [00:00&lt;?, ?it/s]</pre> <pre>\n---------------------------------------------------------------------------\nKeyboardInterrupt                         Traceback (most recent call last)\nCell In[32], line 8\n      6 for t in tqdm(thresholds, desc=\"Calculating neighborhood sizes...\"):\n      7     N_umap = neighborhoods(adata_random, threshold=t, outlier_factor=3, embed_key=\"X_UMAP\")\n----&gt; 8     N_densmap = neighborhoods(adata_random, threshold=t, outlier_factor=3, embed_key=\"X_DenseUMAP\")\n      9     num_keys[\"UMAP\"].append(len(N_umap))\n     10     num_keys[\"DensMAP\"].append(len(N_densmap))\n\nFile ~/Desktop/collaborations/distortion/distortions/geometry/neighborhoods.py:125, in neighborhoods(adata, outlier_factor, threshold, method, percentiles, frame, nbin, **kwargs)\n     83 \"\"\"\n     84 Identify broken neighborhoods in embeddings using different methods.\n     85 \n   (...)    122     If an unsupported method is specified.\n    123 \"\"\"\n    124 if method == \"box\":\n--&gt; 125     return neighborhoods_box(adata, outlier_factor, threshold, nbin, **kwargs)\n    126 if method == \"window\":\n    127     return neighborhoods_window(adata, outlier_factor, threshold, percentiles, frame, **kwargs)\n\nFile ~/Desktop/collaborations/distortion/distortions/geometry/neighborhoods.py:194, in neighborhoods_box(adata, outlier_factor, threshold, nbin, **kwargs)\n    166 def neighborhoods_box(adata, outlier_factor=3, threshold=0.2, nbin=10, **kwargs):\n    167     \"\"\"\n    168     Identify broken neighborhoods using boxplot-based outlier detection.\n    169     \n   (...)    192         for samples with broken neighborhoods.\n    193     \"\"\"\n--&gt; 194     dists = neighborhood_distances(adata, **kwargs)\n    195     brokenness = identify_broken_box(dists, outlier_factor, nbin)\n    196     return threshold_links(dists, brokenness, threshold)\n\nFile ~/Desktop/collaborations/distortion/distortions/geometry/neighborhoods.py:70, in neighborhood_distances(adata, embed_key)\n     66     neighbors = knn_graph[ix].nonzero()[1]\n     67     true = knn_graph[ix, neighbors].toarray().flatten()\n     68     embedding = cdist(\n     69         [adata.obsm[embed_key][ix, :]], \n---&gt; 70         adata.obsm[embed_key][neighbors, :]\n     71     ).flatten()\n     72     dist_list.append(pd.DataFrame({\n     73         \"center\": [ix] * len(neighbors), \n     74         \"neighbor\": neighbors,\n     75         \"true\": true,\n     76         \"embedding\": embedding\n     77     }))\n     79 return pd.concat(dist_list)\n\nFile /opt/miniconda3/envs/dist2/lib/python3.12/site-packages/anndata/_core/aligned_mapping.py:423, in AlignedMappingProperty.__get__(self, obj, objtype)\n    421     return self  # type: ignore\n    422 if not obj.is_view:\n--&gt; 423     return self.construct(obj, store=getattr(obj, f\"_{self.name}\"))\n    424 parent_anndata = obj._adata_ref\n    425 idxs = (obj._oidx, obj._vidx)\n\nFile /opt/miniconda3/envs/dist2/lib/python3.12/site-packages/anndata/_core/aligned_mapping.py:403, in AlignedMappingProperty.construct(self, obj, store)\n    400 axis: Literal[0, 1] | None = None\n    401 \"\"\"Axis of the parent to align to.\"\"\"\n--&gt; 403 def construct(self, obj: AnnData, *, store: MutableMapping[str, Value]) -&gt; T:\n    404     if self.axis is None:\n    405         return self.cls(obj, store=store)\n\nKeyboardInterrupt: </pre> In\u00a0[\u00a0]: Copied! <pre>distortion_size = alt.Chart(\n    pd.DataFrame({\n        \"threshold\": np.tile(np.round(thresholds, 2), 2),\n        \"Method\": np.concatenate([[\"UMAP\"] * len(thresholds), [\"DensMAP\"] * len(thresholds)]),\n        \"Count\": np.concatenate([num_keys[\"UMAP\"], num_keys[\"DensMAP\"]])\n        })\n    ).mark_bar().encode(\n        x=alt.X(\"threshold:N\", title=\"Threshold Fraction\"),\n        y=alt.Y(\"Count:Q\", title=\"Number of Distorted Neighborhoods\"),\n        color=alt.Color(\"Method:N\", title=\"Method\")\n    )\n\n#distortion_size.save(\"../../paper/figures/distortion_size.svg\")\n</pre> distortion_size = alt.Chart(     pd.DataFrame({         \"threshold\": np.tile(np.round(thresholds, 2), 2),         \"Method\": np.concatenate([[\"UMAP\"] * len(thresholds), [\"DensMAP\"] * len(thresholds)]),         \"Count\": np.concatenate([num_keys[\"UMAP\"], num_keys[\"DensMAP\"]])         })     ).mark_bar().encode(         x=alt.X(\"threshold:N\", title=\"Threshold Fraction\"),         y=alt.Y(\"Count:Q\", title=\"Number of Distorted Neighborhoods\"),         color=alt.Color(\"Method:N\", title=\"Method\")     )  #distortion_size.save(\"../../paper/figures/distortion_size.svg\")"},{"location":"tutorials/c_elegans.html#umap-and-denseumap","title":"UMAP and DenseUmap\u00b6","text":""},{"location":"tutorials/c_elegans_algorithm_comparison.html","title":"Comparing Density Preserving Algorithms on the C. Elegans Data","text":"In\u00a0[1]: Copied! <pre>import pandas as pd\nimport numpy as np\ndata_path = \"https://raw.githubusercontent.com/krisrs1128/distortions-data/main/data/c-elegans_qc_final.txt\" \nmetadata_path = \"https://raw.githubusercontent.com/krisrs1128/distortions-data/main/data/c-elegans_qc_final_metadata.txt\"\n\ndata = np.loadtxt(data_path, delimiter=\"\\t\")\nmetadata = pd.read_csv(metadata_path, sep=\",\")\n</pre> import pandas as pd import numpy as np data_path = \"https://raw.githubusercontent.com/krisrs1128/distortions-data/main/data/c-elegans_qc_final.txt\"  metadata_path = \"https://raw.githubusercontent.com/krisrs1128/distortions-data/main/data/c-elegans_qc_final_metadata.txt\"  data = np.loadtxt(data_path, delimiter=\"\\t\") metadata = pd.read_csv(metadata_path, sep=\",\") <p>Prepare embedding method you want to analyze</p> In\u00a0[2]: Copied! <pre>import umap\nembedding_dumap = umap.UMAP(n_neighbors=10, n_components=2, n_epochs=500, densmap = True).fit_transform(data)\nembedding_umap = umap.UMAP(n_neighbors=10, n_components=2, n_epochs=500, densmap = False).fit_transform(data)\n</pre> import umap embedding_dumap = umap.UMAP(n_neighbors=10, n_components=2, n_epochs=500, densmap = True).fit_transform(data) embedding_umap = umap.UMAP(n_neighbors=10, n_components=2, n_epochs=500, densmap = False).fit_transform(data) <p>Visualize both embedding, we can see differences between UMAP and DenseMap:</p> In\u00a0[3]: Copied! <pre>import matplotlib.pyplot as plt\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# Plot DenseUMAP\nsc1 = axes[0].scatter(\n    embedding_dumap[:, 0], embedding_dumap[:, 1],\n    c=pd.Categorical(metadata['cell.type']).codes,\n    cmap='viridis', s=1\n)\naxes[0].set_title(\"DenseUMAP Embedding of C. elegans Dataset\")\naxes[0].set_xlabel(\"Dimension 1\")\naxes[0].set_ylabel(\"Dimension 2\")\n\n# Plot UMAP\nsc2 = axes[1].scatter(\n    embedding_umap[:, 0], embedding_umap[:, 1],\n    c=pd.Categorical(metadata['cell.type']).codes,\n    cmap='viridis', s=1\n)\naxes[1].set_title(\"UMAP Embedding of C. elegans Dataset\")\naxes[1].set_xlabel(\"Dimension 1\")\naxes[1].set_ylabel(\"Dimension 2\")\n\nplt.tight_layout()\nplt.show()\n</pre> import matplotlib.pyplot as plt  fig, axes = plt.subplots(1, 2, figsize=(14, 6))  # Plot DenseUMAP sc1 = axes[0].scatter(     embedding_dumap[:, 0], embedding_dumap[:, 1],     c=pd.Categorical(metadata['cell.type']).codes,     cmap='viridis', s=1 ) axes[0].set_title(\"DenseUMAP Embedding of C. elegans Dataset\") axes[0].set_xlabel(\"Dimension 1\") axes[0].set_ylabel(\"Dimension 2\")  # Plot UMAP sc2 = axes[1].scatter(     embedding_umap[:, 0], embedding_umap[:, 1],     c=pd.Categorical(metadata['cell.type']).codes,     cmap='viridis', s=1 ) axes[1].set_title(\"UMAP Embedding of C. elegans Dataset\") axes[1].set_xlabel(\"Dimension 1\") axes[1].set_ylabel(\"Dimension 2\")  plt.tight_layout() plt.show() <p>The dataset is large, so we can take some samples</p> In\u00a0[4]: Copied! <pre>colors = metadata['cell.type']\ncell_picked = metadata.groupby('cell.type').size().sort_values(ascending=False).index[:5].tolist()\nfrom collections import defaultdict\ndef sampling(source, num_sample, cell_picked):    \n    class_indices = defaultdict(list)\n    for idx, label in enumerate(source):\n        class_indices[label].append(idx)\n\n    rng = np.random.default_rng(seed=42) \n    sampled_indices = []\n    for label, indices in class_indices.items():\n        if label in cell_picked:\n            n_class_samples = min(len(indices), num_sample)\n            sampled_indices.extend(rng.choice(indices, n_class_samples, replace=False))\n    return sampled_indices\nsampled_indices = sampling(colors, 100, cell_picked)\n</pre> colors = metadata['cell.type'] cell_picked = metadata.groupby('cell.type').size().sort_values(ascending=False).index[:5].tolist() from collections import defaultdict def sampling(source, num_sample, cell_picked):         class_indices = defaultdict(list)     for idx, label in enumerate(source):         class_indices[label].append(idx)      rng = np.random.default_rng(seed=42)      sampled_indices = []     for label, indices in class_indices.items():         if label in cell_picked:             n_class_samples = min(len(indices), num_sample)             sampled_indices.extend(rng.choice(indices, n_class_samples, replace=False))     return sampled_indices sampled_indices = sampling(colors, 100, cell_picked) In\u00a0[5]: Copied! <pre>import distortions\nfrom distortions.geometry import Geometry, bind_metric, local_distortions\nfrom distortions.geometry import neighborhoods\nfrom distortions.visualization import dplot\n\nimport anndata as ad\nimport scanpy as sc\n\nadata = ad.AnnData(X=data[sampled_indices])\nadata.X.shape\nadata.obsm[\"X_DUMAP\"] = embedding_dumap[sampled_indices]\nadata.obsm[\"X_UMAP\"] = embedding_umap[sampled_indices]\nadata.obs[\"cell_type\"] = metadata['cell.type'].values[sampled_indices]\nsc.pp.neighbors(adata, n_neighbors=50, n_pcs=40, method='gauss') # Use gauss kernel to compute the neighbors and gain the required information for this data\n</pre> import distortions from distortions.geometry import Geometry, bind_metric, local_distortions from distortions.geometry import neighborhoods from distortions.visualization import dplot  import anndata as ad import scanpy as sc  adata = ad.AnnData(X=data[sampled_indices]) adata.X.shape adata.obsm[\"X_DUMAP\"] = embedding_dumap[sampled_indices] adata.obsm[\"X_UMAP\"] = embedding_umap[sampled_indices] adata.obs[\"cell_type\"] = metadata['cell.type'].values[sampled_indices] sc.pp.neighbors(adata, n_neighbors=50, n_pcs=40, method='gauss') # Use gauss kernel to compute the neighbors and gain the required information for this data  <pre>WARNING: You\u2019re trying to run this on 100 dimensions of `.X`, if you really want this, set `use_rep='X'`.\n         Falling back to preprocessing with `sc.pp.pca` and default params.\n</pre> <pre>/opt/anaconda3/envs/manifold/lib/python3.9/site-packages/anndata/_core/anndata.py:522: FutureWarning: The dtype argument is deprecated and will be removed in late 2024.\n  warnings.warn(\n</pre> <p>Here is the code that creates the line connections between embeddings and their neighbors from the original dataset, the threshold and outlier_factor both controls the amount brokens we will show the line relations.</p> In\u00a0[6]: Copied! <pre>N_DenseMap = neighborhoods(adata, threshold=.2, outlier_factor=2, embed_key=\"X_DUMAP\")\nN_UMAP = neighborhoods(adata, threshold=.2, outlier_factor=2, embed_key=\"X_UMAP\")\n</pre> N_DenseMap = neighborhoods(adata, threshold=.2, outlier_factor=2, embed_key=\"X_DUMAP\") N_UMAP = neighborhoods(adata, threshold=.2, outlier_factor=2, embed_key=\"X_UMAP\") <p>Prepare the ellipse information, to achieve reasonable results, radius should be small enough to make the sample be one connected component</p> In\u00a0[7]: Copied! <pre>radius = 15 # To achieve reasonable results, radius should be smaller enought to make the sample be one connected component\ngeom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"radius\": radius, \"n_neighbors\": None}, laplacian_kwds={\"scaling_epps\": radius})\n\ndensmap_embed_test = adata.obsm[\"X_DUMAP\"].copy()\nH, Hvv, Hs = local_distortions(densmap_embed_test, adata.X, geom)\ndensmap_embed_test = bind_metric(densmap_embed_test, Hvv, Hs)\ndensmap_embed_test[\"cell_type\"] = adata.obs[\"cell_type\"].values\nsummary = {\"densmap_kappa\": Hs[:, 0] / Hs[:, 1], \"densmap_vol\": Hs[:, 0] * Hs[:, 1]}\n\numap_embed_test = adata.obsm[\"X_UMAP\"].copy()\nH, Hvv, Hs = local_distortions(umap_embed_test, adata.X, geom)\numap_embed_test = bind_metric(umap_embed_test, Hvv, Hs)\numap_embed_test[\"cell_type\"] = adata.obs[\"cell_type\"].values\nsummary[\"umap_kappa\"] = Hs[:, 0] / Hs[:, 1]\nsummary[\"umap_vol\"] = Hs[:, 0] * Hs[:, 1]\n</pre> radius = 15 # To achieve reasonable results, radius should be smaller enought to make the sample be one connected component geom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"radius\": radius, \"n_neighbors\": None}, laplacian_kwds={\"scaling_epps\": radius})  densmap_embed_test = adata.obsm[\"X_DUMAP\"].copy() H, Hvv, Hs = local_distortions(densmap_embed_test, adata.X, geom) densmap_embed_test = bind_metric(densmap_embed_test, Hvv, Hs) densmap_embed_test[\"cell_type\"] = adata.obs[\"cell_type\"].values summary = {\"densmap_kappa\": Hs[:, 0] / Hs[:, 1], \"densmap_vol\": Hs[:, 0] * Hs[:, 1]}  umap_embed_test = adata.obsm[\"X_UMAP\"].copy() H, Hvv, Hs = local_distortions(umap_embed_test, adata.X, geom) umap_embed_test = bind_metric(umap_embed_test, Hvv, Hs) umap_embed_test[\"cell_type\"] = adata.obs[\"cell_type\"].values summary[\"umap_kappa\"] = Hs[:, 0] / Hs[:, 1] summary[\"umap_vol\"] = Hs[:, 0] * Hs[:, 1] <pre>/var/folders/vf/9glxmz0n2jgg7q_1dvnvt09h0000gn/T/ipykernel_43907/650361105.py:8: RuntimeWarning: invalid value encountered in true_divide\n  summary = {\"densmap_kappa\": Hs[:, 0] / Hs[:, 1], \"densmap_vol\": Hs[:, 0] * Hs[:, 1]}\n/var/folders/vf/9glxmz0n2jgg7q_1dvnvt09h0000gn/T/ipykernel_43907/650361105.py:14: RuntimeWarning: invalid value encountered in true_divide\n  summary[\"umap_kappa\"] = Hs[:, 0] / Hs[:, 1]\n</pre> <p>Visualization by distortions package</p> In\u00a0[8]: Copied! <pre>display(dplot(densmap_embed_test, width=600, height=500)\\\n        .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\\n        .geom_ellipse(radiusMax=12, radiusMin=2)\\\n        .scale_color(legendTextSize=8)\\\n        .labs(x=\"DensMap 1\", y=\"DensMap 2\")\\\n        .inter_edge_link(N=N_DenseMap, threshold=1, backgroundOpacity=0.4, strokeWidth=0.1, strokeOpacity=1, highlightStrokeWidth=0.1))\n\ndisplay(dplot(umap_embed_test, width=600, height=500)\\\n        .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\\n        .geom_ellipse(radiusMax=12, radiusMin=2)\\\n        .scale_color(legendTextSize=8)\\\n        .labs(x=\"UMAP 1\", y=\"UMAP 2\")\\\n        .inter_edge_link(N=N_UMAP, threshold=1, backgroundOpacity=0.4, strokeWidth=0.1, strokeOpacity=1, highlightStrokeWidth=0.1))\n</pre> display(dplot(densmap_embed_test, width=600, height=500)\\         .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\         .geom_ellipse(radiusMax=12, radiusMin=2)\\         .scale_color(legendTextSize=8)\\         .labs(x=\"DensMap 1\", y=\"DensMap 2\")\\         .inter_edge_link(N=N_DenseMap, threshold=1, backgroundOpacity=0.4, strokeWidth=0.1, strokeOpacity=1, highlightStrokeWidth=0.1))  display(dplot(umap_embed_test, width=600, height=500)\\         .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\         .geom_ellipse(radiusMax=12, radiusMin=2)\\         .scale_color(legendTextSize=8)\\         .labs(x=\"UMAP 1\", y=\"UMAP 2\")\\         .inter_edge_link(N=N_UMAP, threshold=1, backgroundOpacity=0.4, strokeWidth=0.1, strokeOpacity=1, highlightStrokeWidth=0.1)) <pre>/opt/anaconda3/envs/manifold/lib/python3.9/site-packages/jupyter_client/session.py:721: UserWarning: Message serialization failed with:\nkeys must be str, int, float, bool or None, not numpy.int64\nSupporting this message is deprecated in jupyter-client 7, please make sure your message is JSON-compliant\n  content = self.pack(content)\n</pre> <pre>dplot(dataset=[{'embedding_0': -1.4575797319412231, 'embedding_1': -10.177319526672363, 'x0': -0.8967761035817\u2026</pre> <pre>/opt/anaconda3/envs/manifold/lib/python3.9/site-packages/jupyter_client/session.py:721: UserWarning: Message serialization failed with:\nkeys must be str, int, float, bool or None, not numpy.int64\nSupporting this message is deprecated in jupyter-client 7, please make sure your message is JSON-compliant\n  content = self.pack(content)\n</pre> <pre>dplot(dataset=[{'embedding_0': 12.73399829864502, 'embedding_1': -8.810925483703613, 'x0': -0.3376286864707447\u2026</pre> <p>If you want to see the compress direction more closely, the hair plot is a good choice</p> In\u00a0[9]: Copied! <pre>display(dplot(densmap_embed_test, width=600, height=500)\\\n        .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\\n        .geom_hair(radiusMax=24, radiusMin=2)\\\n        .scale_color(legendTextSize=8)\\\n        .labs(x=\"DensMap 1\", y=\"DensMap 2\")\\\n        .inter_edge_link(N=N_DenseMap, threshold=1, backgroundOpacity=0.4, strokeWidth=0.1, strokeOpacity=1, highlightStrokeWidth=0.1))\ndisplay(dplot(umap_embed_test, width=600, height=500)\\\n        .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\\n        .geom_hair(radiusMax=24, radiusMin=2)\\\n        .scale_color(legendTextSize=8)\\\n        .labs(x=\"UMAP 1\", y=\"UMAP 2\")\\\n        .inter_edge_link(N=N_DenseMap, threshold=1, backgroundOpacity=0.4, strokeWidth=0.1, strokeOpacity=1, highlightStrokeWidth=0.1))\n</pre> display(dplot(densmap_embed_test, width=600, height=500)\\         .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\         .geom_hair(radiusMax=24, radiusMin=2)\\         .scale_color(legendTextSize=8)\\         .labs(x=\"DensMap 1\", y=\"DensMap 2\")\\         .inter_edge_link(N=N_DenseMap, threshold=1, backgroundOpacity=0.4, strokeWidth=0.1, strokeOpacity=1, highlightStrokeWidth=0.1)) display(dplot(umap_embed_test, width=600, height=500)\\         .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\         .geom_hair(radiusMax=24, radiusMin=2)\\         .scale_color(legendTextSize=8)\\         .labs(x=\"UMAP 1\", y=\"UMAP 2\")\\         .inter_edge_link(N=N_DenseMap, threshold=1, backgroundOpacity=0.4, strokeWidth=0.1, strokeOpacity=1, highlightStrokeWidth=0.1)) <pre>/opt/anaconda3/envs/manifold/lib/python3.9/site-packages/jupyter_client/session.py:721: UserWarning: Message serialization failed with:\nkeys must be str, int, float, bool or None, not numpy.int64\nSupporting this message is deprecated in jupyter-client 7, please make sure your message is JSON-compliant\n  content = self.pack(content)\n</pre> <pre>dplot(dataset=[{'embedding_0': -1.4575797319412231, 'embedding_1': -10.177319526672363, 'x0': -0.8967761035817\u2026</pre> <pre>/opt/anaconda3/envs/manifold/lib/python3.9/site-packages/jupyter_client/session.py:721: UserWarning: Message serialization failed with:\nkeys must be str, int, float, bool or None, not numpy.int64\nSupporting this message is deprecated in jupyter-client 7, please make sure your message is JSON-compliant\n  content = self.pack(content)\n</pre> <pre>dplot(dataset=[{'embedding_0': 12.73399829864502, 'embedding_1': -8.810925483703613, 'x0': -0.3376286864707447\u2026</pre> <p>Even not so obvious, we can still see the ellipse generated by the densMap is more uniform. And then we can do a simple counting:</p> In\u00a0[10]: Copied! <pre>import altair as alt\ndf_kappa = pd.concat([\n    pd.DataFrame({'ratio': np.log(summary[\"umap_kappa\"]), 'method': 'umap', 'cell_type': adata.obs['cell_type']}),\n    pd.DataFrame({'ratio': np.log(summary[\"densmap_kappa\"]), 'method': 'densmap'})\n])\n\nalt.Chart(df_kappa).mark_bar(opacity=0.5).encode(\n    x=alt.X('ratio', bin=alt.Bin(maxbins=50)),\n    y=alt.Y('count()', stack=None),\n    color=alt.Color('method:N', legend=alt.Legend(title=\"Method\"))\n).properties(width=400, height=300)\n</pre> import altair as alt df_kappa = pd.concat([     pd.DataFrame({'ratio': np.log(summary[\"umap_kappa\"]), 'method': 'umap', 'cell_type': adata.obs['cell_type']}),     pd.DataFrame({'ratio': np.log(summary[\"densmap_kappa\"]), 'method': 'densmap'}) ])  alt.Chart(df_kappa).mark_bar(opacity=0.5).encode(     x=alt.X('ratio', bin=alt.Bin(maxbins=50)),     y=alt.Y('count()', stack=None),     color=alt.Color('method:N', legend=alt.Legend(title=\"Method\")) ).properties(width=400, height=300) Out[10]: <p>By looking the internal isometry information, we can see the local distortion information more clearly, especially provide your a 3d views</p> <p>By looking at the internal isometry information, we can see the local distortion information more clearly, which extend the 2d visualize information</p> In\u00a0[11]: Copied! <pre>metrics = {k: H[k] for k in range(len(H))}\ndplot(densmap_embed_test, width=600, height=500)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\",color=\"cell_type\")\\\n    .geom_ellipse(radiusMax=12, radiusMin=2)\\\n    .inter_isometry(metrics=metrics, metric_bw=1, transformation_bw=0.2, strokeWidth=0.2)\\\n    .scale_color()\\\n    .labs(x=\"DensMap 1\", y=\"DensMap 2\")\n</pre> metrics = {k: H[k] for k in range(len(H))} dplot(densmap_embed_test, width=600, height=500)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\",color=\"cell_type\")\\     .geom_ellipse(radiusMax=12, radiusMin=2)\\     .inter_isometry(metrics=metrics, metric_bw=1, transformation_bw=0.2, strokeWidth=0.2)\\     .scale_color()\\     .labs(x=\"DensMap 1\", y=\"DensMap 2\") Out[11]: <pre>dplot(dataset=[{'embedding_0': -1.4575797319412231, 'embedding_1': -10.177319526672363, 'x0': -0.8967761035817\u2026</pre> In\u00a0[15]: Copied! <pre>metrics = {k: H[k] for k in range(len(H))}\ndplot(umap_embed_test, width=600, height=500)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", angle=\"angle\", a=\"s0\", b=\"s1\", color=\"cell_type\")\\\n    .geom_ellipse(radiusMax=12, radiusMin=2)\\\n    .inter_isometry(metrics=metrics, metric_bw=1, transformation_bw=0.2, strokeWidth=0.2)\\\n    .scale_color()\\\n    .labs(x=\"UMPA 1\", y=\"UMAP 2\")\n</pre> metrics = {k: H[k] for k in range(len(H))} dplot(umap_embed_test, width=600, height=500)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", angle=\"angle\", a=\"s0\", b=\"s1\", color=\"cell_type\")\\     .geom_ellipse(radiusMax=12, radiusMin=2)\\     .inter_isometry(metrics=metrics, metric_bw=1, transformation_bw=0.2, strokeWidth=0.2)\\     .scale_color()\\     .labs(x=\"UMPA 1\", y=\"UMAP 2\") Out[15]: <pre>dplot(dataset=[{'embedding_0': 12.73399829864502, 'embedding_1': -8.810925483703613, 'x0': -0.3376286864707447\u2026</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorials/c_elegans_algorithm_comparison.html#preparation-process","title":"Preparation process\u00b6","text":"<p>Now we can look at some real examples, C.elegans dataset with data link: Ashwin Narayan Datasets https://cb.csail.mit.edu/densvis/datasets/.\\ With this dataset, we can look more closely with how our package works. Especially when we are trying to explore the ellipse difference between the DensMAP and UMAP using our package</p> <p>Note: If you already have the data and embedding, feel free to skip this part</p>"},{"location":"tutorials/c_elegans_algorithm_comparison.html#distortion-analysis","title":"Distortion analysis\u00b6","text":"<p>make sure you already has the <code>distortions</code> package installed. After you prepare the raw data and the embedding you want to analyze, you can bind them by anndata.</p>"},{"location":"tutorials/custom_neighbors.html","title":"Interacting with scDEED Flagged Neighborhoods","text":"In\u00a0[1]: Copied! <pre>import scanpy as sc\n\ncounts = sc.datasets.pbmc3k().X.todense().T\n%load_ext rpy2.ipython\n</pre> import scanpy as sc  counts = sc.datasets.pbmc3k().X.todense().T %load_ext rpy2.ipython In\u00a0[2]: Copied! <pre>%%R -i counts\n\nlibrary(tidyverse)\nlibrary(Seurat)\nlibrary(scDEED)\n\nperplexity &lt;- 40\ndata &lt;- CreateSeuratObject(counts) |&gt;\n    FindVariableFeatures() |&gt;\n    NormalizeData() |&gt;\n    ScaleData() |&gt;\n    RunPCA() |&gt;\n    RunTSNE(perplexity=perplexity)\n</pre> %%R -i counts  library(tidyverse) library(Seurat) library(scDEED)  perplexity &lt;- 40 data &lt;- CreateSeuratObject(counts) |&gt;     FindVariableFeatures() |&gt;     NormalizeData() |&gt;     ScaleData() |&gt;     RunPCA() |&gt;     RunTSNE(perplexity=perplexity) <pre>\u2500\u2500 Attaching core tidyverse packages \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 tidyverse 2.0.0 \u2500\u2500\n\u2714 dplyr     1.1.4     \u2714 readr     2.1.5\n\u2714 forcats   1.0.0     \u2714 stringr   1.5.1\n\u2714 ggplot2   3.5.2     \u2714 tibble    3.3.0\n\u2714 lubridate 1.9.4     \u2714 tidyr     1.3.1\n\u2714 purrr     1.1.0     \n\u2500\u2500 Conflicts \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 tidyverse_conflicts() \u2500\u2500\n\u2716 dplyr::filter() masks stats::filter()\n\u2716 dplyr::lag()    masks stats::lag()\n\u2139 Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n    WARNING: The R package \"reticulate\" only fixed recently\n    an issue that caused a segfault when used with rpy2:\n    https://github.com/rstudio/reticulate/pull/1188\n    Make sure that you use a version of that package that includes\n    the fix.\n    </pre> <pre>Loading required package: SeuratObject\nLoading required package: sp\n\u2018SeuratObject\u2019 was built under R 4.5.0 but the current version is\n4.5.1; it is recomended that you reinstall \u2018SeuratObject\u2019 as the ABI\nfor R may have changed\n\nAttaching package: \u2018SeuratObject\u2019\n\nThe following objects are masked from \u2018package:base\u2019:\n\n    intersect, t\n\n\nAttaching package: \u2018scDEED\u2019\n\nThe following object is masked from \u2018package:stats\u2019:\n\n    optimize\n\nWarning: Data is of class matrix. Coercing to dgCMatrix.\nFinding variable features for layer counts\nCalculating gene variances\n0%   10   20   30   40   50   60   70   80   90   100%\n[----|----|----|----|----|----|----|----|----|----|\n**************************************************|\nCalculating feature variances of standardized and clipped values\n0%   10   20   30   40   50   60   70   80   90   100%\n[----|----|----|----|----|----|----|----|----|----|\n**************************************************|\nNormalizing layer: counts\nPerforming log-normalization\n0%   10   20   30   40   50   60   70   80   90   100%\n[----|----|----|----|----|----|----|----|----|----|\n**************************************************|\nCentering and scaling data matrix\n\r  |                                                                            \r  |                                                                      |   0%\r  |                                                                            \r  |===================================                                   |  50%\r  |                                                                            \r  |======================================================================| 100%\nPC_ 1 \nPositive:  Feature28818, Feature30430, Feature10609, Feature10611, Feature30934, Feature16745, Feature21054, Feature18999, Feature1956, Feature2225 \n\t   Feature32216, Feature29429, Feature31964, Feature1958, Feature1846, Feature31959, Feature23264, Feature18773, Feature18149, Feature17465 \n\t   Feature13509, Feature13383, Feature30115, Feature25893, Feature1903, Feature23057, Feature22827, Feature19264, Feature25268, Feature2483 \nNegative:  Feature19155, Feature10608, Feature24758, Feature1636, Feature26263, Feature12205, Feature19180, Feature2301, Feature26825, Feature13131 \n\t   Feature15831, Feature8890, Feature28833, Feature2760, Feature4088, Feature7587, Feature13779, Feature8887, Feature15412, Feature13126 \n\t   Feature13862, Feature19991, Feature532, Feature4134, Feature7224, Feature18406, Feature9383, Feature31076, Feature20238, Feature11419 \nPC_ 2 \nPositive:  Feature30657, Feature18945, Feature23289, Feature10681, Feature10678, Feature10682, Feature23927, Feature27508, Feature10680, Feature9799 \n\t   Feature10701, Feature10696, Feature10685, Feature10679, Feature10700, Feature10694, Feature2243, Feature21419, Feature10608, Feature17729 \n\t   Feature23476, Feature26139, Feature25915, Feature31683, Feature18431, Feature7803, Feature7465, Feature30509, Feature2121, Feature25909 \nNegative:  Feature31076, Feature17450, Feature28833, Feature8890, Feature22590, Feature7345, Feature19180, Feature4047, Feature22589, Feature7170 \n\t   Feature26840, Feature2238, Feature26825, Feature2301, Feature2317, Feature16816, Feature16916, Feature17424, Feature7587, Feature19539 \n\t   Feature32158, Feature1965, Feature16089, Feature24758, Feature7593, Feature3295, Feature11888, Feature2318, Feature32017, Feature11419 \nPC_ 3 \nPositive:  Feature10681, Feature30657, Feature27508, Feature10682, Feature10701, Feature9799, Feature10700, Feature18945, Feature10680, Feature10679 \n\t   Feature10678, Feature10685, Feature23289, Feature23927, Feature10694, Feature10696, Feature21419, Feature2243, Feature25915, Feature17729 \n\t   Feature23476, Feature7465, Feature23451, Feature26139, Feature31683, Feature18431, Feature12405, Feature4028, Feature7669, Feature9601 \nNegative:  Feature7697, Feature7696, Feature4865, Feature9825, Feature12535, Feature19923, Feature6459, Feature2538, Feature29270, Feature14587 \n\t   Feature10421, Feature19444, Feature27143, Feature20143, Feature5519, Feature15067, Feature10867, Feature20164, Feature27373, Feature13865 \n\t   Feature10828, Feature10241, Feature10110, Feature31597, Feature14266, Feature22002, Feature22527, Feature10390, Feature28980, Feature26183 \nPC_ 4 \nPositive:  Feature10681, Feature10421, Feature7696, Feature4865, Feature30657, Feature27508, Feature7697, Feature12535, Feature9825, Feature10682 \n\t   Feature18945, Feature9799, Feature6459, Feature10701, Feature19923, Feature2538, Feature10867, Feature20143, Feature19444, Feature10685 \n\t   Feature14587, Feature29270, Feature15067, Feature10680, Feature10700, Feature27143, Feature5519, Feature10678, Feature23289, Feature20164 \nNegative:  Feature17040, Feature1958, Feature1963, Feature1965, Feature4028, Feature1956, Feature24758, Feature13126, Feature1901, Feature31959 \n\t   Feature232, Feature4088, Feature16745, Feature21054, Feature1636, Feature1957, Feature18938, Feature8803, Feature1903, Feature15831 \n\t   Feature13127, Feature19354, Feature16089, Feature19155, Feature10611, Feature13131, Feature7692, Feature595, Feature4026, Feature26245 \nPC_ 5 \nPositive:  Feature10608, Feature17040, Feature15831, Feature17443, Feature4088, Feature24011, Feature1636, Feature19254, Feature4582, Feature8803 \n\t   Feature24758, Feature25589, Feature8033, Feature20638, Feature27657, Feature27929, Feature20905, Feature13779, Feature25893, Feature22260 \n\t   Feature27827, Feature9383, Feature16960, Feature2760, Feature17357, Feature13127, Feature925, Feature11512, Feature13865, Feature532 \nNegative:  Feature22590, Feature7345, Feature31076, Feature4047, Feature17450, Feature26840, Feature28833, Feature7170, Feature8890, Feature16816 \n\t   Feature22589, Feature2317, Feature19180, Feature32158, Feature16916, Feature26825, Feature7593, Feature2318, Feature1958, Feature26839 \n\t   Feature30430, Feature7587, Feature1737, Feature9855, Feature1956, Feature2225, Feature22798, Feature31959, Feature232, Feature1957 \n</pre> In\u00a0[3]: Copied! <pre>%%R\n\nembeddings &lt;- Embeddings(data, \"tsne\")\nnormalized_counts &lt;- GetAssayData(data, layer = \"scale.data\") |&gt;\n    as.matrix() |&gt;\n    t()\n</pre> %%R  embeddings &lt;- Embeddings(data, \"tsne\") normalized_counts &lt;- GetAssayData(data, layer = \"scale.data\") |&gt;     as.matrix() |&gt;     t() In\u00a0[4]: Copied! <pre>import numpy as np\nimport rpy2.robjects\n\nembeddings = np.array(rpy2.robjects.globalenv['embeddings'])\nnormalized_counts = np.array(rpy2.robjects.globalenv[\"normalized_counts\"])\n</pre> import numpy as np import rpy2.robjects  embeddings = np.array(rpy2.robjects.globalenv['embeddings']) normalized_counts = np.array(rpy2.robjects.globalenv[\"normalized_counts\"]) In\u00a0[5]: Copied! <pre>%%R\n\nK &lt;- 8\nresult &lt;- scDEED(data, K = K, reduction.method = 'tsne', rerun = F, perplexity = perplexity)\ndubious &lt;- result$full_results |&gt;\n    filter(perplexity == perplexity) |&gt;\n    pull(dubious_cells) |&gt;\n    str_split(\",\")\n\ndubious &lt;- as.integer(dubious[[1]])\n\ndata &lt;- FindNeighbors(data, features = VariableFeatures(data), k.param = 50)\nG &lt;- data@graphs$RNA_nn\nN &lt;- map(dubious, ~ which(G[.x, ] &gt; 0)) |&gt;\n    set_names(dubious)\n</pre> %%R  K &lt;- 8 result &lt;- scDEED(data, K = K, reduction.method = 'tsne', rerun = F, perplexity = perplexity) dubious &lt;- result$full_results |&gt;     filter(perplexity == perplexity) |&gt;     pull(dubious_cells) |&gt;     str_split(\",\")  dubious &lt;- as.integer(dubious[[1]])  data &lt;- FindNeighbors(data, features = VariableFeatures(data), k.param = 50) G &lt;- data@graphs$RNA_nn N &lt;- map(dubious, ~ which(G[.x, ] &gt; 0)) |&gt;     set_names(dubious) <pre>[1] \"Permuting data\"\n  |======================================================================| 100%[1] \"Permutation finished\"\n</pre> <pre>Warning: Number of dimensions changing from 50 to 8\nComputing nearest neighbor graph\nComputing SNN\nIn addition: Warning messages:\n1: The `slot` argument of `GetAssayData()` is deprecated as of SeuratObject 5.0.0.\n\u2139 Please use the `layer` argument instead.\n\u2139 The deprecated feature was likely used in the scDEED package.\n  Please report the issue to the authors.\nThis warning is displayed once every 8 hours.\nCall `lifecycle::last_lifecycle_warnings()` to see where this warning was\ngenerated. \n2: The `slot` argument of `SetAssayData()` is deprecated as of SeuratObject 5.0.0.\n\u2139 Please use the `layer` argument instead.\n\u2139 The deprecated feature was likely used in the scDEED package.\n  Please report the issue to the authors.\nThis warning is displayed once every 8 hours.\nCall `lifecycle::last_lifecycle_warnings()` to see where this warning was\ngenerated. \n</pre> In\u00a0[6]: Copied! <pre>from distortions.geometry import Geometry, bind_metric, local_distortions\n\ngeom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": 20}, adjacency_kwds={\"radius\": 50}, laplacian_kwds={\"scaling_epps\": 5})\nH, Hvv, Hs = local_distortions(embeddings, normalized_counts, geom)\nembeddings = bind_metric(embeddings, Hvv, Hs)\nN = rpy2.robjects.globalenv[\"N\"]\nN_dict = {int(key): list(val) for key, val in N.items()}\n</pre> from distortions.geometry import Geometry, bind_metric, local_distortions  geom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": 20}, adjacency_kwds={\"radius\": 50}, laplacian_kwds={\"scaling_epps\": 5}) H, Hvv, Hs = local_distortions(embeddings, normalized_counts, geom) embeddings = bind_metric(embeddings, Hvv, Hs) N = rpy2.robjects.globalenv[\"N\"] N_dict = {int(key): list(val) for key, val in N.items()} In\u00a0[7]: Copied! <pre>from distortions.visualization import dplot\n\nplots = {}\nplots[\"scdeed_distort\"] = dplot(embeddings, width=440, height=440)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\")\\\n    .geom_ellipse(radiusMax=10, radiusMin=1)\\\n    .inter_edge_link(N=N_dict, stroke=\"#F25E7A\", highlightColor=\"#C83F58\", strokeWidth=.4, highlightStrokeWidth=5, threshold=10, backgroundOpacity=0.5)\n</pre> from distortions.visualization import dplot  plots = {} plots[\"scdeed_distort\"] = dplot(embeddings, width=440, height=440)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\")\\     .geom_ellipse(radiusMax=10, radiusMin=1)\\     .inter_edge_link(N=N_dict, stroke=\"#F25E7A\", highlightColor=\"#C83F58\", strokeWidth=.4, highlightStrokeWidth=5, threshold=10, backgroundOpacity=0.5) In\u00a0[8]: Copied! <pre>#[p.save(f\"../paper/figures/{k}.svg\") for k, p in plots.items()]\n</pre> #[p.save(f\"../paper/figures/{k}.svg\") for k, p in plots.items()] In\u00a0[9]: Copied! <pre>[display(p) for p in plots.values()]\n</pre> [display(p) for p in plots.values()] <pre>dplot(dataset=[{'embedding_0': 5.783105882455072, 'embedding_1': -12.634558999702302, 'x0': -0.303412665270283\u2026</pre> Out[9]: <pre>[None]</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorials/fixed_transform.html","title":"Understanding Isometrization with a Known Transformation","text":"In\u00a0[1]: Copied! <pre>import random\nimport numpy as np\nimport pandas as pd\nrandom.seed(20250409)\n\nN = 500\nu = np.random.uniform(0, 1, (N, 2))\nu_df = pd.DataFrame(u, columns=['x', 'y'])\n</pre> import random import numpy as np import pandas as pd random.seed(20250409)  N = 500 u = np.random.uniform(0, 1, (N, 2)) u_df = pd.DataFrame(u, columns=['x', 'y']) In\u00a0[2]: Copied! <pre>from distortions.geometry import bind_metric\nfrom distortions.visualization import dplot\n\ndef plot_transformation(f, H, Hvv, Hs, transformation_bw=2, metric_bw=20, width=450, height=450, radiusMin=1, radiusMax=10):\n    combined_df = bind_metric(f, Hvv, Hs)\n    combined_df[\"id\"] = combined_df.index\n\n    f_df = pd.DataFrame(f, columns=['x', 'y'])\n    embed_dict = {}\n    for n in range(len(f_df)):\n        embed_dict[n] = f_df.iloc[n, :]\n        embed_dict[n][\"id\"] = n\n\n    h_dict = {k: H[k] for k in range(len(H))}\n    return dplot(combined_df, width=width, height=height, labelFontSize=14)\\\n        .mapping(x=\"embedding_0\", y=\"embedding_1\")\\\n        .geom_ellipse(radiusMin=radiusMin, radiusMax=radiusMax, opacity=0.8)\\\n        .inter_isometry(metrics=h_dict, otherClasses=[\"ellipse\"], transformation_bw=transformation_bw, metric_bw=metric_bw, opacity=0.4, stroke=\"#c6c6c6\", strokeWidth=1.5)\\\n        .labs(x=\"x-axis\", y=\"y-axis\")\n</pre> from distortions.geometry import bind_metric from distortions.visualization import dplot  def plot_transformation(f, H, Hvv, Hs, transformation_bw=2, metric_bw=20, width=450, height=450, radiusMin=1, radiusMax=10):     combined_df = bind_metric(f, Hvv, Hs)     combined_df[\"id\"] = combined_df.index      f_df = pd.DataFrame(f, columns=['x', 'y'])     embed_dict = {}     for n in range(len(f_df)):         embed_dict[n] = f_df.iloc[n, :]         embed_dict[n][\"id\"] = n      h_dict = {k: H[k] for k in range(len(H))}     return dplot(combined_df, width=width, height=height, labelFontSize=14)\\         .mapping(x=\"embedding_0\", y=\"embedding_1\")\\         .geom_ellipse(radiusMin=radiusMin, radiusMax=radiusMax, opacity=0.8)\\         .inter_isometry(metrics=h_dict, otherClasses=[\"ellipse\"], transformation_bw=transformation_bw, metric_bw=metric_bw, opacity=0.4, stroke=\"#c6c6c6\", strokeWidth=1.5)\\         .labs(x=\"x-axis\", y=\"y-axis\") In\u00a0[3]: Copied! <pre>H = np.zeros((N, 2, 2))\nHvv = np.zeros((N, 2, 2))\nHs = np.zeros((N, 2))\n\nfor i in range(N):\n    H[i] = np.array([[1, 0], [0, 1]])\n    Hvv[i] = np.eye(2)\n    Hs[i] = [1, 1]\n</pre> H = np.zeros((N, 2, 2)) Hvv = np.zeros((N, 2, 2)) Hs = np.zeros((N, 2))  for i in range(N):     H[i] = np.array([[1, 0], [0, 1]])     Hvv[i] = np.eye(2)     Hs[i] = [1, 1] In\u00a0[4]: Copied! <pre>plots = {}\nplots[\"original\"] = plot_transformation(u, H, Hvv, Hs)\n</pre> plots = {} plots[\"original\"] = plot_transformation(u, H, Hvv, Hs) In\u00a0[5]: Copied! <pre>f = u.copy()\nf[:, 1] = f[:, 1] ** 2\n</pre> f = u.copy() f[:, 1] = f[:, 1] ** 2 In\u00a0[6]: Copied! <pre>plots[\"transformed\"] = plot_transformation(f, H, Hvv, Hs)\n</pre> plots[\"transformed\"] = plot_transformation(f, H, Hvv, Hs) In\u00a0[7]: Copied! <pre>for i in range(N):\n    H[i] = np.array([[1, 0], [0, 2 * f[i, 1]]])\n    Hvv[i] = np.eye(2)\n    Hs[i] = [1, 2 * f[i, 1]]\n\nplots[\"distortion\"] = plot_transformation(f, H, Hvv, Hs)\n</pre> for i in range(N):     H[i] = np.array([[1, 0], [0, 2 * f[i, 1]]])     Hvv[i] = np.eye(2)     Hs[i] = [1, 2 * f[i, 1]]  plots[\"distortion\"] = plot_transformation(f, H, Hvv, Hs) In\u00a0[8]: Copied! <pre>#[p.save(f\"../paper/figures/{k}.svg\") for k, p in plots.items()]\n</pre> #[p.save(f\"../paper/figures/{k}.svg\") for k, p in plots.items()] In\u00a0[9]: Copied! <pre>[display(p) for p in plots.values()]\n</pre> [display(p) for p in plots.values()] <pre>dplot(dataset=[{'embedding_0': 0.8448678500972645, 'embedding_1': 0.8949533007524632, 'x0': 1.0, 'y0': 0.0, 'x\u2026</pre> <pre>dplot(dataset=[{'embedding_0': 0.8448678500972645, 'embedding_1': 0.8009414105277287, 'x0': 1.0, 'y0': 0.0, 'x\u2026</pre> <pre>dplot(dataset=[{'embedding_0': 0.8448678500972645, 'embedding_1': 0.8009414105277287, 'x0': 1.0, 'y0': 0.0, 'x\u2026</pre> Out[9]: <pre>[None, None, None]</pre>"},{"location":"tutorials/hydra-80.html","title":"Comparing t-SNE Hyperparameters in the Hydra Atlas","text":"In\u00a0[1]: Copied! <pre>import random\nimport scanpy as sc\nimport numpy as np\nimport urllib.request\nimport tempfile\nrandom.seed(20250409)\n\ntemp_file = tempfile.mktemp(suffix=\".h5ad\")\nurllib.request.urlretrieve(\"https://uwmadison.box.com/shared/static/gp1d9akvyq5r7a0rzxw27n86zlqe0d7f.h5ad\", temp_file)\nadata = sc.read_h5ad(temp_file)\nadata.X = adata.X.todense()\n\nsc.pp.normalize_total(adata)\nsc.pp.log1p(adata)\nsc.pp.highly_variable_genes(adata, n_top_genes=1000)\n\nn_neighbors = 50\nix = np.random.choice(len(adata), 2000, replace=False)\nadata = adata[ix, adata.var.highly_variable]\nsc.pp.neighbors(adata, n_neighbors=n_neighbors)\nsc.tl.tsne(adata, n_pcs=30, perplexity=500)\n</pre> import random import scanpy as sc import numpy as np import urllib.request import tempfile random.seed(20250409)  temp_file = tempfile.mktemp(suffix=\".h5ad\") urllib.request.urlretrieve(\"https://uwmadison.box.com/shared/static/gp1d9akvyq5r7a0rzxw27n86zlqe0d7f.h5ad\", temp_file) adata = sc.read_h5ad(temp_file) adata.X = adata.X.todense()  sc.pp.normalize_total(adata) sc.pp.log1p(adata) sc.pp.highly_variable_genes(adata, n_top_genes=1000)  n_neighbors = 50 ix = np.random.choice(len(adata), 2000, replace=False) adata = adata[ix, adata.var.highly_variable] sc.pp.neighbors(adata, n_neighbors=n_neighbors) sc.tl.tsne(adata, n_pcs=30, perplexity=500) In\u00a0[2]: Copied! <pre>from distortions.geometry import Geometry, bind_metric, local_distortions\n\nembedding = adata.obsm[\"X_tsne\"].copy()\nradius = 3 * np.mean(adata.obsp[\"distances\"].data)\ngeom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": 5})\nH, Hvv, Hs = local_distortions(embedding, adata.X, geom)\nembedding = bind_metric(embedding, Hvv, Hs)\nembedding[\"ident\"] = adata.obs[\"ident\"].str.split(\"-\").str[1].values\n</pre> from distortions.geometry import Geometry, bind_metric, local_distortions  embedding = adata.obsm[\"X_tsne\"].copy() radius = 3 * np.mean(adata.obsp[\"distances\"].data) geom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": 5}) H, Hvv, Hs = local_distortions(embedding, adata.X, geom) embedding = bind_metric(embedding, Hvv, Hs) embedding[\"ident\"] = adata.obs[\"ident\"].str.split(\"-\").str[1].values In\u00a0[3]: Copied! <pre>import altair as alt\nalt.data_transformers.enable(\"vegafusion\")\n\nalt.Chart(embedding).mark_circle(opacity=1).encode(\n    x=alt.X(\"embedding_0\"),\n    y=alt.Y(\"embedding_1\")\n).properties(width=400, height=400)\n</pre> import altair as alt alt.data_transformers.enable(\"vegafusion\")  alt.Chart(embedding).mark_circle(opacity=1).encode(     x=alt.X(\"embedding_0\"),     y=alt.Y(\"embedding_1\") ).properties(width=400, height=400) Out[3]: In\u00a0[4]: Copied! <pre>from distortions.visualization import dplot\nfrom distortions.geometry import neighborhoods\n\nplots = {}\nN = neighborhoods(adata, threshold=.2, outlier_factor=3, embed_key=\"X_tsne\", frame=[100, 100], method=\"window\")\nplots[\"hydra_link_80\"] = dplot(embedding, width=440, height=440)\\\n   .mapping(x=\"embedding_0\", y=\"embedding_1\")\\\n   .inter_edge_link(N=N, threshold=3, stroke=\"#F25E7A\", highlightColor=\"#F25E7A\", backgroundOpacity=0.2, strokeWidth=0.2, opacity=0.6)\\\n   .geom_ellipse(radiusMax=10, radiusMin=.8)\\\n   .labs(x=\"t-SNE 1\", y=\"t-SNE 2\")\nplots[\"hydra_link_80\"]\n</pre> from distortions.visualization import dplot from distortions.geometry import neighborhoods  plots = {} N = neighborhoods(adata, threshold=.2, outlier_factor=3, embed_key=\"X_tsne\", frame=[100, 100], method=\"window\") plots[\"hydra_link_80\"] = dplot(embedding, width=440, height=440)\\    .mapping(x=\"embedding_0\", y=\"embedding_1\")\\    .inter_edge_link(N=N, threshold=3, stroke=\"#F25E7A\", highlightColor=\"#F25E7A\", backgroundOpacity=0.2, strokeWidth=0.2, opacity=0.6)\\    .geom_ellipse(radiusMax=10, radiusMin=.8)\\    .labs(x=\"t-SNE 1\", y=\"t-SNE 2\") plots[\"hydra_link_80\"] Out[4]: <pre>dplot(dataset=[{'embedding_0': -5.127078056335449, 'embedding_1': -6.697624206542969, 'x0': -0.833874391295024\u2026</pre> In\u00a0[5]: Copied! <pre>metrics = {k: H[k] / H.mean() for k in range(len(H))}\nplots[\"hydra_isometry\"] = dplot(embedding, width=440, height=440)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\")\\\n    .inter_isometry(metrics=metrics, metrics_bw=.05, transformation_bw=.1, stroke=\"#dcdcdc\")\\\n    .geom_ellipse(radiusMax=10, radiusMin=.8)\\\n    .labs(x=\"t-SNE 1\", y=\"t-SNE 2\")\nplots[\"hydra_isometry\"]\n</pre> metrics = {k: H[k] / H.mean() for k in range(len(H))} plots[\"hydra_isometry\"] = dplot(embedding, width=440, height=440)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\")\\     .inter_isometry(metrics=metrics, metrics_bw=.05, transformation_bw=.1, stroke=\"#dcdcdc\")\\     .geom_ellipse(radiusMax=10, radiusMin=.8)\\     .labs(x=\"t-SNE 1\", y=\"t-SNE 2\") plots[\"hydra_isometry\"] Out[5]: <pre>dplot(dataset=[{'embedding_0': -5.127078056335449, 'embedding_1': -6.697624206542969, 'x0': -0.833874391295024\u2026</pre> In\u00a0[6]: Copied! <pre>from distortions.geometry import neighborhood_distances\n\ndists = neighborhood_distances(adata, embed_key=\"X_tsne\")\nplots[\"hydra_boxplot\"] = dplot(embedding, width=550, height=440)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\")\\\n    .geom_ellipse(radiusMax=8, radiusMin=.5)\\\n    .inter_boxplot(dists=dists, strokeWidth=0.2)\\\n    .labs(x = \"t-SNE 1\", y = \"t-SNE 2\")\nplots[\"hydra_boxplot\"]\n</pre> from distortions.geometry import neighborhood_distances  dists = neighborhood_distances(adata, embed_key=\"X_tsne\") plots[\"hydra_boxplot\"] = dplot(embedding, width=550, height=440)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\")\\     .geom_ellipse(radiusMax=8, radiusMin=.5)\\     .inter_boxplot(dists=dists, strokeWidth=0.2)\\     .labs(x = \"t-SNE 1\", y = \"t-SNE 2\") plots[\"hydra_boxplot\"] Out[6]: <pre>dplot(dataset=[{'embedding_0': -5.127078056335449, 'embedding_1': -6.697624206542969, 'x0': -0.833874391295024\u2026</pre> In\u00a0[7]: Copied! <pre>#[p.save(f\"../paper/figures/{k}.svg\") for k, p in plots.items()]\n</pre> #[p.save(f\"../paper/figures/{k}.svg\") for k, p in plots.items()] In\u00a0[8]: Copied! <pre>[display(p) for p in plots.values()]\n</pre> [display(p) for p in plots.values()] <pre>dplot(dataset=[{'embedding_0': -5.127078056335449, 'embedding_1': -6.697624206542969, 'x0': -0.833874391295024\u2026</pre> <pre>dplot(dataset=[{'embedding_0': -5.127078056335449, 'embedding_1': -6.697624206542969, 'x0': -0.833874391295024\u2026</pre> <pre>dplot(dataset=[{'embedding_0': -5.127078056335449, 'embedding_1': -6.697624206542969, 'x0': -0.833874391295024\u2026</pre> Out[8]: <pre>[None, None, None]</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorials/link_data.html","title":"Analyzing Topology Failures with Interlocking Links","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport pandas as pd\nfrom distortions.geometry import Geometry, bind_metric, local_distortions\n</pre> import numpy as np import pandas as pd from distortions.geometry import Geometry, bind_metric, local_distortions In\u00a0[2]: Copied! <pre>import math\n    \ndef rotate(x, y, z):\n    u = x\n    cos_val = math.cos(0.4)\n    sin_val = math.sin(0.4)\n    v = cos_val * y + sin_val * z\n    w = -sin_val * y + cos_val * z\n    return [u, v, w]\n\ndef link_data(n, offset=1):\n    \"\"\"\n    https://github.com/kevinrobinson/umap-playground/blob/master/public/assets/demo-datas.js#L311\n    \"\"\"\n    points = []\n    for i in range(n):\n        t = 2 * math.pi * i / n\n        sin_t = math.sin(t)\n        cos_t = math.cos(t)\n        points.append(rotate(cos_t, sin_t, 0))\n        points.append(rotate(offset + cos_t, 0, sin_t))\n    \n    return np.array(points)\n</pre> import math      def rotate(x, y, z):     u = x     cos_val = math.cos(0.4)     sin_val = math.sin(0.4)     v = cos_val * y + sin_val * z     w = -sin_val * y + cos_val * z     return [u, v, w]  def link_data(n, offset=1):     \"\"\"     https://github.com/kevinrobinson/umap-playground/blob/master/public/assets/demo-datas.js#L311     \"\"\"     points = []     for i in range(n):         t = 2 * math.pi * i / n         sin_t = math.sin(t)         cos_t = math.cos(t)         points.append(rotate(cos_t, sin_t, 0))         points.append(rotate(offset + cos_t, 0, sin_t))          return np.array(points) In\u00a0[3]: Copied! <pre>from anndata import AnnData\nimport scanpy as sc\n\nM = 100\nn_neighbors = 50\ndata = link_data(M)\n\nadata = AnnData(X=data, obs=pd.DataFrame(range(2 * M)))\nsc.pp.neighbors(adata, n_neighbors=50)\nsc.tl.umap(adata)\nembedding = adata.obsm[\"X_umap\"].copy()\n</pre> from anndata import AnnData import scanpy as sc  M = 100 n_neighbors = 50 data = link_data(M)  adata = AnnData(X=data, obs=pd.DataFrame(range(2 * M))) sc.pp.neighbors(adata, n_neighbors=50) sc.tl.umap(adata) embedding = adata.obsm[\"X_umap\"].copy() In\u00a0[4]: Copied! <pre>radius = 3 * np.mean(adata.obsp[\"distances\"].data)\ngeom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": 5})\nH, Hvv, Hs = local_distortions(embedding, data, geom)\nembedding = bind_metric(embedding, Hvv, Hs)\nembedding[\"x_orig\"] = data[:, 0]\n</pre> radius = 3 * np.mean(adata.obsp[\"distances\"].data) geom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": 5}) H, Hvv, Hs = local_distortions(embedding, data, geom) embedding = bind_metric(embedding, Hvv, Hs) embedding[\"x_orig\"] = data[:, 0] In\u00a0[5]: Copied! <pre>from distortions.geometry import neighborhoods\nfrom distortions.visualization import dplot\n\nN = neighborhoods(adata, threshold=0.01, outlier_factor=2)\ndplot(embedding, width=900, height=500)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"x_orig\")\\\n    .inter_edge_link(N=N, threshold=1)\\\n    .geom_ellipse()\\\n    .scale_color()\n</pre> from distortions.geometry import neighborhoods from distortions.visualization import dplot  N = neighborhoods(adata, threshold=0.01, outlier_factor=2) dplot(embedding, width=900, height=500)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"x_orig\")\\     .inter_edge_link(N=N, threshold=1)\\     .geom_ellipse()\\     .scale_color() Out[5]: <pre>dplot(dataset=[{'embedding_0': 9.539716720581055, 'embedding_1': 3.1580326557159424, 'x0': -0.8638632514305921\u2026</pre> In\u00a0[6]: Copied! <pre>plots = []\nfor offset in np.linspace(0.5, 2.5, 5):\n\n    data = link_data(M, offset=offset)\n    adata = AnnData(X=data, obs=pd.DataFrame(range(2 * M)))\n    sc.pp.neighbors(adata, n_neighbors=50)\n    sc.tl.umap(adata)\n    embedding = adata.obsm[\"X_umap\"].copy()\n\n    H, Hvv, Hs = local_distortions(embedding, data, geom)\n    embedding = bind_metric(embedding, Hvv, Hs)\n    embedding[\"x_orig\"] = data[:, 0]\n\n    N = neighborhoods(adata, threshold=0.2, outlier_factor=2)\n    metrics = {k: H[k] for k in range(len(H))}\n    plots += [dplot(embedding, width=400, height=400)\\\n        .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"x_orig\")\\\n        .geom_ellipse()\\\n        .inter_edge_link(N=N, threshold=1)\\\n        .labs(title=f\"{offset} Units Apart\")\\\n        .scale_color()]\n</pre> plots = [] for offset in np.linspace(0.5, 2.5, 5):      data = link_data(M, offset=offset)     adata = AnnData(X=data, obs=pd.DataFrame(range(2 * M)))     sc.pp.neighbors(adata, n_neighbors=50)     sc.tl.umap(adata)     embedding = adata.obsm[\"X_umap\"].copy()      H, Hvv, Hs = local_distortions(embedding, data, geom)     embedding = bind_metric(embedding, Hvv, Hs)     embedding[\"x_orig\"] = data[:, 0]      N = neighborhoods(adata, threshold=0.2, outlier_factor=2)     metrics = {k: H[k] for k in range(len(H))}     plots += [dplot(embedding, width=400, height=400)\\         .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"x_orig\")\\         .geom_ellipse()\\         .inter_edge_link(N=N, threshold=1)\\         .labs(title=f\"{offset} Units Apart\")\\         .scale_color()] In\u00a0[7]: Copied! <pre>[display(p) for p in plots]\n</pre> [display(p) for p in plots] <pre>dplot(dataset=[{'embedding_0': 3.289219617843628, 'embedding_1': 13.244303703308105, 'x0': -0.6242006037121905\u2026</pre> <pre>dplot(dataset=[{'embedding_0': 9.539716720581055, 'embedding_1': 3.1580326557159424, 'x0': -0.8638632514305921\u2026</pre> <pre>dplot(dataset=[{'embedding_0': 12.08263111114502, 'embedding_1': 9.085368156433105, 'x0': -0.4536952649302679,\u2026</pre> <pre>dplot(dataset=[{'embedding_0': 0.22946549952030182, 'embedding_1': 0.14115360379219055, 'x0': -0.5723637280364\u2026</pre> <pre>dplot(dataset=[{'embedding_0': 7.340658664703369, 'embedding_1': 4.244654655456543, 'x0': -0.8520414657269931,\u2026</pre> Out[7]: <pre>[None, None, None, None, None]</pre>"},{"location":"tutorials/mammoth.html","title":"Analyzing Fragmentation in a Flattened Mammoth","text":"<p>This notebook considers a famous wooly mammoth dataset, which has been used to show the types of artifacts that can be introduced by UMAP [1, 2]. Each row of the data set below corresponds to a readout from a 3D point cloud scan of a woolly mammoth skeleton. Since the data are only three-dimensional, we can visualize the raw data. Nonetheless for being relatively low dimensional, it can still be challenging for UMAP to both (1) preserve the global geometry of the skeleton and (2) capture subtleties in the relationship between individual bones.</p> In\u00a0[1]: Copied! <pre>import numpy as np\nimport pandas as pd\n\ndata = pd.read_json(\"https://raw.githubusercontent.com/krisrs1128/distortions-data/main/data/mammoth_3d.json\")\ndata.columns = [\"x\", \"y\", \"z\"]\n</pre> import numpy as np import pandas as pd  data = pd.read_json(\"https://raw.githubusercontent.com/krisrs1128/distortions-data/main/data/mammoth_3d.json\") data.columns = [\"x\", \"y\", \"z\"] <p>We first run a new map with the 50 nearest neighbor graph. We are using the scanpy package just for consistency with the other notebooks. In principle, we could've also used the ordinary umap package.</p> In\u00a0[2]: Copied! <pre>from anndata import AnnData\nimport scanpy as sc\n\nn_neighbors = 50\nadata = AnnData(X=data, obs=pd.DataFrame(index=data.index))\nsc.pp.neighbors(adata, n_neighbors=n_neighbors)\nsc.tl.umap(adata)\nembedding = adata.obsm[\"X_umap\"].copy()\n</pre> from anndata import AnnData import scanpy as sc  n_neighbors = 50 adata = AnnData(X=data, obs=pd.DataFrame(index=data.index)) sc.pp.neighbors(adata, n_neighbors=n_neighbors) sc.tl.umap(adata) embedding = adata.obsm[\"X_umap\"].copy() <p>In the block below, we estimate the local distortion associated with each point in the point cloud. This estimation step hinges on the geometry object. This is exactly like the geometry objects defined in the megaman package, and it is used to define the intrinsic geometry of the manifold from which the data are assumed to be sampled. This depends on hyperparameters. We have set the number of neighbors to equal the number of neighbors in UMAP, and we have set the radius to be a small multiple of the typical neighborhood distance. We have found these to be reasonable defaults, but still encourage you to test sensitivity, especially to the radius and $\\epsilon$ scaling parameter.</p> In\u00a0[3]: Copied! <pre>from distortions.geometry import Geometry, bind_metric, local_distortions\n\nradius = 3 * np.mean(adata.obsp[\"distances\"].data)\ngeom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": 5})\nH, Hvv, Hs = local_distortions(embedding, data, geom)\nembedding = bind_metric(embedding, Hvv, Hs)\n</pre> from distortions.geometry import Geometry, bind_metric, local_distortions  radius = 3 * np.mean(adata.obsp[\"distances\"].data) geom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": 5}) H, Hvv, Hs = local_distortions(embedding, data, geom) embedding = bind_metric(embedding, Hvv, Hs) <p>Before visualizing distortion, let's visualize the 3D skeleton and analyze the output of dimensional reduction without any overlays. The block below is partly to draw a 3D scatterplot of the mammoth skeleton. Notice some of the subtleties. The tusks don't have even sampling density. The feet are slightly offset. There are small gaps on the left-hand side ribs near the back legs. On the legs, they're more points, sampled near the feet and the knees, then on the longer bones. There are also seem to be more points on the front legs compared to the back. The skull has a kind of bump near the top that's made of relatively few points. These are the kinds of details that exist in real data that we hope nonlinear dimensionality reduction should be able to capture.</p> In\u00a0[4]: Copied! <pre>import plotly\nimport plotly.express as px\n\nplotly.offline.init_notebook_mode()\nfig = px.scatter_3d(data, x='x', y='z', z='y')\nfig.update_traces(marker_size=1, marker_color=\"black\")\nfig\n</pre> import plotly import plotly.express as px  plotly.offline.init_notebook_mode() fig = px.scatter_3d(data, x='x', y='z', z='y') fig.update_traces(marker_size=1, marker_color=\"black\") fig <p>In the block below, we are visualizing the results of UMAP applied to these 3D data. The correspondence is relatively clear we can see that the algorithm has preserved the global relationships between the parts of the mammoth. It's impressive that we still seem to preserve the ribs and even the distinction between some toes at least on the front legs. But we can also immediately recognize some distortion. The tasks are uneven lengths here, even though they're relatively even in the original data. The tail looks like it's contained inside of the pelvis. The symmetry between the ribs seems a bit off. Indeed, the entire shoulder area appears to be a bit \"broken.\"</p> In\u00a0[5]: Copied! <pre>import altair as alt\nalt.data_transformers.enable(\"vegafusion\")\n\nalt.Chart(embedding).mark_circle(color=\"black\").encode(\n    x=alt.X(\"embedding_0\"),\n    y=alt.Y(\"embedding_1\")\n).properties(width=450, height=350)\n</pre> import altair as alt alt.data_transformers.enable(\"vegafusion\")  alt.Chart(embedding).mark_circle(color=\"black\").encode(     x=alt.X(\"embedding_0\"),     y=alt.Y(\"embedding_1\") ).properties(width=450, height=350) Out[5]: <p>We can get a sense of the global distortion by plotting the embedding distance between points against the original distances in 3D. What we see here -- and it's relatively common across many examples we've studied -- is that the embedding distances are quite skewed to the right. The embedding pairwise distance is due increase with the original pairwise distances, but there's a long tail of outliers. These are points that are far apart in the embedding, but which close in the original data. This visualization is static, but we'll see how we can query the specific outliers in our interactive pots.</p> In\u00a0[6]: Copied! <pre>from distortions.geometry import neighborhood_distances\n\ndistances = neighborhood_distances(adata)\nalt.Chart(distances).mark_boxplot(outliers=True).encode(\n    x=alt.X('true', bin={\"maxbins\": 20}),\n    y=alt.Y('embedding')\n)\n</pre> from distortions.geometry import neighborhood_distances  distances = neighborhood_distances(adata) alt.Chart(distances).mark_boxplot(outliers=True).encode(     x=alt.X('true', bin={\"maxbins\": 20}),     y=alt.Y('embedding') ) Out[6]: <p>We now move to the interactive visualizations specific to the distortions package. Our first plot will highlight the fragmented neighborhoods. These are points that are highly separated from their neighbors in the embedding space. The intuition roughly correspondence to the boxplot from above. Roughly, for any point, we evaluate the fraction of its neighbors whose distances are outlying in those box plots, and if a large enough fraction or outliers, we consider the neighborhood around that point to be fragmented. More formally in the code below we look for points where at least 30% of its neighbors are three IQRs away from the median embedding distance across the bins associated with those neighbors. Moving your mouse close to any of these neighborhoods will draw edges to the original neighbors used to define the UMAP. This interactivity is defined by the inter_edge_link layer. The other layers are used should define the static ellipse visualization.</p> In\u00a0[\u00a0]: Copied! <pre>from distortions.geometry import neighborhoods\nfrom distortions.visualization import dplot\n\nplots = {}\nN = neighborhoods(adata, threshold=.1, outlier_factor=3)\nplots[\"mammoth_links\"] = dplot(embedding, height = 350, width=450)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\")\\\n    .inter_edge_link(N=N, strokeWidth=.2, opacity=0.7, threshold=10, stroke=\"#F25E7A\", highlightColor=\"#C83F58\")\\\n    .geom_ellipse(opacity=0.8, radiusMin=.5, radiusMax=10)\\\n    .labs(x=\"UMAP1\", y=\"UMAP2\")\nplots[\"mammoth_links\"]\n</pre> from distortions.geometry import neighborhoods from distortions.visualization import dplot  plots = {} N = neighborhoods(adata, threshold=.1, outlier_factor=3) plots[\"mammoth_links\"] = dplot(embedding, height = 350, width=450)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\")\\     .inter_edge_link(N=N, strokeWidth=.2, opacity=0.7, threshold=10, stroke=\"#F25E7A\", highlightColor=\"#C83F58\")\\     .geom_ellipse(opacity=0.8, radiusMin=.5, radiusMax=10)\\     .labs(x=\"UMAP1\", y=\"UMAP2\") plots[\"mammoth_links\"] <p></p> <p>Next let's make an isometry visualization. As we hover our mouse over neighborhoods of the skeleton, the embedding resizes itself, so that distances are relatively balanced across all directions. The ellipses also change in size, those close to the mouse become more and more like circles. The main idea of this visualization is that even though all embedding must distort distances in order to reduce dimension, we can try to locally reduce distortion around the region of a mouse query. One thing to be careful of is that sometimes the singular values of each can be quite small. This can lead to the interaction, causing areas to enlarge dramatically. In our manuscript, we sometimes windsorize the singular values. For simplicity, we've avoided this step here, but the PBMC and two clusters examples both show how to do that transformation.</p> In\u00a0[\u00a0]: Copied! <pre>metrics = {k: H[k] / H.std() for k in range(len(H))}\nplots[\"mammoth_isometry\"] = dplot(embedding, height=350, width=450)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\")\\\n    .inter_isometry(metrics=metrics, transformation_bw=.5, metric_bw=.1)\\\n    .geom_ellipse(opacity=0.8, radiusMin=.5, radiusMax=10)\\\n    .labs(x=\"UMAP1\", y=\"UMAP2\")\nplots[\"mammoth_isometry\"]\n</pre> metrics = {k: H[k] / H.std() for k in range(len(H))} plots[\"mammoth_isometry\"] = dplot(embedding, height=350, width=450)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\")\\     .inter_isometry(metrics=metrics, transformation_bw=.5, metric_bw=.1)\\     .geom_ellipse(opacity=0.8, radiusMin=.5, radiusMax=10)\\     .labs(x=\"UMAP1\", y=\"UMAP2\") plots[\"mammoth_isometry\"] <p></p> <p>Finally, let's make an interactive version of the boxplot that we had before. The widget on the top right allows us to select edges that are outlying in the boxplot by drawing a brush over them (click and draw this region). The corresponding neighbors light up whenever the edge connecting them is covered by the brush. The points near the top left of the box plot are the most distorted edges. These should be very close to each other, according to their original distances but have been placed for the embedding. To change the number of outliers is that are available for selection, you can change the outlier_iqr argument of the inter_boxplot layer. Larger values will make it so that fewer points appear for selection.</p> In\u00a0[\u00a0]: Copied! <pre>plots[\"mammoth_box\"] = dplot(embedding, height=350, width=530)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\")\\\n    .geom_ellipse(radiusMax=10, radiusMin=.5)\\\n    .inter_boxplot(dists=distances, outlier_iqr=10, highlightColor=\"#F25E7A\", strokeWidth=0.4)\\\n    .labs(x=\"UMAP1\", y=\"UMAP2\")\nplots[\"mammoth_box\"]\n</pre> plots[\"mammoth_box\"] = dplot(embedding, height=350, width=530)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\")\\     .geom_ellipse(radiusMax=10, radiusMin=.5)\\     .inter_boxplot(dists=distances, outlier_iqr=10, highlightColor=\"#F25E7A\", strokeWidth=0.4)\\     .labs(x=\"UMAP1\", y=\"UMAP2\") plots[\"mammoth_box\"] <p></p> In\u00a0[16]: Copied! <pre>[display(p) for p in plots.values()]\n</pre> [display(p) for p in plots.values()] <pre>dplot(dataset=[{'embedding_0': 8.870267868041992, 'embedding_1': 0.8856074810028076, 'x0': -0.8852808564862759\u2026</pre> <pre>dplot(dataset=[{'embedding_0': 8.870267868041992, 'embedding_1': 0.8856074810028076, 'x0': -0.8852808564862759\u2026</pre> <pre>dplot(dataset=[{'embedding_0': 8.870267868041992, 'embedding_1': 0.8856074810028076, 'x0': -0.8852808564862759\u2026</pre> Out[16]: <pre>[None, None, None]</pre> In\u00a0[11]: Copied! <pre>#[p.save(f\"../paper/figures/{k}.svg\") for k, p in plots.items()]\n</pre> #[p.save(f\"../paper/figures/{k}.svg\") for k, p in plots.items()] In\u00a0[12]: Copied! <pre>len(N)\n</pre> len(N) Out[12]: <pre>425</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorials/mammoth.html#data-preparation","title":"Data Preparation\u00b6","text":""},{"location":"tutorials/mammoth.html#static-visualizations","title":"Static Visualizations\u00b6","text":""},{"location":"tutorials/mammoth.html#interactive-visualizations","title":"Interactive Visualizations\u00b6","text":""},{"location":"tutorials/pbmc.html","title":"PBMC Atlas","text":"<p>This notebook looks at the <code>scanpy</code> classic dimensionality reduction tutorial from the distortion estimation point of view. We'll apply the UMAP and cell type clustering routines and then create some interactive figures that show how cell types can have systematically different distortion properties. If you want to see what this looks like in <code>scanpy</code>'s new plotting workflow just replace the <code>sc.datasets.pbmc3k_processed()</code> call below with <code>sc.datasets.pbmc68k_reduced()</code>.</p> In\u00a0[1]: Copied! <pre>import scanpy as sc\n\nadata = sc.datasets.pbmc3k_processed()\n</pre> import scanpy as sc  adata = sc.datasets.pbmc3k_processed() <pre>  0%|          | 0.00/23.5M [00:00&lt;?, ?B/s]</pre> <p>The block below looks like a lot of code, but it's mostly because we need to hard code the labels for different self clusters. The first four lines are the most important they run a new map with 50 nearest neighbors after PCA denoising. We then cluster those UMAP embeddings with the Leiden algorithm. We can get some more interpretable cell type annotations by referring to well known marker genes. This is what the <code>marker_gene_dict</code> and  <code>cluster2annotation</code> variables contain. None of these steps are really necessary for distortion estimation, but they'll allow us to put names on the differences between cell types, that will see below.</p> In\u00a0[2]: Copied! <pre>import random\nimport scanpy as sc\nrandom.seed(20250410)\n\nn_neighbors = 50\nsc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=40)\nsc.tl.umap(adata, init_pos = \"spectral\") # set to \"random\" for random initialization\nsc.tl.leiden(\n    adata,\n    key_added=\"clusters\",\n    resolution=0.5,\n    n_iterations=2,\n    flavor=\"igraph\",\n    directed=False,\n)\nmarker_genes_dict = {\n    \"B-cell\": [\"CD79A\", \"MS4A1\"],\n    \"Dendritic\": [\"FCER1A\", \"CST3\"],\n    \"Monocytes\": [\"FCGR3A\"],\n    \"NK\": [\"GNLY\", \"NKG7\"],\n    \"Other\": [\"IGLL1\"],\n    \"Plasma\": [\"IGJ\"],\n    \"T-cell\": [\"CD3D\"],\n}\n\ncluster2annotation = {\n    \"0\": \"Monocytes\",\n    \"1\": \"NK\",\n    \"2\": \"T-cell\",\n    \"3\": \"Dendritic\",\n    \"4\": \"Dendritic\",\n    \"5\": \"Plasma\",\n    \"6\": \"B-cell\",\n    \"7\": \"Dendritic\",\n    \"8\": \"Other\",\n}\n\nadata.obs[\"cell_type\"] = adata.obs[\"clusters\"].map(cluster2annotation).astype(\"category\")\n</pre> import random import scanpy as sc random.seed(20250410)  n_neighbors = 50 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=40) sc.tl.umap(adata, init_pos = \"spectral\") # set to \"random\" for random initialization sc.tl.leiden(     adata,     key_added=\"clusters\",     resolution=0.5,     n_iterations=2,     flavor=\"igraph\",     directed=False, ) marker_genes_dict = {     \"B-cell\": [\"CD79A\", \"MS4A1\"],     \"Dendritic\": [\"FCER1A\", \"CST3\"],     \"Monocytes\": [\"FCGR3A\"],     \"NK\": [\"GNLY\", \"NKG7\"],     \"Other\": [\"IGLL1\"],     \"Plasma\": [\"IGJ\"],     \"T-cell\": [\"CD3D\"], }  cluster2annotation = {     \"0\": \"Monocytes\",     \"1\": \"NK\",     \"2\": \"T-cell\",     \"3\": \"Dendritic\",     \"4\": \"Dendritic\",     \"5\": \"Plasma\",     \"6\": \"B-cell\",     \"7\": \"Dendritic\",     \"8\": \"Other\", }  adata.obs[\"cell_type\"] = adata.obs[\"clusters\"].map(cluster2annotation).astype(\"category\") <p>Now that we have the embedding, we can estimate the associated distortion. The array <code>H</code> below stores, the local distortion information associated with every single cell. The estimates come from the geometry function, which is exactly copied from the <code>megaman</code> package and which implement the algorithms described in this paper. This function unfortunately has a few hyperparameters, and that's because to estimate distortion we need to estimate a graph Laplacian. This provides a kind of ground truth manifold distance information -- in fact, there is strong theory to support the use of this object in estimating manifolds when the sample size increases to infinity. Unfortunately, with any finite amount of data, the estimate can depend on the hyper parameters in the function. We generally recommend setting the number of neighbors to be the same as the number of neighbors in the original embedding function, in this case 50. From there, we can set the radius to the a small multiple of the average distance between neighbors. The scaling epsilon parameter is usually a small number from one to 10 and it's purpose is to stabilize the values <code>H</code>. You might want to tinker it with it in case you're noticing an extreme range of ellipse sizes.</p> In\u00a0[3]: Copied! <pre>from distortions.geometry import Geometry, local_distortions\nimport numpy as np\n\nembedding = adata.obsm[\"X_umap\"].copy()\nradius = 3 * np.mean(adata.obsp[\"distances\"].data)\ngeom = Geometry(\"brute\", laplacian_method=\"geometric\", laplacian_kwds={\"scaling_epps\": 5}, adjacency_kwds={\"n_neighbors\": n_neighbors}, affinity_kwds={\"radius\": radius})\nH, Hvv, Hs = local_distortions(embedding, adata.X, geom)\n</pre> from distortions.geometry import Geometry, local_distortions import numpy as np  embedding = adata.obsm[\"X_umap\"].copy() radius = 3 * np.mean(adata.obsp[\"distances\"].data) geom = Geometry(\"brute\", laplacian_method=\"geometric\", laplacian_kwds={\"scaling_epps\": 5}, adjacency_kwds={\"n_neighbors\": n_neighbors}, affinity_kwds={\"radius\": radius}) H, Hvv, Hs = local_distortions(embedding, adata.X, geom) <p>Next would do some light postprocessing on the local distortion estimates. This is only necessary in this notebook because we want to illustrate the isometrization routine. Since the raw output H has a few outliers will try truncating them. This will make sure that those outliers don't dominate the visualization. We also re-normalize the singular values <code>Hs</code> according to their mean. This ensures that we aren't always contracting or always dilating regions of the visualization when we interact with it. Again this step is only necessary for the <code>inter_isometry</code> function below that implements isometrization.</p> In\u00a0[4]: Copied! <pre># postprocessing\n#Hs[Hs &gt; 8] = 8 # for random plot\nHs[Hs &gt; 2.5] = 2.5\nHs /= Hs.mean()\nfor i in range(len(H)):\n    H[i] = Hvv[i] @ np.diag(Hs[i]) @ Hvv[i].T\n</pre> # postprocessing #Hs[Hs &gt; 8] = 8 # for random plot Hs[Hs &gt; 2.5] = 2.5 Hs /= Hs.mean() for i in range(len(H)):     H[i] = Hvv[i] @ np.diag(Hs[i]) @ Hvv[i].T <p>Next, we add that local distortion information into our original embedding output. There's nothing really fancy going on in <code>bind_metric</code>. It's really just a wrapper of some pandas concatenation calls.</p> In\u00a0[5]: Copied! <pre>from distortions.geometry import bind_metric\n\nembedding = bind_metric(embedding, Hvv, Hs)\nembedding[\"cell_type\"] = adata.obs[\"cell_type\"].values\n</pre> from distortions.geometry import bind_metric  embedding = bind_metric(embedding, Hvv, Hs) embedding[\"cell_type\"] = adata.obs[\"cell_type\"].values <p>Before we do anything interactive, let's build some intuition about these outputs using some static visualizations. Our first is a plot is just a scatter pot of the UMAP embeddings. We see some clear structure that differentiates between different types of blood cells. The question is -- how reliable are these embeddings for making specific distance comparisons? From the raw output, we had no idea about house distances might be stretched or compressed locally, or whether distances between clusters accurately preserve the distances observed in the original high-dimensional data.</p> In\u00a0[6]: Copied! <pre>import altair as alt\n\nsort_order = [\"Monocytes\", \"NK\", \"T-cell\", \"Dendritic\", \"Plasma\", \"B-cell\", \"Other\"]\nalt.Chart(embedding).mark_circle().encode(\n    x=alt.X(\"embedding_0\"),\n    y=alt.Y(\"embedding_1\"),\n    color=alt.Color(\"cell_type\", sort=sort_order).scale(scheme=\"category10\")\n).properties(width=400, height=400)\\\n .configure_axis(grid=False)\n</pre> import altair as alt  sort_order = [\"Monocytes\", \"NK\", \"T-cell\", \"Dendritic\", \"Plasma\", \"B-cell\", \"Other\"] alt.Chart(embedding).mark_circle().encode(     x=alt.X(\"embedding_0\"),     y=alt.Y(\"embedding_1\"),     color=alt.Color(\"cell_type\", sort=sort_order).scale(scheme=\"category10\") ).properties(width=400, height=400)\\  .configure_axis(grid=False) Out[6]: <p>Let's now look at a less standard (but still static) plot. We'll compare the singular values from the local metrics estimated above. Please give a sense of the dilation and compression induced by the embedding locally around a cell. Ideally these would all be close to the identity of line meaning that no one direction along the true manifold is stretched more than any another. Here, though we noticed that often the x-axis (first singular value, $\\lambda_1$) is quite a bit larger than the y-axis (second singular value, $\\lambda_2$). The directions with the larger $\\lambda_{1}$ relative to $\\lambda_{2}$ have been stretched. We also noticed that the T-cells and some NK cells have the more severe distortion, since their x-axis values can be much larger than their y-axis values.</p> In\u00a0[7]: Copied! <pre>from distortions.visualization import eigenvalue_plot\n\nlambda_plot = eigenvalue_plot(\n    Hs, embedding[\"cell_type\"], \n    sort_order=[\"Monocytes\", \"NK\", \"T-cell\", \"Dendritic\", \"Plasma\", \"B-cell\", \"Other\"]\n).configure_axis(labelFontSize=12, titleFontSize=22)\\\n .configure_range(category=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])\n\n#lambda_plot.save(\"pbmc_lambda.svg\")\nlambda_plot\n</pre> from distortions.visualization import eigenvalue_plot  lambda_plot = eigenvalue_plot(     Hs, embedding[\"cell_type\"],      sort_order=[\"Monocytes\", \"NK\", \"T-cell\", \"Dendritic\", \"Plasma\", \"B-cell\", \"Other\"] ).configure_axis(labelFontSize=12, titleFontSize=22)\\  .configure_range(category=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])  #lambda_plot.save(\"pbmc_lambda.svg\") lambda_plot Out[7]: In\u00a0[8]: Copied! <pre>compression_mask = (Hs[:, 0] &lt; 1) &amp; (Hs[:, 1] &lt; 1)\nHs_zoom = Hs[compression_mask]\ncell_types_zoom = embedding[\"cell_type\"].iloc[compression_mask]\n\nlambda_plot_zoom = eigenvalue_plot(\n    Hs_zoom, cell_types_zoom, \n    sort_order=[\"Monocytes\", \"NK\", \"T-cell\", \"Dendritic\", \"Plasma\", \"B-cell\", \"Other\"]\n).configure_axis(labelFontSize=12, titleFontSize=22)\\\n .configure_range(category=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])\n\n#lambda_plot_zoom.save(\"pbmc_lambda_zoom.svg\")\nlambda_plot_zoom\n</pre> compression_mask = (Hs[:, 0] &lt; 1) &amp; (Hs[:, 1] &lt; 1) Hs_zoom = Hs[compression_mask] cell_types_zoom = embedding[\"cell_type\"].iloc[compression_mask]  lambda_plot_zoom = eigenvalue_plot(     Hs_zoom, cell_types_zoom,      sort_order=[\"Monocytes\", \"NK\", \"T-cell\", \"Dendritic\", \"Plasma\", \"B-cell\", \"Other\"] ).configure_axis(labelFontSize=12, titleFontSize=22)\\  .configure_range(category=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])  #lambda_plot_zoom.save(\"pbmc_lambda_zoom.svg\") lambda_plot_zoom Out[8]: <p>Now we're ready to make some interactive visualizations. Our first looks for fragmented neighborhoods. These neighborhoods are centered around cells that have a large fraction of neighbors that are placed very far away in the embedding space relative to their true distances in gene expression space. The intuition is that algorithms like UMAP, and $t$-SNE are known to \"tear\" the data.  In extreme cases, cells that might have been not that far apart in their gene expression patterns can be placed on opposite sides of the visualization.  This phenomenon is relatively well documented theoretically as well -- nonlinear dimensionality reduction sometimes resorts to introducing discontinuities in order to achieve their overall embedding objective.</p> <p>In the block below, the object <code>N</code> and is just a dictionary where the keys are the centers of the distorted neighborhoods and the values are the 50 nearest neighbors to that center cell. We interactively visualize these neighborhoods, using the <code>dplot</code> code. The layering syntax should feel familiar to ggplot2 or altair users (granted with much less functionality). The mapping object takes columns of the input <code>DataFrame</code> to the graphical properties in the marks below.  The <code>inter_edge_link</code> command, add interactivity so that when we place our mouse close to one of the fragmented neighborhoods, we see edges emanating to all their neighbors. The fragmented neighborhoods themselves are highlighted with a thick border. The threshold argument controls how close the mouse needs to be before the links are drawn, and strokeWidth gives the associated line width.</p> In\u00a0[16]: Copied! <pre>from distortions.geometry import neighborhoods\nfrom distortions.visualization import dplot\n\nN = neighborhoods(adata, threshold=.2, outlier_factor=2)\nplots = {} \nplots[\"pbmc_links\"] = dplot(embedding, width=440, height=340)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\\n    .geom_ellipse(radiusMax=15, radiusMin=1)\\\n    .inter_edge_link(N=N, threshold=.1, strokeWidth=0.4)\\\n    .scale_color(legendTextSize=15)\\\n    .labs(x=\"UMAP 1\", y=\"UMAP 2\")\nplots[\"pbmc_links\"]\n</pre> from distortions.geometry import neighborhoods from distortions.visualization import dplot  N = neighborhoods(adata, threshold=.2, outlier_factor=2) plots = {}  plots[\"pbmc_links\"] = dplot(embedding, width=440, height=340)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\     .geom_ellipse(radiusMax=15, radiusMin=1)\\     .inter_edge_link(N=N, threshold=.1, strokeWidth=0.4)\\     .scale_color(legendTextSize=15)\\     .labs(x=\"UMAP 1\", y=\"UMAP 2\") plots[\"pbmc_links\"] Out[16]: <pre>dplot(dataset=[{'embedding_0': 5.796429634094238, 'embedding_1': 11.640312194824219, 'x0': -0.8577109625586664\u2026</pre> <p>Unfortunately, the way these notebooks are hosted, you won't be able to directly interact with the output from the call, even though if you were following along in your own notebook, the output should be interactive. We've copied a small recording of our interacting with this visualization in case you just want to have an idea of what this package gives without running it yourself.</p> <p></p> <p>Our next interactive plot compares the embedding versus original expression distances. Instead of flagging entire neighborhoods that have been fragmented, it can be used to find individual links that are poorly preserved in the embedding compared to the original data. We accomplish this by extracting the distance between neighbors and the original and embedding spaces with the <code>neighborhood_distances</code> function and then passing that to <code>inter_boxplot</code> layer. You can now drag a brush over the boxplot widget, and it will highlight the neighboring pairs that lie under the brush. For example, when we draw our brush over the top points above the leftmost box, we're highlighting, neighbors that are very close to one another in expression space but which have been placed far apart in the embedding</p> In\u00a0[10]: Copied! <pre>from distortions.geometry import neighborhood_distances\n\ndists = neighborhood_distances(adata)\nplots[\"pbmc_boxplot\"] = dplot(embedding, width=540, height=340)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\\n    .geom_ellipse(radiusMax=15, radiusMin=1)\\\n    .inter_boxplot(dists=dists, strokeWidth=0.4, legendOffset=100)\\\n    .labs(x=\"UMAP 1\", y=\"UMAP 2\")\nplots[\"pbmc_boxplot\"]\n</pre> from distortions.geometry import neighborhood_distances  dists = neighborhood_distances(adata) plots[\"pbmc_boxplot\"] = dplot(embedding, width=540, height=340)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\     .geom_ellipse(radiusMax=15, radiusMin=1)\\     .inter_boxplot(dists=dists, strokeWidth=0.4, legendOffset=100)\\     .labs(x=\"UMAP 1\", y=\"UMAP 2\") plots[\"pbmc_boxplot\"] Out[10]: <pre>dplot(dataset=[{'embedding_0': 5.796429634094238, 'embedding_1': 11.640312194824219, 'x0': -0.8577109625586664\u2026</pre> <p></p> <p>Next let's apply our isometrization function. This allows us to reverse the distortion locally around query regions. Formally it applies the inverse of the distortion metrics <code>H</code> that were estimated above. The intuition is that this serves as a kind of compromise. Even though we can't ensure that our overall visualization is an isometry, we can at least try to achieve isometries locally around an area of interest. We have set a few hyperparameters here -- they are explained in a bit more detail in the blocks below. For example, we can see that many of the T cells are quite eccentric (this is consistent with the singular values scatterplot above). When we hover over them, they are compressed to be more circular. The directions of dilation have been compressed slightly so that the artificial spread introduced by the inventing algorithm is removed.</p> In\u00a0[24]: Copied! <pre>metrics = {k: H[k] for k in range(len(H))}\nplots[\"pbmc_isometry\"] = dplot(embedding, width=440, height=340)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\\n    .geom_ellipse(radiusMin=.7, radiusMax=8)\\\n    .inter_isometry(metrics=metrics, metric_bw=0.5, transformation_bw=0.2, strokeWidth=0.2)\\\n    .scale_color(legendTextSize=8)\\\n    .labs(x=\"UMAP 1\", y=\"UMAP 2\")\nplots[\"pbmc_isometry\"]\n</pre> metrics = {k: H[k] for k in range(len(H))} plots[\"pbmc_isometry\"] = dplot(embedding, width=440, height=340)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cell_type\")\\     .geom_ellipse(radiusMin=.7, radiusMax=8)\\     .inter_isometry(metrics=metrics, metric_bw=0.5, transformation_bw=0.2, strokeWidth=0.2)\\     .scale_color(legendTextSize=8)\\     .labs(x=\"UMAP 1\", y=\"UMAP 2\") plots[\"pbmc_isometry\"] Out[24]: <pre>dplot(dataset=[{'embedding_0': 5.796429634094238, 'embedding_1': 11.640312194824219, 'x0': -0.8577109625586664\u2026</pre> <p></p> <p>The metric and transformation bandwidth (<code>bw</code>) parameters set in the above visualization are necessary to formalize the isomerization step. The metric bandwidth parameter determines how many of the neighboring ellipses should be used when learning the inverse transformation. Smaller values mean that more neighbors can contribute to the inverse. This can make the output, more stable, but has the downside that it averages over metrics that might not actually be that similar to ones near the mouse. The transformation bandwidth parameter controls how much of a plot gets changed whenever we move our mouse. It can be a bit unwieldy to transform all samples in the plot just to see the isometric embedding within the region of interest. The two plots below highlight the similar ellipses according to both parameters as we move on us over the plot -- similar points appear in black.</p> In\u00a0[12]: Copied! <pre>plots[\"pbmc_transform\"] = dplot(embedding, width=440, height=340)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"kernel_transform\")\\\n    .geom_ellipse(radiusMin=.7, radiusMax=8)\\\n    .inter_isometry(metrics=metrics, metric_bw=1, transformation_bw=0.2, strokeWidth=0.2)\\\n    .scale_color(legendTextSize=8)\\\n    .labs(x=\"UMAP 1\", y=\"UMAP 2\")\n\nplots[\"pbmc_metric\"] = dplot(embedding, width=440, height=340)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"kernel_metric\")\\\n    .geom_ellipse(radiusMin=.7, radiusMax=8)\\\n    .inter_isometry(metrics=metrics, metric_bw=1, transformation_bw=0.2, strokeWidth=0.2)\\\n    .scale_color(legendTextSize=8)\\\n    .labs(x=\"UMAP 1\", y=\"UMAP 2\")\n</pre> plots[\"pbmc_transform\"] = dplot(embedding, width=440, height=340)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"kernel_transform\")\\     .geom_ellipse(radiusMin=.7, radiusMax=8)\\     .inter_isometry(metrics=metrics, metric_bw=1, transformation_bw=0.2, strokeWidth=0.2)\\     .scale_color(legendTextSize=8)\\     .labs(x=\"UMAP 1\", y=\"UMAP 2\")  plots[\"pbmc_metric\"] = dplot(embedding, width=440, height=340)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"kernel_metric\")\\     .geom_ellipse(radiusMin=.7, radiusMax=8)\\     .inter_isometry(metrics=metrics, metric_bw=1, transformation_bw=0.2, strokeWidth=0.2)\\     .scale_color(legendTextSize=8)\\     .labs(x=\"UMAP 1\", y=\"UMAP 2\") <p>The block below appears only so that we can save the state of our interactive plots into an SVG file. This is how we got the plots for our paper. You can read more about saving SVGs from the output of the distortion package by reading the \"Saving Interactions as SVG \" tutorial on this site.</p> In\u00a0[13]: Copied! <pre>#[p.save(f\"{k}.svg\") for k, p in plots.items()]\n</pre> #[p.save(f\"{k}.svg\") for k, p in plots.items()] In\u00a0[14]: Copied! <pre>[display(p) for p in plots.values()]\n</pre> [display(p) for p in plots.values()] <pre>dplot(dataset=[{'embedding_0': 5.796429634094238, 'embedding_1': 11.640312194824219, 'x0': -0.8577109625586664\u2026</pre> <pre>dplot(dataset=[{'embedding_0': 5.796429634094238, 'embedding_1': 11.640312194824219, 'x0': -0.8577109625586664\u2026</pre> <pre>dplot(dataset=[{'embedding_0': 5.796429634094238, 'embedding_1': 11.640312194824219, 'x0': -0.8577109625586664\u2026</pre> <pre>dplot(dataset=[{'embedding_0': 5.796429634094238, 'embedding_1': 11.640312194824219, 'x0': -0.8577109625586664\u2026</pre> <pre>dplot(dataset=[{'embedding_0': 5.796429634094238, 'embedding_1': 11.640312194824219, 'x0': -0.8577109625586664\u2026</pre> Out[14]: <pre>[None, None, None, None, None]</pre> In\u00a0[15]: Copied! <pre>print(len(N))\n</pre> print(len(N)) <pre>72\n</pre>"},{"location":"tutorials/pbmc.html#run-umap","title":"Run UMAP\u00b6","text":""},{"location":"tutorials/pbmc.html#estimate-distortion","title":"Estimate Distortion\u00b6","text":""},{"location":"tutorials/pbmc.html#static-visualizations","title":"Static Visualizations\u00b6","text":""},{"location":"tutorials/pbmc.html#interactive-visualizations","title":"Interactive Visualizations\u00b6","text":""},{"location":"tutorials/svg.html","title":"Saving Interactions as SVG","text":"<p>Let's first save the results from our homepage's quickstart into a plot object.</p> In\u00a0[1]: Copied! <pre>from distortions.geometry import Geometry, bind_metric, local_distortions, neighborhoods\nfrom distortions.visualization import dplot\nimport anndata as ad\nimport numpy as np\nimport scanpy as sc\n\nadata = ad.AnnData(np.random.poisson(2, size=(100, 5)))\nsc.pp.neighbors(adata, n_neighbors=15)\nsc.tl.umap(adata)\n\ngeom = Geometry(affinity_kwds={\"radius\": 2}, adjacency_kwds={\"n_neighbors\": 15})\n_, Hvv, Hs = local_distortions(adata.obsm[\"X_umap\"], adata.X, geom)\nembedding = bind_metric(adata.obsm[\"X_umap\"], Hvv, Hs)\n\nN = neighborhoods(adata, outlier_factor=1)\nplot = dplot(embedding)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\")\\\n    .inter_edge_link(N=N)\\\n    .geom_ellipse()\n</pre> from distortions.geometry import Geometry, bind_metric, local_distortions, neighborhoods from distortions.visualization import dplot import anndata as ad import numpy as np import scanpy as sc  adata = ad.AnnData(np.random.poisson(2, size=(100, 5))) sc.pp.neighbors(adata, n_neighbors=15) sc.tl.umap(adata)  geom = Geometry(affinity_kwds={\"radius\": 2}, adjacency_kwds={\"n_neighbors\": 15}) _, Hvv, Hs = local_distortions(adata.obsm[\"X_umap\"], adata.X, geom) embedding = bind_metric(adata.obsm[\"X_umap\"], Hvv, Hs)  N = neighborhoods(adata, outlier_factor=1) plot = dplot(embedding)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\")\\     .inter_edge_link(N=N)\\     .geom_ellipse() <p>If you print plot, you will see the figure. Hovering the mouse near a point highlights its neighbors. If you double click the figure, it freezes the interactivity.</p> In\u00a0[2]: Copied! <pre>plot\n</pre> plot Out[2]: <pre>dplot(dataset=[{'embedding_0': 12.975311279296875, 'embedding_1': 7.4127984046936035, 'x0': 0.0360943131024686\u2026</pre> <p></p> <p>To save a specific view, call the <code>save()</code> method on the plot object. By default, it will save a file <code>plot.svg</code> to the current notebook directory. You can specify your own path, but it must be an SVG file.</p> In\u00a0[3]: Copied! <pre>plot.save(\"output.svg\")\n</pre> plot.save(\"output.svg\") <p>One known limitation is that you have to at least hover over the SVG before the plot will properly save. This is because anywidget loads some utilities lazily, and we can't save until some interactions have been made. The first time you run <code>plot.save()</code> (before any interactions), it might save an empty svg file to the directory.</p>"},{"location":"tutorials/two_clusters.html","title":"Density Preservation in a Gaussian Mixture Dataset","text":"<p>One of the benefit benefits of estimating local distortion is that it shows how the interpretation of embedding distances may not be comparable across different parts of the plot. In one region distances can be compressed, in others they might be dilated. This is potentially useful if an embedding distort densities. In our paper, we show how these local metrics can be used to evaluate the difference between plain dimensionality reduction methods and density-aware versions -- see also the C. elegans article here. But for now, this article will just show that this local distortion information can help in a very simple example of two clusters with differential densities.</p> <p>The block below generates two Gaussian clusters, one with variance 10 the other with variance 1 and centered at (30, 0). These two clusters are adjacent to one another, but don't really overlap.</p> In\u00a0[1]: Copied! <pre>import numpy as np\nimport pandas as pd\nnp.random.seed(20250702)\n\ndef two_clusters_differential(n):\n    \"\"\"Two 2D clusters of different sizes.\"\"\"\n    points = []\n    for _ in range(n):\n        points.append([10 * np.random.normal(), 10 * np.random.normal()])\n        points.append([30 + np.random.normal(), np.random.normal()])\n    return np.array(points)\n</pre> import numpy as np import pandas as pd np.random.seed(20250702)  def two_clusters_differential(n):     \"\"\"Two 2D clusters of different sizes.\"\"\"     points = []     for _ in range(n):         points.append([10 * np.random.normal(), 10 * np.random.normal()])         points.append([30 + np.random.normal(), np.random.normal()])     return np.array(points) <p>Below we generate a data sample using this function, and we use scanpy to obtain a UMAP embedding. There are 1000 points total 500 in each cluster.</p> In\u00a0[2]: Copied! <pre>M = 500\nn_neighbors = 50\ndata = two_clusters_differential(M)\n</pre> M = 500 n_neighbors = 50 data = two_clusters_differential(M) <p>Let's visualize this raw data. While we could use any visualization package we want. Let's try using our own distortions package. This requires two columns for the singular values that defined the length of each of the ellipse axis. Since for this initial plot will be happy to have plain circles, let's manually set those lengths to one.</p> In\u00a0[3]: Copied! <pre>data_df = pd.DataFrame(data)\ndata_df[\"cluster\"] = [\"A\", \"B\"] * M\ndata_df.columns = [\"x\", \"y\", \"cluster\"]\ndata_df[\"s0\"] = 1\ndata_df[\"s1\"] = 1\n</pre> data_df = pd.DataFrame(data) data_df[\"cluster\"] = [\"A\", \"B\"] * M data_df.columns = [\"x\", \"y\", \"cluster\"] data_df[\"s0\"] = 1 data_df[\"s1\"] = 1 <p>The code below makes the visualization. The <code>.mapping</code> call is analogous to <code>aes()</code> in ggplot2 and <code>.encode()</code> in Altair. This plot backs up will be initially claimed about the relative sizes and overlap.</p> In\u00a0[4]: Copied! <pre>from distortions.visualization import dplot\n\nplots = {}\nplots[\"two_clusters\"] = dplot(data_df, width=450, height=350, labelFontSize=14)\\\n    .mapping(x=\"x\", y=\"y\", color=\"cluster\")\\\n    .scale_color(scheme=[\"turquoise\", \"orange\"])\\\n    .geom_ellipse(radiusMax=6, radiusMin=1)\\\n    .labs(x = \"Original 1\", y = \"Original 2\")\nplots[\"two_clusters\"]\n</pre> from distortions.visualization import dplot  plots = {} plots[\"two_clusters\"] = dplot(data_df, width=450, height=350, labelFontSize=14)\\     .mapping(x=\"x\", y=\"y\", color=\"cluster\")\\     .scale_color(scheme=[\"turquoise\", \"orange\"])\\     .geom_ellipse(radiusMax=6, radiusMin=1)\\     .labs(x = \"Original 1\", y = \"Original 2\") plots[\"two_clusters\"] Out[4]: <pre>dplot(dataset=[{'x': -10.53549603766011, 'y': -1.8629896720824943, 'cluster': 'A', 's0': 1, 's1': 1}, {'x': 29\u2026</pre> <p></p> <p>Below, we've applied UMAP with fifty neighbors and all other parameters are set to their scanpy defaults.</p> In\u00a0[5]: Copied! <pre>from anndata import AnnData\nimport scanpy as sc\n\nadata = AnnData(X=data, obs=pd.DataFrame(range(2 * M)))\nsc.pp.neighbors(adata, n_neighbors=n_neighbors)\nsc.tl.umap(adata)\nembedding = adata.obsm[\"X_umap\"].copy()\n</pre> from anndata import AnnData import scanpy as sc  adata = AnnData(X=data, obs=pd.DataFrame(range(2 * M))) sc.pp.neighbors(adata, n_neighbors=n_neighbors) sc.tl.umap(adata) embedding = adata.obsm[\"X_umap\"].copy() <p>We can visualize the embedding using distortions in the same way that we visualize the raw data. Despite having very different variances/densities, the clusters have been laid out to view of comparable size. The extent to which this fails is quite remarkable, but it's also very well-documented that nonlinear dimensionality reduction methods cannot be trusted to preserve density across clusters [1, 2].</p> In\u00a0[6]: Copied! <pre>embedding_df = pd.DataFrame(embedding, columns=[\"x\", \"y\"])\nembedding_df[\"s0\"] = 1\nembedding_df[\"s1\"] = 1\nembedding_df[\"cluster\"] = data_df[\"cluster\"]\n\nplots[\"plain_embedding\"] = dplot(embedding_df, width=450, height=350, labelFontSize=14)\\\n    .mapping(x=\"x\", y=\"y\", color=\"cluster\")\\\n    .scale_color(scheme=[\"turquoise\", \"orange\"])\\\n    .geom_ellipse(radiusMax=6, radiusMin=1)\\\n    .labs(x = \"Original 1\", y = \"Original 2\")\nplots[\"plain_embedding\"]\n</pre> embedding_df = pd.DataFrame(embedding, columns=[\"x\", \"y\"]) embedding_df[\"s0\"] = 1 embedding_df[\"s1\"] = 1 embedding_df[\"cluster\"] = data_df[\"cluster\"]  plots[\"plain_embedding\"] = dplot(embedding_df, width=450, height=350, labelFontSize=14)\\     .mapping(x=\"x\", y=\"y\", color=\"cluster\")\\     .scale_color(scheme=[\"turquoise\", \"orange\"])\\     .geom_ellipse(radiusMax=6, radiusMin=1)\\     .labs(x = \"Original 1\", y = \"Original 2\") plots[\"plain_embedding\"] Out[6]: <pre>dplot(dataset=[{'x': -7.3624162673950195, 'y': 5.324365139007568, 's0': 1, 's1': 1, 'cluster': 'A'}, {'x': 6.1\u2026</pre> <p></p> <p>Next we estimate local distortions. These are estimates of how the embedding warps geometry locally. The resulting ellipses are the images of unit circles (with respect to the original space's distances) after having been transformed by the embedding. We've slightly post processed the estimated metrics to avoid some outlying values that would otherwise dominate the plot (or at least make the interactions less smooth). The function <code>bind_metric</code> puts these estimated distortion metrics (an array of length <code>N</code> samples) into the original embedding <code>DataFrame</code> we computed above.</p> In\u00a0[7]: Copied! <pre>from distortions.geometry import Geometry, bind_metric, local_distortions\n\nradius = np.mean(adata.obsp[\"distances\"].data)\ngeom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": 1})\nH, Hvv, Hs = local_distortions(embedding, data, geom)\n\n# postprocessing\nHs[Hs &gt; 5] = 5\nHs /= Hs.mean()\nfor i in range(len(H)):\n    H[i] = Hvv[i] @ np.diag(Hs[i]) @ Hvv[i].T\n\nembedding = bind_metric(embedding, Hvv, Hs)\nembedding[\"cluster\"] = data_df[\"cluster\"]\n</pre> from distortions.geometry import Geometry, bind_metric, local_distortions  radius = np.mean(adata.obsp[\"distances\"].data) geom = Geometry(\"brute\", laplacian_method=\"geometric\", affinity_kwds={\"radius\": radius}, adjacency_kwds={\"n_neighbors\": n_neighbors}, laplacian_kwds={\"scaling_epps\": 1}) H, Hvv, Hs = local_distortions(embedding, data, geom)  # postprocessing Hs[Hs &gt; 5] = 5 Hs /= Hs.mean() for i in range(len(H)):     H[i] = Hvv[i] @ np.diag(Hs[i]) @ Hvv[i].T  embedding = bind_metric(embedding, Hvv, Hs) embedding[\"cluster\"] = data_df[\"cluster\"] <p>Below we plot the singular values associated with each of these local metrics. The closer these are to the point, the less the embedding method distorts the original distances (because the point one, one corresponds to the identity). Notice that the first singular value is always larger than the second singular value, which is why all points lie below the dashed line.</p> <p>Surprisingly, we can see that the metrics very clearly distinguish between the two clusters, even though this information was not passed in the distortion estimation procedure. The singular values for cluster a tend to be smaller than those for this corresponds to the fact that those distances have been compressed. This is exactly consistent with the visualization from above. The UMAP seems to have made the two clusters appear of comparable size even though we know that the Cluster A has larger variance. The only way this can be achieved is by compressing the distances in this region of the plot.</p> In\u00a0[8]: Copied! <pre>from distortions.visualization import eigenvalue_plot\n\nlambda_plot = eigenvalue_plot(Hs, embedding[\"cluster\"])\\\n    .configure_axis(labelFontSize=12, titleFontSize=22)\\\n    .configure_range(category=[\"#40e0d0\", \"#ff9d06\"])\n\n#lambda_plot.save(\"two_clusters_lambda.svg\")\nlambda_plot\n</pre> from distortions.visualization import eigenvalue_plot  lambda_plot = eigenvalue_plot(Hs, embedding[\"cluster\"])\\     .configure_axis(labelFontSize=12, titleFontSize=22)\\     .configure_range(category=[\"#40e0d0\", \"#ff9d06\"])  #lambda_plot.save(\"two_clusters_lambda.svg\") lambda_plot Out[8]: <p>Even the static ellipse visualizations are giving us a sense of the differences between these two clusters (a difference that would've been invisible if we had relied on the UMAP alone). We can go a little bit further via applying some interactivity. These interactive visualizations will allow us to dig into a little bit more detail around the current mouse interactions than we could show in the static views alone (This approach is inspired by the focus plus context principle in data visualization).</p> <p>First, let's look for the fragmented neighborhoods. These are the points that have a large fraction of their close neighbors that are far away from them in the embedding space. Unsurprisingly many of these points lie on the boundary between the two clusters. This is consistent with what we know about the original data. The two clusters are actually adjacent to one another, even though in this UMAP they're shown very clearly separated. One of the orange neighborhoods is considered fragmented, even though most of its neighbors are in the orange cluster. The issue with this point seems to be that it's neighbors are on different sides of the cluster.</p> In\u00a0[9]: Copied! <pre>from distortions.geometry import neighborhoods\n\nN = neighborhoods(adata, threshold=0.1, outlier_factor=3)\nplots[\"two_clusters_links\"] = dplot(embedding, width=450, height=350, labelFontSize=14)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cluster\")\\\n    .inter_edge_link(N=N, threshold=1, backgroundOpacity=0.8)\\\n    .scale_color(scheme=[\"turquoise\", \"orange\"])\\\n    .geom_ellipse(radiusMax=10, radiusMin=1)\\\n    .labs(x = \"UMAP1\", y = \"UMAP2\")\nplots[\"two_clusters_links\"]\n</pre> from distortions.geometry import neighborhoods  N = neighborhoods(adata, threshold=0.1, outlier_factor=3) plots[\"two_clusters_links\"] = dplot(embedding, width=450, height=350, labelFontSize=14)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cluster\")\\     .inter_edge_link(N=N, threshold=1, backgroundOpacity=0.8)\\     .scale_color(scheme=[\"turquoise\", \"orange\"])\\     .geom_ellipse(radiusMax=10, radiusMin=1)\\     .labs(x = \"UMAP1\", y = \"UMAP2\") plots[\"two_clusters_links\"] Out[9]: <pre>dplot(dataset=[{'embedding_0': -7.3624162673950195, 'embedding_1': 5.324365139007568, 'x0': -0.061769458747554\u2026</pre> <p></p> <p>Next, we can make the isometry visualization. On the hosted notebook, you will only be able to see the recording that we've made below, but if you're running this locally, you should be able to hover over points and see the plot respond. The main point here is that when you hover over the blue cluster, it gets larger while if you hover over the orange cluster it slightly shrinks. The magnitude of the correction isn't enough to compensate for the extreme difference in variances that we see in the original data, but the estimated effects are at least in the right direction. It's worth keeping in mind that even the distortion estimates we have our estimates -- they have to be learned from data. Like in this example, we might have an indication that there is a difference in density without being able to precisely estimate its magnitude.</p> In\u00a0[10]: Copied! <pre>metrics = {k: H[k] for k in range(len(H))}\nplots[\"two_clusters_isometry\"] = dplot(embedding, width=450, height=350, labelFontSize=14)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cluster\")\\\n    .geom_ellipse(radiusMin=1, radiusMax=10)\\\n    .inter_isometry(metrics=metrics, metric_bw=1, transformation_bw=.1, stroke=\"#f7f7f7\")\\\n    .scale_color(scheme=[\"turquoise\", \"orange\"])\\\n    .scale_size()\\\n    .labs(x=\"UMAP1\", y=\"UMAP2\")\nplots[\"two_clusters_isometry\"]\n</pre> metrics = {k: H[k] for k in range(len(H))} plots[\"two_clusters_isometry\"] = dplot(embedding, width=450, height=350, labelFontSize=14)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"cluster\")\\     .geom_ellipse(radiusMin=1, radiusMax=10)\\     .inter_isometry(metrics=metrics, metric_bw=1, transformation_bw=.1, stroke=\"#f7f7f7\")\\     .scale_color(scheme=[\"turquoise\", \"orange\"])\\     .scale_size()\\     .labs(x=\"UMAP1\", y=\"UMAP2\") plots[\"two_clusters_isometry\"] Out[10]: <pre>dplot(dataset=[{'embedding_0': -7.3624162673950195, 'embedding_1': 5.324365139007568, 'x0': -0.061769458747554\u2026</pre> <p></p> <p>To understand what exactly this visualization is doing, let's analyze the kernels. There are two types of similarity that are used by the isometry visualization. The first type decides which point should contribute in estimating the local metric around the mouse position. That's what we're showing in the plot below. The width of the points that are considered can be controlled by changing the <code>metric_bw</code> parameter -- smaller values will allow more points to contribute.</p> In\u00a0[11]: Copied! <pre>plots[\"two_clusters_metric\"] = dplot(embedding, width=450, height=350, labelFontSize=14)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"kernel_metric\")\\\n    .geom_ellipse(radiusMin=1, radiusMax=10)\\\n    .inter_isometry(metrics=metrics, metric_bw=1, transformation_bw=.1, stroke=\"#f7f7f7\")\\\n    .scale_color(scheme=[\"turquoise\", \"orange\"])\\\n    .scale_size()\\\n    .labs(x=\"UMAP1\", y=\"UMAP2\")\nplots[\"two_clusters_metric\"]\n</pre> plots[\"two_clusters_metric\"] = dplot(embedding, width=450, height=350, labelFontSize=14)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"kernel_metric\")\\     .geom_ellipse(radiusMin=1, radiusMax=10)\\     .inter_isometry(metrics=metrics, metric_bw=1, transformation_bw=.1, stroke=\"#f7f7f7\")\\     .scale_color(scheme=[\"turquoise\", \"orange\"])\\     .scale_size()\\     .labs(x=\"UMAP1\", y=\"UMAP2\") plots[\"two_clusters_metric\"] Out[11]: <pre>dplot(dataset=[{'embedding_0': -7.3624162673950195, 'embedding_1': 5.324365139007568, 'x0': -0.061769458747554\u2026</pre> <p></p> <p>The second kind of kernel controls the region of points that are transformed after each interaction. We've included this because in more complicated em beddings, we may only want to update the region around the mouse position. We've chosen the kernel bandwidth here so that when hovering over one cluster, the other cluster won't be moved to so dramatically. You can change the transformation_bw parameter to adjust how responsive the entire plot is to any localized mousemove.</p> In\u00a0[12]: Copied! <pre>plots[\"two_clusters_transform\"] = dplot(embedding, width=450, height=350, labelFontSize=14)\\\n    .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"kernel_transform\")\\\n    .geom_ellipse(radiusMin=1, radiusMax=10)\\\n    .inter_isometry(metrics=metrics, metric_bw=1, transformation_bw=.1, stroke=\"#f7f7f7\")\\\n    .scale_color(scheme=[\"turquoise\", \"orange\"])\\\n    .scale_size()\\\n    .labs(x=\"UMAP1\", y=\"UMAP2\")\nplots[\"two_clusters_transform\"]\n</pre> plots[\"two_clusters_transform\"] = dplot(embedding, width=450, height=350, labelFontSize=14)\\     .mapping(x=\"embedding_0\", y=\"embedding_1\", color=\"kernel_transform\")\\     .geom_ellipse(radiusMin=1, radiusMax=10)\\     .inter_isometry(metrics=metrics, metric_bw=1, transformation_bw=.1, stroke=\"#f7f7f7\")\\     .scale_color(scheme=[\"turquoise\", \"orange\"])\\     .scale_size()\\     .labs(x=\"UMAP1\", y=\"UMAP2\") plots[\"two_clusters_transform\"] Out[12]: <pre>dplot(dataset=[{'embedding_0': -7.3624162673950195, 'embedding_1': 5.324365139007568, 'x0': -0.061769458747554\u2026</pre> <p></p> In\u00a0[13]: Copied! <pre>#[p.save(f\"../paper/figures/{k}.svg\") for k, p in plots.items()]\n</pre> #[p.save(f\"../paper/figures/{k}.svg\") for k, p in plots.items()] In\u00a0[14]: Copied! <pre>[display(p) for p in plots.values()]\n</pre> [display(p) for p in plots.values()] <pre>dplot(dataset=[{'x': -10.53549603766011, 'y': -1.8629896720824943, 'cluster': 'A', 's0': 1, 's1': 1}, {'x': 29\u2026</pre> <pre>dplot(dataset=[{'x': -7.3624162673950195, 'y': 5.324365139007568, 's0': 1, 's1': 1, 'cluster': 'A'}, {'x': 6.1\u2026</pre> <pre>dplot(dataset=[{'embedding_0': -7.3624162673950195, 'embedding_1': 5.324365139007568, 'x0': -0.061769458747554\u2026</pre> <pre>dplot(dataset=[{'embedding_0': -7.3624162673950195, 'embedding_1': 5.324365139007568, 'x0': -0.061769458747554\u2026</pre> <pre>dplot(dataset=[{'embedding_0': -7.3624162673950195, 'embedding_1': 5.324365139007568, 'x0': -0.061769458747554\u2026</pre> <pre>dplot(dataset=[{'embedding_0': -7.3624162673950195, 'embedding_1': 5.324365139007568, 'x0': -0.061769458747554\u2026</pre> Out[14]: <pre>[None, None, None, None, None, None]</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorials/two_clusters.html#data-generation-and-embedding","title":"Data Generation and Embedding\u00b6","text":""},{"location":"tutorials/two_clusters.html#distortion-estimation","title":"Distortion Estimation\u00b6","text":""},{"location":"tutorials/two_clusters.html#interactive-visualizations","title":"Interactive Visualizations\u00b6","text":""}]}